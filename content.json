{"pages":[{"title":"About this blog","text":"Japanese Ver. Data Science를 좋아하는 학생입니다.특히나, Causal Inference분야에 관심이 많습니다.R, python을 사용하고 있습니다.다양한 사람들과 소통하며 공부하기를 희망하고 있습니다. ・블로그 운영의 목적 스스로의 복습용 메모 주로 머신러닝의 응용처로써의 통계적 인과추론(Causal Inference)에 대해 학습한 내용을 정리합니다. 함께 공부하는 사람에 대한 내용 공유 한국과 일본의 학습자들과 공유하기 위해 모든 블로그 포스트는 한국어 버젼과 일본어 버젼 두가지로 작성하고 있습니다. 부족한 부분이 많습니다. 오타나 잘못된 내용을 발견하셨다면 댓글로 알려주세요.","link":"/About-this-blog/index.html"},{"title":"About this blog","text":"Korean Ver. Data Scienceが大好きな学生です。特に、Causal Inferenceの分野に興味を持っています。R, pythonを使っています。色んな方とコミュニケーションを取りながら学習することを願っています。 ・ブログの目的 自分自身の復習用のメモ 主に機械学習の応用先としての統計的因果推論(Causal Inference)について勉強した内容をまとめます。 他の学習者への内容共有 日本と韓国の学習者と共有するために全てのポストは、日本語バージョンと韓国語バージョンの二通りで作成しています。 まだまだ足りないところが沢山です。 誤字及び間違った内容が見つかりましたら、いつでもコメントください。","link":"/About-this-blog-jap/index.html"}],"posts":[{"title":"【Causal Inference 입문편 ①】인과추론의 목적과 RCT에 관하여","text":"* 인과추론(Causal Inference)으로 뭘 할 수 있는데? \"A 아이스크림을 공중파 CF에 내보냈을때, 해당 아이스크림의 매상은 얼마나 올랐을까?\" \"전 사원 대상 Python 연수 프로그램을 설치 했을때, 사원 들의 일의 능률은 얼마나 올랐을까?\" 이와 같은 질문들은 비즈니스에서 일상적으로 흔히 나올 수 있는 질문들이다. 하지만 이에 대해 깊은 고찰 없이 단순하게 효과를 정의하고 평가함 으로써, 우리는 수많은 바이어스 를 만들어 내고 있다. 공중파 CF의 효과를 계산하기 위해 단순히 CF 전후의 매상의 차이를 계산해서, CF와 관계없이 시기적으로 날씨가 더워져서 오른 맥주의 매상까지도 CF의 효과로써 평가해버린다. 또한 Python 연수를 신청한 사람들은 그렇지 않은 사원들보다 원래부터 우수한 사람이 많을수 있다. 원래부터 일의 능률이 높은 연수자그룹과 비연수자 그룹의 능률을 단순 비교해서 원래의 차이까지도 python연수의 효과로 평가해버린다. 이처럼 인과추론의 목적를 철저하게 비즈니스적 관점에서 보자면 어떠한 시책의 정확한 효과측정 을 위한 이론 &amp; 기술 분야라고 할 수 있다. * Inference 의 신뢰성의 3단계 Level 1. 실험(Experimental) 레벨 RCT (Randomized Controlled Trial; 무작위화 비교 실험) 3가지 기본요건 (1). 비교 : Control Group과 Treatment Group 의 비교를 통해 독립변수가 종속변수에 영향을 미쳤는지 확인하는 과정 (2). 조작 : 시간적으로 독립변수가 먼저 발생하고 그 후에 뒤따라 종속변수가 발생함을 입증하기 위해, 임의로 독립변수를 의도적인 시기에 발생하도록하고 이에 뒤따른 종속변수의 변화를 측정하도록 시간적 순서를 조작하는 것 (인과성의 선후관계) (3). 통제 : 허위적 관계가 아닌 것을 입증하기 위해, 독립변수를 제외한 종속변수에 영향을 미칠 수 있는 여러 변수들이 종속변수에 영향을 미치지 못하도록 상황을 의도적으로 통제하는 것 Level 2. 준실험(Quasi Experimental) 레벨 Level 1의 실험설계는 인과관계를 명확히 구명할 수 있지만, 인위적 통제가 어렵거나 윤리적 문제등으로 인해 (특히 비즈니스의 경우 제한된 예산 등에 의해) 실제 활용이 매우 어렵다. 이에 따라 비록 실험 설계에는 미치지 못하지만, 그 대안적인 방법으로 활용되는 방법이다. 대표적인 방법 (1). 시계열 설계(time-series design) : 비교집단을 별도로 설정하기 곤란한 경우에 하나의 집단 을 선택해서, 독립변수 도입의 전후상태를 비교하는 방법이다. 외적요인에 대한 통제가 어렵기 때문에 (각 기간마다 외부의 영향이 다르다), 위험이 있을 수 있다. 이를 개선하기 위해서는 같은 조사를 여러 집단에서 되풀이하여 실시하여 같은 결과를 얻을 수 있는지 확인할 필요가 있다. (2). 비동일 통제집단 설계(nonequivalent control group design) : 비동일 통제집단 설계는 실험설계의 통제집단 전후비교와 유사하지만 비교집단을 무작위로 선정하지 않는다 는 차이가 있다. 비동일 통제집단 설계는 무작위배치 이외의 방법(매칭, 기존집단의 선정 등)으로 Control Group 및 Treatment Group을 선정한다. 이외에도 변수조작법(IV) , 차의 차 분석(DID) , 경향스코어 매칭(PS) , 회귀불연속 디자인(RDD) 등이 있다. Level 3. 관찰(Observation) 레벨 독립변수를 조작할 수 없고, 연구대상을 무작위할 수 없는 경우 이다. 어느 한 시점에서 독립변수와 종속변수 모두를 측정해서 상관관계를 파악하는데에 그친다. 선후관계가 파악되지 않았고, 무작위화를 통해 동일한 집단에서 비교하지 못했으므로 부적절한 해석을 하게 될 위험을 가지고 있다. 확증편향 \\(^{[*1]}\\)(confirmation bias) 이나 사후해석편향 \\(^{[*2]}\\)(hindsight bias)에 영향을 받기 쉽다. 예를 들어, 시책 담당자가 좋은 결과만을 보고 싶다고 하면 집계의 방법을 유리하게 설정해서 유리한 결과가 나오도록 하는 것이 얼마든지 가능하므로 주의가 필요하다. Level 3은 Level 1&amp; Level 2를 한 후에 추가적으로 검토하는 용도. 또한, 집계의 방법을 미리 정해놓는 것을 통해, 자의적으로 변경해서 입맛에 맞는 해석을 하지 않는 것이 중요하다. ####【여기서 기억해야 할 것】 Lv1 \\(\\rightarrow\\) Lv2 \\(\\rightarrow\\) Lv3 의 순서로 시책의 효과를 검토해가는 것이 중요하다!! &lt;span style=\"font-size: 85%;&gt; \\(^{[*1]}:\\) 원하는 정보를 선택적으로 모으는 등의 가지고 있는 신념을 확인하려는 경향성. &lt;span style=\"font-size: 85%;&gt; \\(^{[*2]}:\\) 어떤 사건이 발생한 후, 사전에 그런 일이 일어날 것으로 예상했었다는 식으로 문제를 처리하는 것. 실제로는 벌어진 사건에 대해 전혀 대비를 하지 못하고, 그 원인을 냉정하게 규명해야 함에도 불구하고 \"충분히 예측했던 일\"이라며 자기 확신에 빠지는 것. * Potential Outcome Framework 처치(Treatment) 혹은 개입(Intervention)이 이뤄졌는지 여부 \\(\\begin{equation}Z_i= \\left \\{\\begin{array}{l}1 (Treated) \\\\0 (Untreated)\\end{array}\\right.\\end{equation}\\) 종속변수(DV; Dependent Variable) 혹은 목적변수(Criterion Variable) ; 개입을 받은 경우와 받지 않은 경우 두가지로 나타낼 수 있다. (실제로는 어느 한쪽만 관찰가능하지만) \\(\\begin{equation}Y_i= \\left \\{\\begin{array}{l}Y_i^{(1)} (Z_i = 1) \\\\Y_i^{(0)} (Z_i = 0)\\end{array}\\right.\\end{equation}\\) \\(\\Rightarrow Y_i = Y_i^{(0)}(1- Z_i) + Y_i^{(1)}Z_i\\) 이와 같이, 샘플 \\(i\\) 에 대하여 개입을 받은 경우의 결과 \\(Y^{(1)}\\) 와 받지 않은 경우의 결과 \\(Y^{(0)}\\) 간의 차이가 개입의 진정한 처치효과(TE; Treatment Effect) 라고 가정하는 것을 Potential Outcome Framework 라고 한다. \\(\\bf \\tau_{TE} = Y^{(1)}-Y^{(0)}\\) 모든 샘플 \\(i\\) 에 대해 각각의 처치효과를 구하는 것은 까다롭기 떄문에, 그룹간의 비교로써 평균처치효과(ATE; Average Treatment Effect) 를 다루는 경우도 많다. \\(\\bf \\tau_{ATE}= E[Y^{(1)}]-E[Y^{(0)}]\\) * Level 1. 실험레벨 ; 인과추론의 기초, RCT RCT의 특징 비즈니스의 관점에서는 AB테스트 라고 할 수 있다. RCT (Randomized Controlled Trial; 무작위화 비교 실험)를 통해 Control Group과 Treatment Group을 무작위하게 나눔으로써 두 그룹간의 동질성 을 기대할 수 있다. 측정된 교란인자(confounding factors)\\(^{[*1]}\\)는 물론, 측정되지 않은 교란인자 에 대해서도 비교군과 대조군의 균형을 이룬다. (측정되지 않은 교란인자 까지 처리할 수 있는 실험디자인은 RCT와 완벽하게 설계된 조작변수법(IV), 분할시계열디자인(ITS) 밖에 존재하지 않는다.) 그로 인해 모든 연구 디자인 중 가장 높은 내적타당성\\(^{[*2]}\\)을 기대할 수 있다. 즉 RCT에서는 이론상, \\(ATU = ATT = ATE\\)을 기대할 수 있다. ( \\(ATU\\) (Average Treatment Effect on the Untreated) \\(= E[Y^{(1)}|Z=0] - E[Y^{(0)}|Z=0]\\) ) ( \\(ATT\\) (Average Treatment Effect on the Treated) \\(= E[Y^{(1)}|Z=1] - E[Y^{(0)}|Z=1]\\) ) ( \\(\\bf ATE\\) (Average Treatment Effect) \\(\\bf = E[Y^{(1)}] - E[Y^{(0)}]\\) ) [*] 위의 표에서 Control Group의 \\(Y_i^{(1)}\\)과 Treatment Group의 \\(Y_i^{(0)}\\)은 실제로 관찰 불가능한 반사실적 Potential Outcome 이다. RCT의 의의 선택바이어스(Selection Bias) 의 제거 조작변수 이외의 다른 변수들을 통제하지 못한 채 Control Group과 Treatment Group 선택하게 되면, 그룹간의 동질성을 확보하지 못하여 교란변수(confounding factor) 에 의해 효과가 왜곡 될 수있다. 이러한 것을 선택 바이어스 라고 한다. RCT는 완전 무작위로 처치그룹을 선택하기 때문에 선택 바이어스 에서 자유로워질 수 있다. RCT의 약점 (1). 비용(예산, 시간 등)이 많이 든다. (2). 외적타당성(일반화 가능성)\\(^{[*3]}\\) RCT에서는 비용의 문제로 인해 외부조건을 통제하게 되고 그로인해 외적타당성은 낮아질 수 있다. (3). noncompliance 문제 RCT에서 무작위로 그룹을 배분해도 거기에 따르지 않는 사람이 생겨서 나타나는 문제 (4). (특히 기업의 AB테스트에서) 다른 RCT를 같은 대상자에 겹쳐서 실행하게 될 경우, 그에 따른 바이어스가 생길 수 있다. 통계적으로 처리하기가 상당히 복잡해진다. &lt;span style=\"font-size: 85%;&gt; \\(^{[*1]}:\\) '원인'과 '결과' 양쪽 모두에게 공통의 원인이 되는 요인. Graphical Model에서 공통부모, 분기로 표현되는 부분. 내생성(Endogeneity)으로도 표현한다. &lt;span style=\"font-size: 85%;&gt; \\(^{[*2]}:\\) 다른 외생변수들이 종속변수에 영향을 주지 않고 진정한 독립변수 의 효과인가의 타당성. &lt;span style=\"font-size: 85%;&gt; \\(^{[*3]}:\\) 내적타당성을 높이기 위해 실험조건을 엄격히 통제한다면 일반화 가능성이 낮아질 수 있다. 얼마나 일반적 현실에 확장 가능한지의 타당성. * Reference 해당 포스트는 유튜브 채널「データの科学のメソドロジー」의 山田典一님의 강의를 틀로 내용을 정리 &amp; 추가 했음을 밝힙니다. 그 외 참조 効果検証入門〜正しい比較のための因果推論/計量経済学の基礎 （安井翔太） RCTをめぐる3つの問題とその解法（山口一男） 実験（Experiment）と疑似実験（Quasi-experiment）に関する記事(津川友介) http://blog.daum.net/sangrimza/15612241 https://m.blog.naver.com/PostView.nhn?blogId=lucifer246&amp;logNo=201407281&amp;proxyReferer=https:%2F%2Fwww.google.com%2F","link":"/2020/11/30/CI1/"},{"title":"【 도대체 베이지안 네트워크가 뭐야? ①】","text":"* 베이지안 네트워크(BN; Bayesian Network) 란? 확률 변수(RV; Random variables)들 사이의 조건부 독립 등의 관계를 보임으로써, RV의 full joint distribution등을 간결하게 표현할 수 있는 그래프 표기법 (Graphical Notation) 이다. 여기서 그래프(Graph) 란, 수학에서 차트(Chart)와 대조되어 정의된 node와 edge의 집합 edge가 방향이 지정되어 있으면 directed, 그렇지 않으면 undirected 그래프의 모든 edge가 directed일 때 directed graph directed edge에서, 시작되는 쪽의 노드를 parent node 라고 하고 반대쪽은 child node라고 한다 복수의 연결된 directed edge의 방향이 같은 경우 이를 directed path라고 하고, directed path의 첫 번째 노드는 경로상의 모든 노드들의 ancestor node이고, 반대로 나머지 노드들은 첫번째 노드의 descendant node이다. directed path의 시작점과 끝점이 일치할 경우 이를 cyclic이라 하고, 그렇지 않은 경우 acyclic라고 한다. 베이지안 네트워크(BN) 의 Syntax Network 는 Node와 이들을 연결시키는 Edge로 구성된다 방향성 비순환 그래프(DAG; Directed Acyclic Graph) 가 되어야 한다 개별 Node들은 RV인 \\(X\\)에 대해 \\(\\bf P(X | Paranets(X))\\)를 의미한다. 개별 Edge들은 부모가 자식에게 주는 직접적인 영향(Direct Influence) 을 의미한다. * 먼저 확률에 대한 간단한 복습부터 베이지안 네트워크 라는 것은 결국 확률변수(RV) 간의 관계 를 표현한 것이다. 확률 이라는 것은 상대적인 빈도 이다. 독립성 (Independence) \\(P(A|B) = P(A)\\) \\(\\Leftrightarrow P(A,B) = P(A)P(B)\\) \\(\\Leftrightarrow P(B|A) = P(B)\\); A와 B가 독립이면, B는 A와 독립이다. 사건B가 발생했다는 정보는 사건A가 발생할 확률에 추가적인 정보를 제공하지 못한다. 이는, 밑에 서술하는 Conditional Independence 와 대립되는 의미로 Marginal Independence 라고 할 수 있다. 조건부 독립 (Conditional Independence) \\(P(A|B,C) = P(A|C)\\) 사건C가 주어졌을 때 두 사건 A와 B가 독립인 경우, 이것은 C라는 조건하에서 조건부 독립 이다. 조건부 확률 (Conditional Probability) \\(P(A= true|B=true)\\) \"Probablity of A given B\" B가 주어졌을 때, A의 확률 결합 확률 (joint Probability) \\(P(A= true, B=true)\\) \"the probability of A=true and B=true\" A=true와 B=true가 동시에 만족할 확률 조건부 확률과 결합 확률의 관계 는 일반적으로, \\(P(X|Y) =\\cfrac{P(X,Y)}{P(Y)}\\) 총 확률 법칙 (Law of Total Probability) \"Summing out\" or \"Marginalization\" \\(P(A) = \\sum_kP(A,B_k) = \\sum_kP(A|B_k)P(B_k)\\) \\(P(A) = \\sum_kP(A,B_k)\\) 는 \\(B_1,B_2,...,B_n\\)이 각각 상호배반적인 집합이고 이들의 합집합이 전체집합이 되므로 성립 (marginalize) \\(\\sum_kP(A,B_k) = \\sum_kP(A|B_k)P(B_k)\\)는 조건부확률과 결합확률의 관계를 이용하면 유도가능 이로 인한 이점은, \\(P(A)\\)를 직접 구하는 것보다, \\(P(A|B_k)\\)와 같은 조건부확률을 구해서 합치는 것이 일반적으로 더 수월하다는 것이다. 혹은 결합확률을 알고 있을 때, 여러가지 확률을 계산 할 수 있다. 예를들어, 결합확률인 \\(P(a,b,c,d)\\)를 알고 있을 때, \\(P(c|b)\\)는 이렇게 표현할 수 있다 \\(P(c|b) = \\sum_a \\sum_d P(a,c,d|b) = \\cfrac{1}{P(b)}\\sum_a \\sum_d {\\bf P(a,b,c,d)}\\) 그러나 joint의 경우에는 parameter의 수가 exponential하게 늘어나게 된다! (Chain Rule의 필요성) 확률의 연쇄법칙 (Chain Rule for probability) 모든 joint distribution에 대해, 결합확률과 조건부확률의 관계에 의해 언제나 이하와 같이 표현할 수 있다. \\(P(a,b,c,...,z) = P(a|b,c,...,z)P(b,c,....,z)\\) 이것을 반복적으로 하면, \\(P(a,b,c,...,z) = P(a|b,c,...,z)P(b|c,...,z)P(c|d,...,z)...P(z)\\)로 표현 가능하다. (Factorization) 곱 분해 법칙 (Rule of product decomposition) Bayesian Network에서는 그래프에 속한 RV의 결합분포(joint distribution)는 family의 모든 조건부 분포 \\(P(Child|Parent)\\)의 곱\\(^{[*1]}\\)으로 표현 할 수 있다. (시리즈의 다음 포스트의 Factorization of Bayes Network 내용 참조) \\(P(x_1,x_2,...,x_n) = \\prod _iP(x_i|Parents(x_i))\\) Parents는 직접적으로 연결되어 영향을 받는 변수만을 의미! 예를 들어, \\(X\\rightarrow Y \\rightarrow Z\\) 인 그래프에서 \\(P(X=x, Y=y, Z=z)\\)를 구하는 것을 생각해보자 원래는 가능한 모든 조합의 \\((x, y, z)\\)에 해당하는 확률 테이블을 만들어야 한다 그러나, 이 법칙을 이용하면 \\(P(X=x, Y=y, Z=z) = P(X=x)P(Y=y|X=x)P(Z=z|Y=y)\\)로 간결하게 표현 가능 이처럼 고차원을 저차원으로 만들어 차원의 저주(curse of dimensionality) 에서도 비교적 자유로워 질 수 있다. &lt;span style=\"font-size: 85%;&gt; \\(^{[*1]}:\\) 이렇게 정의되는 원래는 뒤에서 기술하는 베이지안 네트워크의 Typical Local Structures Rules와 관련 되어있다. * 베이지안 네트워크의 Rules of Typical Local Structures Rule 1. 사슬 혹은 폭포형 (Chain or Cascading) 변수\\(X\\)와 변수\\(Y\\)의 사이에 하나의 방향성 경로 만 있고 변수\\(Z\\)가 해당 경로를 가로막고 있는 경우, \\(Z\\)가 조건부로 주어졌을때 두 변수 \\(X\\)와 \\(Y\\)는 조건부 독립 이다. \\(X \\perp Y|Z\\) \\(\\Leftrightarrow P(Y|X,Z) = P(Y|Z)\\) Rule 2. 분기 혹은 공통부모형 (Fork or Common parent) 변수 \\(Z\\)가 \\(X\\)와 \\(Y\\)의 공통 원인이고 \\(X\\)와 \\(Y\\)사이에 단 하나의 경로가 있는 경우, \\(Z\\)의 조건이 주어졌을 때 \\(X\\)와 \\(Y\\)는 조건부 독립 이다. \\(X \\perp Y | Z\\) \\(\\Leftrightarrow P(X,Y|Z) = P(X|Z)P(Y|Z)\\) Rule 3. 충돌부 혹은 V-구조 (Collider or V-structure) 변수 \\(Z\\)가 두 변수 \\(X\\)와 \\(Y\\) 사이의 충돌 노드이고 \\(X\\)와 \\(Y\\) 사이에 단 하나의 경로 만 있을 경우, \\(X\\)와 \\(Y\\)는 비조건부 독립(underconditionally independent) 이다. 그러나 \\(Z\\) 또는 \\(Z\\)의 descendant을 조건부로 하였을 때 \\(X\\)와 \\(Y\\)는 종속적일 가능성 이 있다. \\(\\sim (X \\perp Y|Z)\\) \\(\\Leftrightarrow P(X,Y,Z)=P(X)P(Y)P(Z|X,Y)\\) 즉 \\(Z\\)가 not given 일 때는 독립이지만, 반대로 \\(Z\\)가 given으로 주어지면 \\(X\\), \\(Y\\)가 종속적이 될 가능성이 생겨버린다. * Bayes Ball Algorithm 목적 ; \\(X \\perp Y | Z\\) (\\(Z\\)가 given일 때 \\(X\\)와 \\(Y\\)가 독립) 이 성립하는지 여부를 판정하기 위한 알고리즘 \\(X\\)에서 공이 출발한다고 가정했을 때 \\(Y\\)까지 공이 도달하는지 확인하는 방법 여기서 공은 Information을 의미하고 화살표는 공의 움직임을 의미한다. 노드 간이 직접적인 edge로 연결되어 있지 않더라도 공이 굴러가서 도달할 수 있다면 Indirect influence가 존재하기때문에 두 변수는 depedent하다는 것을 의미한다. Rule 1의 경우 (1). \\(Z\\)가 given이 아닐 때, 공은 지나갈 수 있다. (\\(X, Y\\)는 종속) (2). \\(Z\\)가 given 일 때, 공은 지나갈 수 없다. (\\(X \\perp Y|Z\\)) Rule 2의 경우 (1). \\(Z\\)가 given이 아닐 때, 공은 지나갈 수 있다. (\\(X, Y\\)는 종속) (2). \\(Z\\)가 given 일 때, 공은 지나갈 수 없다. (\\(X \\perp Y|Z\\)) Rule 3의 경우 (1). \\(Z\\)가 given이 아닐 때, 공은 지나갈 수 없다. (\\(\\bf X \\perp Y\\)) (2). \\(X_C\\)가 given 일 때, 반대로 path가 생겨서 공이 지나갈 수 있게 된다. (\\(X, Y\\)는 종속 \\(|Z\\)) Bayes Ball Algorithm 연습 문제 1. \\(X_1\\perp X_4|X_2\\) 두가지 경로로 공을 굴릴 수 있다. (1). \\(X_1 \\rightarrow {\\bf X_2}(given) \\rightarrow X_4\\) 의 경로는 \\(X_2\\)가 사슬의 given으로 막혀있으므로 지나갈 수 없다. (2). \\(X_1 \\rightarrow X_3 \\rightarrow X_5 \\rightarrow X_6 \\leftarrow {\\bf X_2}(given) \\rightarrow X_4\\) 의 경로는 \\(X_6\\)가 충돌부의 not given으로 막혀있으므로 지나갈 수 없다. 따라서 어떠한 경로로도 볼은 지나갈수 없으므로 \\(X_2\\)가 given일 때 \\(X_1\\)와 \\(X_4\\)는 독립 이다. 문제 2. \\(X_2\\perp X_5|X_1\\) 두가지 경로로 공을 굴릴 수 있다. (1). \\(X_2 \\rightarrow X_6 \\leftarrow X_5\\) 의 경로는 \\(X_6\\)가 충돌부의 not given으로 막혀있으므로 지나갈 수 없다. (2). \\(X_2 \\leftarrow {\\bf X_1}(given) \\rightarrow X_3 \\rightarrow X_5\\) 의 경로는 \\(X_1\\)가 분기의 given으로 막혀있으므로 지나갈 수 없다. 따라서 어떠한 경로로도 볼은 지나갈수 없으므로 \\(X_1\\)가 given일 때 \\(X_2\\)와 \\(X_5\\)는 독립 이다. 문제 3. \\(X_1\\perp X_6|\\{X_2, X_3\\}\\) 두가지 경로로 공을 굴릴 수 있다. (1). \\(X_1 \\rightarrow {\\bf X_2}(given) \\rightarrow X_6\\) 의 경로는 \\(X_2\\)가 사슬의 given으로 막혀있으므로 지나갈 수 없다. (2). \\(X_1 \\rightarrow {\\bf X_3}(given) \\rightarrow X_5 \\rightarrow X_6\\) 의 경로는 \\(X_3\\)가 사슬의 given으로 막혀있으므로 지나갈 수 없다. 따라서 어떠한 경로로도 볼은 지나갈수 없으므로 \\(\\{X_2, X_3\\}\\)가 given일 때 \\(X_1\\)와 \\(X_6\\)는 독립 이다. 문제 4. \\(X_2\\perp X_3|\\{X_1, X_6\\}\\) 두가지 경로로 공을 굴릴 수 있다. (1). \\(X_2 \\leftarrow {\\bf X_1}(given) \\rightarrow X_3\\) 의 경로는 \\(X_1\\)가 분기의 given으로 막혀있으므로 지나갈 수 없다. (2). \\(X_2 \\rightarrow {\\bf X_6}(given) \\leftarrow X_5 \\leftarrow X_3\\) 의 경로는 \\(X_6\\)가 충돌부의 given으로 뚫려있으므로 지나갈 수 있다. 따라서 두번째 경로로 볼은 지나갈 수 있으므로 \\(\\{X_1, X_6\\}\\)가 given일 때 \\(X_2\\)와 \\(X_3\\)는 독립이 성립하지 않는다. * \\(d\\)-Seperation의 정의 \\(d\\)는 방향성(directly)을 의미한다. Bayesian Ball Algorithm으로 \\(d\\)-Seperation을 확인할 수 있다. 정리하자면, 경로p가 조건부집합 \\(\\{W\\}\\)에 의해 \\(d\\)-Seperate된다는 명제는 이하와 필요충분조건이다. 경로p는 조건부집합 \\(\\{W\\}\\)에 속하는 중간노드 \\(Z\\) 의 사슬 \\(X \\rightarrow Z \\rightarrow Y\\) 또는 분기 \\(X \\leftarrow Z \\rightarrow Y\\) 를 포함한다. 경로p는 조건부집합 \\(\\{W\\}\\)에 속하지 않는 중간노드 \\(Z'\\) 의 충돌부 \\(X \\rightarrow Z' \\leftarrow Y\\) 를 포함한다. * Reference 해당 포스트는 Edwith에 개설된 문일철 교수님의 인공지능 및 기계학습 개론 II 강의를 정리 &amp; 추가한 내용임을 밝힙니다. 추가 내용 참조 의학 및 사회과학 연구를 위한 통계적 인과추론 （Judea Pearl, Madelyn Glymour, Nicholas P. Jewell）","link":"/2020/11/14/BN1/"},{"title":"【 도대체 베이지안 네트워크가 뭐야? ②】","text":"* Factorization of Bayes Network 그래프에 속한 RV의 결합분포(joint distribution)는 family의 모든 조건부 분포 \\(P(Child|Parent)\\)의 곱으로 표현 할 수 있다. \\(P(X_1,X_2,...,X_n) = \\prod _iP(X_i|Parents(X_i))\\) 곱 분해 법칙 (Rule of product decomposition) 확률의 연쇄법칙 \\(P(a,b,c,...,z) = P(a|b,c,...,z)P(b,c,....,z)\\)에서 사슬과 분기의 Rule에 따르면 부모노드가 given이면 이상은 조상노드는 전부 독립이게 되므로 성립. (충돌부는 부모노드가 아니다.) 즉, Bayes Network의 정보를 통해 joint distribution를 계산할 때 parameter의 갯수를 줄일 수 있다. \\([ 예시 ]\\) \\(P(X_1,X_2,X_3,X_4,X_5,X_6,X_7,X_8)\\)를 구한다고 하자. 확률의 연쇄법칙 (Chain Rule for probability) 에 의해 아무런 Bayesian Network의 정보가 없다고 하더라도 \\(P(X_1,X_2,X_3,...,X_8) = P(X_1|X_2,X_3,...,X_8)P(X_2|X_3,...,X_8)P(X_3|X_4,...,X_8)...P(X_8)\\) 로 Factorize 할 수 있다. 곱 분해 법칙 (Rule of product decomposition) 에 의해 Bayesian Network의 정보를 활용하면 \\(P(X_1,X_2,X_3,...,X_8) = P(X_1)P(X_2)P(X_3|X_1)P(X_4|X_2)P(X_5|X_2)P(X_6|X_3,X_4)P(X_7|X_6)P(X_8|X_5,X_6)\\) 로 훨씬 작은 parameter만으로 Factorize 가능하다. * Plate Notation \\(\\begin{align} P(D|\\theta) &amp;= P(X_1,...,X_N|\\mu,\\sigma) \\\\ &amp;= \\prod_i^N P(X_i|\\mu,\\sigma) \\end{align}\\) 이처럼 여러 개의 독립적인 RV들에 대해 위와 같이 Plate Notation 로 표현하는 것이 가능하다. * 베이지안 네트워크에서의 확률추론 BN에 있는 모든 random variables ; \\(X = \\{X1 ... X_N\\}\\) 주어진 증거 변수 (given evidence variables) ; \\(X_V =\\{X_{k+1}...X_N\\}\\) \\(x_V\\)는 evidence values 명시적으로 다루지는 않지만 관계가 있어서 감안할 필요가 있는 변수 (hidden variables) ; \\(X_H = X-X_V = \\{X_1...X_k\\}\\) hidden variables ; \\(X_H = \\{Y,Z\\}\\) \\(Y\\) : query variable (interested hidden variables) \\(Z\\) : uninterested hidden variables 1-1 주변확률 (Marginal Probability) 증거 변수 \\(X_V\\) 의 주변확률 (Marginal Probability) \\(P(x_V)\\) 는? \\(\\begin{align} P(x_V) &amp;=\\sum_{X_H}P(X)=\\sum_{X_H}P(X_H,X_V) \\space\\space\\space\\space\\space\\space\\dots(1)\\\\ &amp;= \\sum_{x_1}...\\sum_{x_k}P(x_1...x_k,x_V)\\space\\space\\space\\space\\space\\space\\space\\space\\space\\dots(2) \\end{align}\\) (1). 모든 변수에 대해 full joint 된 것을 \\(X_H\\)로 marginalize out한 것이라고 생각한다. (2). 각각의 Hidden variable에 대해 marginalize out한 것이라고 생각한다. 1-2. 조건부 확률 (Conditional Probability) 주어진 증거(evidence)의 집합\\(x_V\\)이 있을때, query variable(주어지지 않았지만 관심있는 변수) 의 조건부 확률 \\(P(Y|x_V)\\)은? \\(\\begin{align} P(Y|X_V) &amp;= \\sum_ZP(Y,Z = z|x_V) \\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\dots(1)\\\\ &amp;= \\sum_Z\\cfrac{P(Y,Z,x_V)}{P(x_V)} = \\sum_Z\\alpha P(X) \\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\dots(2)\\\\ &amp;= \\sum_Z \\cfrac{P(Y,Z,x_V)}{\\sum_{y,z}P(Y=y, Z=z, x_V)}\\space\\space\\space\\space\\space\\space\\space\\space\\space\\dots(3) \\end{align}\\) (1). \\(Z\\)를 joint로 넣어주면서 \\(Z\\)에 대해 marginalize out 한다. (2). 조건부 확률의 정의를 이용해, \\(x_V\\)를 포함한 full joint 를 \\(P(x_V)\\) (Marginal Probability)로 나눈다. (\\(\\cfrac{1}{P(x_V)} = \\alpha\\)라는 정규화 상수(normalization constant)의 곱으로 생각할수도 있다.) (3). 분모의 주변확률은 Inference Question1처럼 full joint 를 모든 Hidden variable에 대해 marginalize 해서 구할 수 있다. * 변수제거 알고리즘 (Variable Eliminatation Algorithm) 위와 같이 주어진 상황에서 변수제거 알고리즘으로 \\(P(J=j)\\)를 구해보자 * Step1 위의 준비를 통해 베이지안 네트워크 상에서 관심있는 확률의 추론을 위해서, full joint 를 구하고 uninterested hidden variable에 대해 Marginalize 한다. \\(\\sum_{A,E,B,M} P(J= j,A,E,B,M)\\) * Step2 full joint 를 Bayesina Network의 정보를 이용해 곱분해 법칙으로 바꿔 쓴다. 분해한 곱의 나열순서는 topological order \\(^{[*1]}\\) 를 따른다. topological order ; B, E, A, J, M \\(\\sum_{B,E,A,M} P(B)P(E)P(A|B,E)P(J=j|A)P(M|A)\\) &lt;span style=\"font-size: 85%;&gt; \\(^{[*1]}:\\) 들어오는 화살표가 없는 노드 부터 하나씩 선택하며 지우는 것을 반복할때 결정되는 순서 * Step3 순서를 유지한 채 각 \\(\\sum\\)가 관련없는 것을 밖으로 빼낸다. 제거할 변수의 순서는 뒤에서부터 정해진다. \\(\\space\\space\\space\\sum_B P(B)\\sum_EP(E)\\sum_AP(A|B,E)P(J=j|A)\\sum_MP(M|A)\\) * Step4 뒤에서 부터 function notation으로 바꿔주면서 변수를 지워나간다. \\(\\space\\space\\space\\sum_B P(B)\\sum_EP(E)\\sum_AP(A|B,E)P(J=j|A) \\underline {\\sum_MP(M|A)}\\) \\(=\\sum_B P(B)\\sum_EP(E)\\sum_AP(A|B,E)P(J=j|A) \\underline {\\bf f_1(A)}\\) 밑줄친 부분은 J와 \\(d\\)-seperate이기 때문에 고려할 필요가 없다. 즉, A의 값과 상관없이 \\(f_1(A)\\)는 1을 갖는다. \\(=\\sum_B P(B)\\sum_EP(E)\\underline{\\sum_AP(A|B,E)P(J=j|A)}\\) \\(=\\sum_B P(B)\\sum_EP(E)\\underline {\\bf f_2(E,B)}\\) \\(f_2(E,B)\\)는 이하와 같다. \\(=\\sum_B P(B)\\underline {\\sum_EP(E)f_2(B,E)}\\) \\(=\\sum_B P(B) \\underline {\\bf f_3(B)}\\) \\(f_3(B)\\)는 이하와 같다. \\(= \\sum_BP(B)f_3(B)\\) \\(= P(B=b)f_3(B=b) + P(B= \\sim b)f_3(B=\\sim b)\\) \\(=0.001 * 0.849017 + 0.999 * 0.0513413 \\fallingdotseq 0.052139\\) 따라서, \\(P(J=j) = 0.052139\\) 가 된다. * Reference 해당 포스트는 Edwith에 개설된 문일철 교수님의 인공지능 및 기계학습 개론 II 강의를 정리 &amp; 추가한 내용임을 밝힙니다. 추가 내용 참조 https://www.youtube.com/watch?v=TZnEJ4wvLPY 의학 및 사회과학 연구를 위한 통계적 인과추론 （Judea Pearl, Madelyn Glymour, Nicholas P. Jewell）","link":"/2020/11/14/BN2/"},{"title":"【Causal Inference②】조작변수법(IV)에 관하여","text":"* RCT를 사용할 수 없을 때는 어떻게 할까? Level 1. 실험(Experimental) 레벨 (개입연구) 관찰자(해석자)가 개입의 계획을 세워서 데이터를 수집 \\(\\rightarrow\\) RCT (무작위화비교실험) \\(\\blacktriangleright\\) Level 2. 준실험(Quasi Experimental) 레벨 비교적 질 좋은 관찰연구 정도의 느낌 실험데이터가 아니라 관찰데이터 를 사용해서, 개입의 여부 등으로 결과에의 영향을 추정 측정되지 않은 교란인자를 처리할 수 있는 것은 사실상 RCT만이 쉽게 가능하지만, 모든 교란인자를 충분히 측정할 수 있다고 하면 준실험설계로도 충분히 인과관계를 설명할 수 있다. 변수조작법(IV) , 차의 차 분석(DID) , 경향스코어 매칭(PS) , 회귀불연속 디자인(RDD) 등이 있다. Level 3. 관찰(Observation) 레벨 더욱 인과추론 하기에 취약한 관찰연구 디자인 \\(I\\). 조작변수법 (IV; Instrumental variable methods) - 조작변수법이란? 매우 어렵지만 이론상 완벽하게 설계된다면 측정되지 않은 교란인자 도 처리할 수 있는 방법. 외생변수 ; 모델의 밖에서 결정되어 주어진 변수 (설명변수로써 바람직하다). 모델의 잔차항 과 독립하게 된다. 내생변수 ; 모델 내에서 결정되는 변수 (설명변수로써 바람직하지 않다). 예를 들어 측정되지 않은 교란인자 가 있는 경우 영향을 받는 설명변수와 모델의 잔차항 사이에 상관 관계가 생겨버리고 이 설명변수는 내생변수 가 되어 내생성 바이어스 를 만든다. 이렇게 발생된 내생변수 를 외생화 하기 위해 도입된 변수 \\(Z\\)를 조작변수(IV) 라고 한다. 이러한 조작변수를 이용해, 설명변수가 결과에 미치는 영향을 평가하는 방법을 조작변수법 이라고 한다. \\([ 예시 ]\\) - 참의 관계 : \\(ln(wage) = a + b \\cdot educ + c \\cdot ability + u\\) 임금(Wage)와 교육년수(Education)와 능력(Ability)은 위와 같은 관계가 있다고 가정한다. 그러나 능력은 실제로 측정불가하기 때문에 교육수준만으로 임금과의 관계를 설명하는 모델을 작성했다고 하자. \\(ln(wage) = a' + b' \\cdot educ + v\\) 이 때, 능력(Ability)은 관측되지 않은 교란인자 가 되고 계수 \\(b'\\)에는 내생성 바이어스가 존재하게 된다. - 조작변수법의 과정 내생변수 를 피설명변수로 별도의 조작변수 \\(IV\\)를 통해 설명하는 모델을 작성한다. \\(\\begin{align} ln(wage) &amp;= a' + b' \\cdot educ + \\underline v \\\\ &amp;= a' + b' \\cdot educ + \\underline {c' \\cdot X+ v'} \\end{align}\\) \\(\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\) (C를 잔차항에 포함된 교란인자 라고 가정) \\(\\bf educ = \\alpha + \\beta \\cdot \\underline {IV} + \\gamma \\cdot X + \\epsilon\\) 조작변수 \\(\\bf IV\\)의 조건 Exclusion restriction : IV는 원래의 결과부분에 해당하는 변수(Wage)에게 개입변수(설명변수, Education)를 통해서만 영향을 줄 수있다. No instrument-outcome confounder：IV와 원래의 결과부분에 해당하는 변수(Wage)에게 동시에 영향을 주는 공통의 원인(L 또는 X) 이 존재하지 않아야 한다 Instrument relevance : 개입변수(설명변수, Education)에게는 확실히 영향을 주는 변수여야 한다. Monotonicity : 조작변수가 역효과를 내는 사람(Defiers)이 존재하지 않아야 한다. (완전히 반대로 움직이는 케이스) 이상의 조건을 만족하는 조작변수를 발견해, 이를 통해 교란인자에 의한 효과를 제거한다. 【그러나, 이러한 조건을 만족하는 조작변수를 찾아내는 것은 매우 어렵고 특히 비즈니스 현장에서는 거의 불가능에 가깝다.】 - 그럼에도 불구하고 생각해보는 조작변수법(IV)의 활용 가능성 하지만 실제 개입에서는 개입의 대상이지만 따르지 않는 경우나 대상이 아니지만 따르는 경우와 같이 참가자가 개입의도와 반대로 움직이는 경우가 존재한다. 정책이나 치료와 같은 개입의 효과를 추정하기 위해서 개입의도대로 움직이는 부분집단만을 비교하는 것이 좋지 않을까 라는 이론 개입을 행하는 참가자의 의도를 1과 0을 갖는 dummy 조작변수 \\(z\\) 로 생각한다. \\(\\begin{equation}z= \\left \\{\\begin{array}{l}1 (개입의도 있음) \\\\0 (개입의도없음)\\end{array}\\right.\\end{equation}\\) \\(d = zd_1 + (1-z)d_0\\) (\\(d\\)는 \\(z\\)가 1일 때 \\(d_1\\)이 되고, \\(z\\)가 0일 때 \\(d_0\\)이 된다.) \\(\\begin{equation}d= \\left \\{\\begin{array}{l}1 (실행) \\\\0 (실행하지않음)\\end{array}\\right.\\end{equation}\\) \\(y=dy_1 + (1-d)y_0\\) (마찬가지로 \\(y\\)는 \\(d\\)가 1일 때 \\(y_1\\)이 되고, \\(d\\)가 0일 때 \\(y_0\\)이 된다.) 조작변수의 가정으로, \\(\\bf (y_0,y_1) \\perp z|d,\\space\\space\\space d_z \\perp z\\)를 만족한다 개입의도 \\(z\\) 참가자의 의사 \\(d\\) Notation 상황의 해석 1 1 \\(d_1\\) = 1 개입의 대상이 되어서 참가자가 개입의도에 맞게 따르는 경우 1 0 \\(d_1\\) = 0 개입의 대상이 되었지만 참가자가 개입의도에 따르지 않는 경우 (noncompliance) 0 1 \\(d_0\\) = 1 개입의 대상이 아님에도 불구하고 개입의도의 방향으로 움직이는 경우 0 0 \\(d_0\\) = 0 개입의 대상이 아니였기 때문에 개입의도에 따르지 않는 경우 - 국소적 평균효과(LATE; local average treatment effect) 정의 ; \\(\\Large LATE = E(y_1-y_0|d_1=1,d_0=0)\\) 의미 ; 개입의도의 방향대로 움직여주는 부분집합에서만 측정한 효과 [예시] 콜롬비아에서 이루어진 '바우쳐제도'는 학업성적 향상의 효과가 있었을까? [상황설명] - 바우쳐제도란, 제비뽑기로 장학생을 선정해서 사립 중학교의 수업료 절반을 부담해주는 제도이다. - 그러나 바우쳐제도 만으로 수업료를 감당하기 힘들어 제비뽑기에서 선발되어도 사립중학교의 입학을 포기하는 학생들이 존재했다. - 부모님들의 경제적능력이 좋거나 사립학교를 선호하는 학생들은 제비뽑기에서 떨어져도 사립학교에 입학했다. \\(\\begin{equation}z= \\left \\{\\begin{array}{l}1 (제비뽑기당첨) \\\\0 (제비뽑기탈락)\\end{array}\\right.\\end{equation}\\) \\(d = zd_1 + (1-z)d_0\\) \\(\\begin{equation}d= \\left \\{\\begin{array}{l}1 (사립학교진학) \\\\0 (공립학교진학)\\end{array}\\right.\\end{equation}\\) \\(y=dy_1 + (1-d)y_0\\) (성적) 여기서 우리가 궁금한 것은 [바우쳐제도] \\(\\bf \\rightarrow\\) [사립학교진학] \\(\\bf \\rightarrow\\) [성적향상] 의 인과스토리(causal story)를 가진 효과이다. 그러므로 우리가 관심있는 케이스는 제비뽑기에 붙으면 사립학교에 가고 떨어지면 공립학교에 진학할 학생 이다. 즉, 제비뽑기에 붙던 안붙던 사립학교에 갈 학생 (\\(d_1=1,d_0=1\\))이나 붙던 안붙던 공립학교에 갈 학생 (\\(d_1=0,d_0=0\\))은 고려의 대상이 아니다. 따라서, \\(ATE = E(y_1-y_0)\\) 를 구하면 단순히 사립학교와 공립학교의 성적 차이를 구하게 된다. 이 경우 \\(LATE = E(y_1-y_0|d_1=1,d_0=0)\\) 를 구하는 것이 바람직할 것이다. 이와 같이 준실험으로써의 조작변수법은 상당이 어렵지만 LATE 의 아이디어로써의 조작변수법은 생각해볼만 하다. * Reference 해당 포스트는 유튜브 채널「データの科学のメソドロジー」의 山田典一님의 강의를 틀로 내용을 정리 &amp; 추가 했음을 밝힙니다. 그 외 참조 調査観察データの統計科学―因果推論・選択バイアス・データ融（星野崇宏） 捜査変数法（一橋大学経済研究所, 北村 行伸） 操作変数法Instrumental variable methodsに関するブログ (津川友介)","link":"/2020/12/04/CN2/"}],"tags":[{"name":"causal","slug":"causal","link":"/tags/causal/"},{"name":"KMOOC","slug":"KMOOC","link":"/tags/KMOOC/"},{"name":"통계적 인과추론","slug":"통계적-인과추론","link":"/tags/%ED%86%B5%EA%B3%84%EC%A0%81-%EC%9D%B8%EA%B3%BC%EC%B6%94%EB%A1%A0/"}],"categories":[{"name":"KOR","slug":"KOR","link":"/categories/KOR/"},{"name":"통계적인과추론","slug":"KOR/통계적인과추론","link":"/categories/KOR/%ED%86%B5%EA%B3%84%EC%A0%81%EC%9D%B8%EA%B3%BC%EC%B6%94%EB%A1%A0/"},{"name":"ML","slug":"KOR/통계적인과추론/ML","link":"/categories/KOR/%ED%86%B5%EA%B3%84%EC%A0%81%EC%9D%B8%EA%B3%BC%EC%B6%94%EB%A1%A0/ML/"}]}