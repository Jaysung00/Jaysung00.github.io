{"pages":[{"title":"About this blog","text":"Japanese Ver. Data Science를 좋아하는 학생입니다.특히나, Causal Inference분야에 관심이 많습니다.R, python을 사용하고 있습니다.다양한 사람들과 소통하며 공부하기를 희망하고 있습니다. ・블로그 운영의 목적 스스로의 복습용 메모 주로 머신러닝의 응용처로써의 통계적 인과추론(Causal Inference)에 대해 학습한 내용을 정리합니다. 함께 공부하는 사람에 대한 내용 공유 한국과 일본의 학습자들과 공유하기 위해 모든 블로그 포스트는 한국어 버젼과 일본어 버젼 두가지로 작성하고 있습니다. 부족한 부분이 많습니다. 오타나 잘못된 내용을 발견하셨다면 댓글로 알려주세요.","link":"/About-this-blog/index.html"},{"title":"About this blog","text":"Korean Ver. Data Scienceが大好きな学生です。特に、Causal Inferenceの分野に興味を持っています。R, pythonを使っています。色んな方とコミュニケーションを取りながら学習することを願っています。 ・ブログの目的 自分自身の復習用のメモ 主に機械学習の応用先としての統計的因果推論(Causal Inference)について勉強した内容をまとめます。 他の学習者への内容共有 日本と韓国の学習者と共有するために全てのポストは、日本語バージョンと韓国語バージョンの二通りで作成しています。 まだまだ足りないところが沢山です。 誤字及び間違った内容が見つかりましたら、いつでもコメントください。","link":"/About-this-blog-jap/index.html"}],"posts":[{"title":"【Causal Inference①】인과추론의 목적과 RCT에 관하여","text":"* 인과추론(Causal Inference)으로 뭘 할 수 있는데? \"A 아이스크림을 공중파 CF에 내보냈을때, 해당 아이스크림의 매상은 얼마나 올랐을까?\" \"전 사원 대상 Python 연수 프로그램을 설치 했을때, 사원 들의 일의 능률은 얼마나 올랐을까?\" 이와 같은 질문들은 비즈니스에서 일상적으로 흔히 나올 수 있는 질문들이다. 하지만 이에 대해 깊은 고찰 없이 단순하게 효과를 정의하고 평가함 으로써, 우리는 수많은 바이어스 를 만들어 내고 있다. 공중파 CF의 효과를 계산하기 위해 단순히 CF 전후의 매상의 차이를 계산해서, CF와 관계없이 시기적으로 날씨가 더워져서 오른 맥주의 매상까지도 CF의 효과로써 평가해버린다. 또한 Python 연수를 신청한 사람들은 그렇지 않은 사원들보다 원래부터 우수한 사람이 많을수 있다. 원래부터 일의 능률이 높은 연수자그룹과 비연수자 그룹의 능률을 단순 비교해서 원래의 차이까지도 python연수의 효과로 평가해버린다. 이처럼 인과추론의 목적를 철저하게 비즈니스적 관점에서 보자면 어떠한 시책의 정확한 효과측정 을 위한 이론 &amp; 기술 분야라고 할 수 있다. * Inference 의 신뢰성의 3단계 Level 1. 실험(Experimental) 레벨 RCT (Randomized Controlled Trial; 무작위화 비교 실험) 3가지 기본요건 (1). 비교 : Control Group과 Treatment Group 의 비교를 통해 독립변수가 종속변수에 영향을 미쳤는지 확인하는 과정 (2). 조작 : 시간적으로 독립변수가 먼저 발생하고 그 후에 뒤따라 종속변수가 발생함을 입증하기 위해, 임의로 독립변수를 의도적인 시기에 발생하도록하고 이에 뒤따른 종속변수의 변화를 측정하도록 시간적 순서를 조작하는 것 (인과성의 선후관계) (3). 통제 : 허위적 관계가 아닌 것을 입증하기 위해, 독립변수를 제외한 종속변수에 영향을 미칠 수 있는 여러 변수들이 종속변수에 영향을 미치지 못하도록 상황을 의도적으로 통제하는 것 Level 2. 준실험(Quasi Experimental) 레벨 Level 1의 실험설계는 인과관계를 명확히 구명할 수 있지만, 인위적 통제가 어렵거나 윤리적 문제등으로 인해 (특히 비즈니스의 경우 제한된 예산 등에 의해) 실제 활용이 매우 어렵다. 이에 따라 비록 실험 설계에는 미치지 못하지만, 그 대안적인 방법으로 활용되는 방법이다. 대표적인 방법 (1). 시계열 설계(time-series design) : 비교집단을 별도로 설정하기 곤란한 경우에 하나의 집단 을 선택해서, 독립변수 도입의 전후상태를 비교하는 방법이다. 외적요인에 대한 통제가 어렵기 때문에 (각 기간마다 외부의 영향이 다르다), 위험이 있을 수 있다. 이를 개선하기 위해서는 같은 조사를 여러 집단에서 되풀이하여 실시하여 같은 결과를 얻을 수 있는지 확인할 필요가 있다. (2). 비동일 통제집단 설계(nonequivalent control group design) : 비동일 통제집단 설계는 실험설계의 통제집단 전후비교와 유사하지만 비교집단을 무작위로 선정하지 않는다 는 차이가 있다. 비동일 통제집단 설계는 무작위배치 이외의 방법(매칭, 기존집단의 선정 등)으로 Control Group 및 Treatment Group을 선정한다. 이외에도 변수조작법(IV) , 차의 차 분석(DID) , 경향스코어 매칭(PS) , 회귀불연속 디자인(RDD) 등이 있다. Level 3. 관찰(Observation) 레벨 독립변수를 조작할 수 없고, 연구대상을 무작위할 수 없는 경우 이다. 어느 한 시점에서 독립변수와 종속변수 모두를 측정해서 상관관계를 파악하는데에 그친다. 선후관계가 파악되지 않았고, 무작위화를 통해 동일한 집단에서 비교하지 못했으므로 부적절한 해석을 하게 될 위험을 가지고 있다. 확증편향 \\(^{[*1]}\\)(confirmation bias) 이나 사후해석편향 \\(^{[*2]}\\)(hindsight bias)에 영향을 받기 쉽다. 예를 들어, 시책 담당자가 좋은 결과만을 보고 싶다고 하면 집계의 방법을 유리하게 설정해서 유리한 결과가 나오도록 하는 것이 얼마든지 가능하므로 주의가 필요하다. Level 3은 Level 1&amp; Level 2를 한 후에 추가적으로 검토하는 용도. 또한, 집계의 방법을 미리 정해놓는 것을 통해, 자의적으로 변경해서 입맛에 맞는 해석을 하지 않는 것이 중요하다. ####【여기서 기억해야 할 것】 Lv1 \\(\\rightarrow\\) Lv2 \\(\\rightarrow\\) Lv3 의 순서로 시책의 효과를 검토해가는 것이 중요하다!! &lt;span style=\"font-size: 85%;&gt; \\(^{[*1]}:\\) 원하는 정보를 선택적으로 모으는 등의 가지고 있는 신념을 확인하려는 경향성. &lt;span style=\"font-size: 85%;&gt; \\(^{[*2]}:\\) 어떤 사건이 발생한 후, 사전에 그런 일이 일어날 것으로 예상했었다는 식으로 문제를 처리하는 것. 실제로는 벌어진 사건에 대해 전혀 대비를 하지 못하고, 그 원인을 냉정하게 규명해야 함에도 불구하고 \"충분히 예측했던 일\"이라며 자기 확신에 빠지는 것. * Potential Outcome Framework 처치(Treatment) 혹은 개입(Intervention)이 이뤄졌는지 여부 \\(\\begin{equation}Z_i= \\left \\{\\begin{array}{l}1 (Treated) \\\\0 (Untreated)\\end{array}\\right.\\end{equation}\\) 종속변수(DV; Dependent Variable) 혹은 목적변수(Criterion Variable) ; 개입을 받은 경우와 받지 않은 경우 두가지로 나타낼 수 있다. (실제로는 어느 한쪽만 관찰가능하지만) \\(\\begin{equation}Y_i= \\left \\{\\begin{array}{l}Y_i^{(1)} (Z_i = 1) \\\\Y_i^{(0)} (Z_i = 0)\\end{array}\\right.\\end{equation}\\) \\(\\Rightarrow Y_i = Y_i^{(0)}(1- Z_i) + Y_i^{(1)}Z_i\\) 이와 같이, 샘플 \\(i\\) 에 대하여 개입을 받은 경우의 결과 \\(Y^{(1)}\\) 와 받지 않은 경우의 결과 \\(Y^{(0)}\\) 간의 차이가 개입의 진정한 처치효과(TE; Treatment Effect) 라고 가정하는 것을 Potential Outcome Framework 라고 한다. \\(\\bf \\tau_{TE} = Y^{(1)}-Y^{(0)}\\) 모든 샘플 \\(i\\) 에 대해 각각의 처치효과를 구하는 것은 까다롭기 떄문에, 그룹간의 비교로써 평균처치효과(ATE; Average Treatment Effect) 를 다루는 경우도 많다. \\(\\bf \\tau_{ATE}= E[Y^{(1)}]-E[Y^{(0)}]\\) * Level 1. 실험레벨 ; 인과추론의 기초, RCT - RCT의 특징 비즈니스의 관점에서는 AB테스트 라고 할 수 있다. RCT (Randomized Controlled Trial; 무작위화 비교 실험)를 통해 Control Group과 Treatment Group을 무작위하게 나눔으로써 두 그룹간의 동질성 을 기대할 수 있다. 측정된 교란인자(confounding factors)\\(^{[*1]}\\)는 물론, 측정되지 않은 교란인자 에 대해서도 비교군과 대조군의 균형을 이룬다. (측정되지 않은 교란인자 까지 처리할 수 있는 실험디자인은 RCT와 완벽하게 설계된 조작변수법(IV), 분할시계열디자인(ITS) 밖에 존재하지 않는다.) 그로 인해 모든 연구 디자인 중 가장 높은 내적타당성\\(^{[*2]}\\)을 기대할 수 있다. 즉 RCT에서는 이론상, \\(ATU = ATT = ATE\\)을 기대할 수 있다. ( \\(ATU\\) (Average Treatment Effect on the Untreated) \\(= E[Y^{(1)}|Z=0] - E[Y^{(0)}|Z=0]\\) ) ( \\(ATT\\) (Average Treatment Effect on the Treated) \\(= E[Y^{(1)}|Z=1] - E[Y^{(0)}|Z=1]\\) ) ( \\(\\bf ATE\\) (Average Treatment Effect) \\(\\bf = E[Y^{(1)}] - E[Y^{(0)}]\\) ) [*] 위의 표에서 Control Group의 \\(Y_i^{(1)}\\)과 Treatment Group의 \\(Y_i^{(0)}\\)은 실제로 관찰 불가능한 반사실적 Potential Outcome 이다. - RCT의 의의 선택바이어스(Selection Bias) 의 제거 조작변수 이외의 다른 변수들을 통제하지 못한 채 Control Group과 Treatment Group 선택하게 되면, 그룹간의 동질성을 확보하지 못하여 교란변수(confounding factor) 에 의해 효과가 왜곡 될 수있다. 이러한 것을 선택 바이어스 라고 한다. RCT는 완전 무작위로 처치그룹을 선택하기 때문에 선택 바이어스 에서 자유로워질 수 있다. - RCT의 약점 (1). 비용(예산, 시간 등)이 많이 든다. (2). 외적타당성(일반화 가능성)\\(^{[*3]}\\) RCT에서는 비용의 문제로 인해 외부조건을 통제하게 되고 그로인해 외적타당성은 낮아질 수 있다. (3). noncompliance 문제 RCT에서 무작위로 그룹을 배분해도 거기에 따르지 않는 사람이 생겨서 나타나는 문제 (4). (특히 기업의 AB테스트에서) 다른 RCT를 같은 대상자에 겹쳐서 실행하게 될 경우, 그에 따른 바이어스가 생길 수 있다. 통계적으로 처리하기가 상당히 복잡해진다. &lt;span style=\"font-size: 85%;&gt; \\(^{[*1]}:\\) '원인'과 '결과' 양쪽 모두에게 공통의 원인이 되는 요인. Graphical Model에서 공통부모, 분기로 표현되는 부분. 내생성(Endogeneity)으로도 표현한다. &lt;span style=\"font-size: 85%;&gt; \\(^{[*2]}:\\) 다른 외생변수들이 종속변수에 영향을 주지 않고 진정한 독립변수 의 효과인가의 타당성. &lt;span style=\"font-size: 85%;&gt; \\(^{[*3]}:\\) 내적타당성을 높이기 위해 실험조건을 엄격히 통제한다면 일반화 가능성이 낮아질 수 있다. 얼마나 일반적 현실에 확장 가능한지의 타당성. * Reference 해당 포스트는 유튜브 채널「データの科学のメソドロジー」의 山田典一님의 강의를 틀로 내용을 정리 &amp; 추가 했음을 밝힙니다. 그 외 참조 効果検証入門〜正しい比較のための因果推論/計量経済学の基礎 （安井翔太） RCTをめぐる3つの問題とその解法（山口一男） 実験（Experiment）と疑似実験（Quasi-experiment）に関する記事(津川友介) http://blog.daum.net/sangrimza/15612241 https://m.blog.naver.com/PostView.nhn?blogId=lucifer246&amp;logNo=201407281&amp;proxyReferer=https:%2F%2Fwww.google.com%2F","link":"/2020/11/30/CI1/"},{"title":"【 도대체 베이지안 네트워크가 뭐야? ①】","text":"* 베이지안 네트워크(BN; Bayesian Network) 란? 확률 변수(RV; Random variables)들 사이의 조건부 독립 등의 관계를 보임으로써, RV의 full joint distribution등을 간결하게 표현할 수 있는 그래프 표기법 (Graphical Notation) 이다. 여기서 그래프(Graph) 란, 수학에서 차트(Chart)와 대조되어 정의된 node와 edge의 집합 edge가 방향이 지정되어 있으면 directed, 그렇지 않으면 undirected 그래프의 모든 edge가 directed일 때 directed graph directed edge에서, 시작되는 쪽의 노드를 parent node 라고 하고 반대쪽은 child node라고 한다 복수의 연결된 directed edge의 방향이 같은 경우 이를 directed path라고 하고, directed path의 첫 번째 노드는 경로상의 모든 노드들의 ancestor node이고, 반대로 나머지 노드들은 첫번째 노드의 descendant node이다. directed path의 시작점과 끝점이 일치할 경우 이를 cyclic이라 하고, 그렇지 않은 경우 acyclic라고 한다. 베이지안 네트워크(BN) 의 Syntax Network 는 Node와 이들을 연결시키는 Edge로 구성된다 방향성 비순환 그래프(DAG; Directed Acyclic Graph) 가 되어야 한다 개별 Node들은 RV인 \\(X\\)에 대해 \\(\\bf P(X | Paranets(X))\\)를 의미한다. 개별 Edge들은 부모가 자식에게 주는 직접적인 영향(Direct Influence) 을 의미한다. * 먼저 확률에 대한 간단한 복습부터 베이지안 네트워크 라는 것은 결국 확률변수(RV) 간의 관계 를 표현한 것이다. 확률 이라는 것은 상대적인 빈도 이다. 독립성 (Independence) \\(P(A|B) = P(A)\\) \\(\\Leftrightarrow P(A,B) = P(A)P(B)\\) \\(\\Leftrightarrow P(B|A) = P(B)\\); A와 B가 독립이면, B는 A와 독립이다. 사건B가 발생했다는 정보는 사건A가 발생할 확률에 추가적인 정보를 제공하지 못한다. 이는, 밑에 서술하는 Conditional Independence 와 대립되는 의미로 Marginal Independence 라고 할 수 있다. 조건부 독립 (Conditional Independence) \\(P(A|B,C) = P(A|C)\\) 사건C가 주어졌을 때 두 사건 A와 B가 독립인 경우, 이것은 C라는 조건하에서 조건부 독립 이다. 조건부 확률 (Conditional Probability) \\(P(A= true|B=true)\\) \"Probablity of A given B\" B가 주어졌을 때, A의 확률 결합 확률 (joint Probability) \\(P(A= true, B=true)\\) \"the probability of A=true and B=true\" A=true와 B=true가 동시에 만족할 확률 조건부 확률과 결합 확률의 관계 는 일반적으로, \\(P(X|Y) =\\cfrac{P(X,Y)}{P(Y)}\\) 총 확률 법칙 (Law of Total Probability) \"Summing out\" or \"Marginalization\" \\(P(A) = \\sum_kP(A,B_k) = \\sum_kP(A|B_k)P(B_k)\\) \\(P(A) = \\sum_kP(A,B_k)\\) 는 \\(B_1,B_2,...,B_n\\)이 각각 상호배반적인 집합이고 이들의 합집합이 전체집합이 되므로 성립 (marginalize) \\(\\sum_kP(A,B_k) = \\sum_kP(A|B_k)P(B_k)\\)는 조건부확률과 결합확률의 관계를 이용하면 유도가능 이로 인한 이점은, \\(P(A)\\)를 직접 구하는 것보다, \\(P(A|B_k)\\)와 같은 조건부확률을 구해서 합치는 것이 일반적으로 더 수월하다는 것이다. 혹은 결합확률을 알고 있을 때, 여러가지 확률을 계산 할 수 있다. 예를들어, 결합확률인 \\(P(a,b,c,d)\\)를 알고 있을 때, \\(P(c|b)\\)는 이렇게 표현할 수 있다 \\(P(c|b) = \\sum_a \\sum_d P(a,c,d|b) = \\cfrac{1}{P(b)}\\sum_a \\sum_d {\\bf P(a,b,c,d)}\\) 그러나 joint의 경우에는 parameter의 수가 exponential하게 늘어나게 된다! (Chain Rule의 필요성) 확률의 연쇄법칙 (Chain Rule for probability) 모든 joint distribution에 대해, 결합확률과 조건부확률의 관계에 의해 언제나 이하와 같이 표현할 수 있다. \\(P(a,b,c,...,z) = P(a|b,c,...,z)P(b,c,....,z)\\) 이것을 반복적으로 하면, \\(P(a,b,c,...,z) = P(a|b,c,...,z)P(b|c,...,z)P(c|d,...,z)...P(z)\\)로 표현 가능하다. (Factorization) 곱 분해 법칙 (Rule of product decomposition) Bayesian Network에서는 그래프에 속한 RV의 결합분포(joint distribution)는 family의 모든 조건부 분포 \\(P(Child|Parent)\\)의 곱\\(^{[*1]}\\)으로 표현 할 수 있다. (시리즈의 다음 포스트의 Factorization of Bayes Network 내용 참조) \\(P(x_1,x_2,...,x_n) = \\prod _iP(x_i|Parents(x_i))\\) Parents는 직접적으로 연결되어 영향을 받는 변수만을 의미! 예를 들어, \\(X\\rightarrow Y \\rightarrow Z\\) 인 그래프에서 \\(P(X=x, Y=y, Z=z)\\)를 구하는 것을 생각해보자 원래는 가능한 모든 조합의 \\((x, y, z)\\)에 해당하는 확률 테이블을 만들어야 한다 그러나, 이 법칙을 이용하면 \\(P(X=x, Y=y, Z=z) = P(X=x)P(Y=y|X=x)P(Z=z|Y=y)\\)로 간결하게 표현 가능 이처럼 고차원을 저차원으로 만들어 차원의 저주(curse of dimensionality) 에서도 비교적 자유로워 질 수 있다. &lt;span style=\"font-size: 85%;&gt; \\(^{[*1]}:\\) 이렇게 정의되는 원래는 뒤에서 기술하는 베이지안 네트워크의 Typical Local Structures Rules와 관련 되어있다. * 베이지안 네트워크의 Rules of Typical Local Structures Rule 1. 사슬 혹은 폭포형 (Chain or Cascading) 변수\\(X\\)와 변수\\(Y\\)의 사이에 하나의 방향성 경로 만 있고 변수\\(Z\\)가 해당 경로를 가로막고 있는 경우, \\(Z\\)가 조건부로 주어졌을때 두 변수 \\(X\\)와 \\(Y\\)는 조건부 독립 이다. \\(X \\perp Y|Z\\) \\(\\Leftrightarrow P(Y|X,Z) = P(Y|Z)\\) Rule 2. 분기 혹은 공통부모형 (Fork or Common parent) 변수 \\(Z\\)가 \\(X\\)와 \\(Y\\)의 공통 원인이고 \\(X\\)와 \\(Y\\)사이에 단 하나의 경로가 있는 경우, \\(Z\\)의 조건이 주어졌을 때 \\(X\\)와 \\(Y\\)는 조건부 독립 이다. \\(X \\perp Y | Z\\) \\(\\Leftrightarrow P(X,Y|Z) = P(X|Z)P(Y|Z)\\) Rule 3. 충돌부 혹은 V-구조 (Collider or V-structure) 변수 \\(Z\\)가 두 변수 \\(X\\)와 \\(Y\\) 사이의 충돌 노드이고 \\(X\\)와 \\(Y\\) 사이에 단 하나의 경로 만 있을 경우, \\(X\\)와 \\(Y\\)는 비조건부 독립(underconditionally independent) 이다. 그러나 \\(Z\\) 또는 \\(Z\\)의 descendant을 조건부로 하였을 때 \\(X\\)와 \\(Y\\)는 종속적일 가능성 이 있다. \\(\\sim (X \\perp Y|Z)\\) \\(\\Leftrightarrow P(X,Y,Z)=P(X)P(Y)P(Z|X,Y)\\) 즉 \\(Z\\)가 not given 일 때는 독립이지만, 반대로 \\(Z\\)가 given으로 주어지면 \\(X\\), \\(Y\\)가 종속적이 될 가능성이 생겨버린다. * Bayes Ball Algorithm 목적 ; \\(X \\perp Y | Z\\) (\\(Z\\)가 given일 때 \\(X\\)와 \\(Y\\)가 독립) 이 성립하는지 여부를 판정하기 위한 알고리즘 \\(X\\)에서 공이 출발한다고 가정했을 때 \\(Y\\)까지 공이 도달하는지 확인하는 방법 여기서 공은 Information을 의미하고 화살표는 공의 움직임을 의미한다. 노드 간이 직접적인 edge로 연결되어 있지 않더라도 공이 굴러가서 도달할 수 있다면 Indirect influence가 존재하기때문에 두 변수는 depedent하다는 것을 의미한다. Rule 1의 경우 (1). \\(Z\\)가 given이 아닐 때, 공은 지나갈 수 있다. (\\(X, Y\\)는 종속) (2). \\(Z\\)가 given 일 때, 공은 지나갈 수 없다. (\\(X \\perp Y|Z\\)) Rule 2의 경우 (1). \\(Z\\)가 given이 아닐 때, 공은 지나갈 수 있다. (\\(X, Y\\)는 종속) (2). \\(Z\\)가 given 일 때, 공은 지나갈 수 없다. (\\(X \\perp Y|Z\\)) Rule 3의 경우 (1). \\(Z\\)가 given이 아닐 때, 공은 지나갈 수 없다. (\\(\\bf X \\perp Y\\)) (2). \\(X_C\\)가 given 일 때, 반대로 path가 생겨서 공이 지나갈 수 있게 된다. (\\(X, Y\\)는 종속 \\(|Z\\)) Bayes Ball Algorithm 연습 문제 1. \\(X_1\\perp X_4|X_2\\) 두가지 경로로 공을 굴릴 수 있다. (1). \\(X_1 \\rightarrow {\\bf X_2}(given) \\rightarrow X_4\\) 의 경로는 \\(X_2\\)가 사슬의 given으로 막혀있으므로 지나갈 수 없다. (2). \\(X_1 \\rightarrow X_3 \\rightarrow X_5 \\rightarrow X_6 \\leftarrow {\\bf X_2}(given) \\rightarrow X_4\\) 의 경로는 \\(X_6\\)가 충돌부의 not given으로 막혀있으므로 지나갈 수 없다. 따라서 어떠한 경로로도 볼은 지나갈수 없으므로 \\(X_2\\)가 given일 때 \\(X_1\\)와 \\(X_4\\)는 독립 이다. 문제 2. \\(X_2\\perp X_5|X_1\\) 두가지 경로로 공을 굴릴 수 있다. (1). \\(X_2 \\rightarrow X_6 \\leftarrow X_5\\) 의 경로는 \\(X_6\\)가 충돌부의 not given으로 막혀있으므로 지나갈 수 없다. (2). \\(X_2 \\leftarrow {\\bf X_1}(given) \\rightarrow X_3 \\rightarrow X_5\\) 의 경로는 \\(X_1\\)가 분기의 given으로 막혀있으므로 지나갈 수 없다. 따라서 어떠한 경로로도 볼은 지나갈수 없으므로 \\(X_1\\)가 given일 때 \\(X_2\\)와 \\(X_5\\)는 독립 이다. 문제 3. \\(X_1\\perp X_6|\\{X_2, X_3\\}\\) 두가지 경로로 공을 굴릴 수 있다. (1). \\(X_1 \\rightarrow {\\bf X_2}(given) \\rightarrow X_6\\) 의 경로는 \\(X_2\\)가 사슬의 given으로 막혀있으므로 지나갈 수 없다. (2). \\(X_1 \\rightarrow {\\bf X_3}(given) \\rightarrow X_5 \\rightarrow X_6\\) 의 경로는 \\(X_3\\)가 사슬의 given으로 막혀있으므로 지나갈 수 없다. 따라서 어떠한 경로로도 볼은 지나갈수 없으므로 \\(\\{X_2, X_3\\}\\)가 given일 때 \\(X_1\\)와 \\(X_6\\)는 독립 이다. 문제 4. \\(X_2\\perp X_3|\\{X_1, X_6\\}\\) 두가지 경로로 공을 굴릴 수 있다. (1). \\(X_2 \\leftarrow {\\bf X_1}(given) \\rightarrow X_3\\) 의 경로는 \\(X_1\\)가 분기의 given으로 막혀있으므로 지나갈 수 없다. (2). \\(X_2 \\rightarrow {\\bf X_6}(given) \\leftarrow X_5 \\leftarrow X_3\\) 의 경로는 \\(X_6\\)가 충돌부의 given으로 뚫려있으므로 지나갈 수 있다. 따라서 두번째 경로로 볼은 지나갈 수 있으므로 \\(\\{X_1, X_6\\}\\)가 given일 때 \\(X_2\\)와 \\(X_3\\)는 독립이 성립하지 않는다. * \\(d\\)-Seperation의 정의 \\(d\\)는 방향성(directly)을 의미한다. Bayesian Ball Algorithm으로 \\(d\\)-Seperation을 확인할 수 있다. 정리하자면, 경로p가 조건부집합 \\(\\{W\\}\\)에 의해 \\(d\\)-Seperate된다는 명제는 이하와 필요충분조건이다. 경로p는 조건부집합 \\(\\{W\\}\\)에 속하는 중간노드 \\(Z\\) 의 사슬 \\(X \\rightarrow Z \\rightarrow Y\\) 또는 분기 \\(X \\leftarrow Z \\rightarrow Y\\) 를 포함한다. 경로p는 조건부집합 \\(\\{W\\}\\)에 속하지 않는 중간노드 \\(Z'\\) 의 충돌부 \\(X \\rightarrow Z' \\leftarrow Y\\) 를 포함한다. * Reference 해당 포스트는 Edwith에 개설된 문일철 교수님의 인공지능 및 기계학습 개론 II 강의를 정리 &amp; 추가한 내용임을 밝힙니다. 추가 내용 참조 의학 및 사회과학 연구를 위한 통계적 인과추론 （Judea Pearl, Madelyn Glymour, Nicholas P. Jewell）","link":"/2020/11/14/BN1/"},{"title":"【 도대체 베이지안 네트워크가 뭐야? ②】","text":"* Factorization of Bayes Network 그래프에 속한 RV의 결합분포(joint distribution)는 family의 모든 조건부 분포 \\(P(Child|Parent)\\)의 곱으로 표현 할 수 있다. \\(P(X_1,X_2,...,X_n) = \\prod _iP(X_i|Parents(X_i))\\) 곱 분해 법칙 (Rule of product decomposition) 확률의 연쇄법칙 \\(P(a,b,c,...,z) = P(a|b,c,...,z)P(b,c,....,z)\\)에서 사슬과 분기의 Rule에 따르면 부모노드가 given이면 이상은 조상노드는 전부 독립이게 되므로 성립. (충돌부는 부모노드가 아니다.) 즉, Bayes Network의 정보를 통해 joint distribution를 계산할 때 parameter의 갯수를 줄일 수 있다. \\([ 예시 ]\\) \\(P(X_1,X_2,X_3,X_4,X_5,X_6,X_7,X_8)\\)를 구한다고 하자. 확률의 연쇄법칙 (Chain Rule for probability) 에 의해 아무런 Bayesian Network의 정보가 없다고 하더라도 \\(P(X_1,X_2,X_3,...,X_8) = P(X_1|X_2,X_3,...,X_8)P(X_2|X_3,...,X_8)P(X_3|X_4,...,X_8)...P(X_8)\\) 로 Factorize 할 수 있다. 곱 분해 법칙 (Rule of product decomposition) 에 의해 Bayesian Network의 정보를 활용하면 \\(P(X_1,X_2,X_3,...,X_8) = P(X_1)P(X_2)P(X_3|X_1)P(X_4|X_2)P(X_5|X_2)P(X_6|X_3,X_4)P(X_7|X_6)P(X_8|X_5,X_6)\\) 로 훨씬 작은 parameter만으로 Factorize 가능하다. * Plate Notation \\(\\begin{align} P(D|\\theta) &amp;= P(X_1,...,X_N|\\mu,\\sigma) \\\\ &amp;= \\prod_i^N P(X_i|\\mu,\\sigma) \\end{align}\\) 이처럼 여러 개의 독립적인 RV들에 대해 위와 같이 Plate Notation 로 표현하는 것이 가능하다. * 베이지안 네트워크에서의 확률추론 BN에 있는 모든 random variables ; \\(X = \\{X1 ... X_N\\}\\) 주어진 증거 변수 (given evidence variables) ; \\(X_V =\\{X_{k+1}...X_N\\}\\) \\(x_V\\)는 evidence values 명시적으로 다루지는 않지만 관계가 있어서 감안할 필요가 있는 변수 (hidden variables) ; \\(X_H = X-X_V = \\{X_1...X_k\\}\\) hidden variables ; \\(X_H = \\{Y,Z\\}\\) \\(Y\\) : query variable (interested hidden variables) \\(Z\\) : uninterested hidden variables 1-1 주변확률 (Marginal Probability) 증거 변수 \\(X_V\\) 의 주변확률 (Marginal Probability) \\(P(x_V)\\) 는? \\(\\begin{align} P(x_V) &amp;=\\sum_{X_H}P(X)=\\sum_{X_H}P(X_H,X_V) \\space\\space\\space\\space\\space\\space\\dots(1)\\\\ &amp;= \\sum_{x_1}...\\sum_{x_k}P(x_1...x_k,x_V)\\space\\space\\space\\space\\space\\space\\space\\space\\space\\dots(2) \\end{align}\\) (1). 모든 변수에 대해 full joint 된 것을 \\(X_H\\)로 marginalize out한 것이라고 생각한다. (2). 각각의 Hidden variable에 대해 marginalize out한 것이라고 생각한다. 1-2. 조건부 확률 (Conditional Probability) 주어진 증거(evidence)의 집합\\(x_V\\)이 있을때, query variable(주어지지 않았지만 관심있는 변수) 의 조건부 확률 \\(P(Y|x_V)\\)은? \\(\\begin{align} P(Y|X_V) &amp;= \\sum_ZP(Y,Z = z|x_V) \\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\dots(1)\\\\ &amp;= \\sum_Z\\cfrac{P(Y,Z,x_V)}{P(x_V)} = \\sum_Z\\alpha P(X) \\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\dots(2)\\\\ &amp;= \\sum_Z \\cfrac{P(Y,Z,x_V)}{\\sum_{y,z}P(Y=y, Z=z, x_V)}\\space\\space\\space\\space\\space\\space\\space\\space\\space\\dots(3) \\end{align}\\) (1). \\(Z\\)를 joint로 넣어주면서 \\(Z\\)에 대해 marginalize out 한다. (2). 조건부 확률의 정의를 이용해, \\(x_V\\)를 포함한 full joint 를 \\(P(x_V)\\) (Marginal Probability)로 나눈다. (\\(\\cfrac{1}{P(x_V)} = \\alpha\\)라는 정규화 상수(normalization constant)의 곱으로 생각할수도 있다.) (3). 분모의 주변확률은 Inference Question1처럼 full joint 를 모든 Hidden variable에 대해 marginalize 해서 구할 수 있다. * 변수제거 알고리즘 (Variable Eliminatation Algorithm) 위와 같이 주어진 상황에서 변수제거 알고리즘으로 \\(P(J=j)\\)를 구해보자 * Step1 위의 준비를 통해 베이지안 네트워크 상에서 관심있는 확률의 추론을 위해서, full joint 를 구하고 uninterested hidden variable에 대해 Marginalize 한다. \\(\\sum_{A,E,B,M} P(J= j,A,E,B,M)\\) * Step2 full joint 를 Bayesina Network의 정보를 이용해 곱분해 법칙으로 바꿔 쓴다. 분해한 곱의 나열순서는 topological order \\(^{[*1]}\\) 를 따른다. topological order ; B, E, A, J, M \\(\\sum_{B,E,A,M} P(B)P(E)P(A|B,E)P(J=j|A)P(M|A)\\) &lt;span style=\"font-size: 85%;&gt; \\(^{[*1]}:\\) 들어오는 화살표가 없는 노드 부터 하나씩 선택하며 지우는 것을 반복할때 결정되는 순서 * Step3 순서를 유지한 채 각 \\(\\sum\\)가 관련없는 것을 밖으로 빼낸다. 제거할 변수의 순서는 뒤에서부터 정해진다. \\(\\space\\space\\space\\sum_B P(B)\\sum_EP(E)\\sum_AP(A|B,E)P(J=j|A)\\sum_MP(M|A)\\) * Step4 뒤에서 부터 function notation으로 바꿔주면서 변수를 지워나간다. \\(\\space\\space\\space\\sum_B P(B)\\sum_EP(E)\\sum_AP(A|B,E)P(J=j|A) \\underline {\\sum_MP(M|A)}\\) \\(=\\sum_B P(B)\\sum_EP(E)\\sum_AP(A|B,E)P(J=j|A) \\underline {\\bf f_1(A)}\\) 밑줄친 부분은 J와 \\(d\\)-seperate이기 때문에 고려할 필요가 없다. 즉, A의 값과 상관없이 \\(f_1(A)\\)는 1을 갖는다. \\(=\\sum_B P(B)\\sum_EP(E)\\underline{\\sum_AP(A|B,E)P(J=j|A)}\\) \\(=\\sum_B P(B)\\sum_EP(E)\\underline {\\bf f_2(E,B)}\\) \\(f_2(E,B)\\)는 이하와 같다. \\(=\\sum_B P(B)\\underline {\\sum_EP(E)f_2(B,E)}\\) \\(=\\sum_B P(B) \\underline {\\bf f_3(B)}\\) \\(f_3(B)\\)는 이하와 같다. \\(= \\sum_BP(B)f_3(B)\\) \\(= P(B=b)f_3(B=b) + P(B= \\sim b)f_3(B=\\sim b)\\) \\(=0.001 * 0.849017 + 0.999 * 0.0513413 \\fallingdotseq 0.052139\\) 따라서, \\(P(J=j) = 0.052139\\) 가 된다. * Reference 해당 포스트는 Edwith에 개설된 문일철 교수님의 인공지능 및 기계학습 개론 II 강의를 정리 &amp; 추가한 내용임을 밝힙니다. 추가 내용 참조 https://www.youtube.com/watch?v=TZnEJ4wvLPY 의학 및 사회과학 연구를 위한 통계적 인과추론 （Judea Pearl, Madelyn Glymour, Nicholas P. Jewell）","link":"/2020/11/14/BN2/"},{"title":"【Causal Inference②】조작변수법(IV)에 관하여","text":"* RCT를 사용할 수 없을 때는 어떻게 할까? Level 1. 실험(Experimental) 레벨 (개입연구) 관찰자(해석자)가 개입의 계획을 세워서 데이터를 수집 \\(\\rightarrow\\) RCT (무작위화비교실험) \\(\\blacktriangleright\\) Level 2. 준실험(Quasi Experimental) 레벨 비교적 질 좋은 관찰연구 정도의 느낌 실험데이터가 아니라 관찰데이터 를 사용해서, 개입의 여부 등으로 결과에의 영향을 추정 측정되지 않은 교란인자를 처리할 수 있는 것은 사실상 RCT만이 쉽게 가능하지만, 모든 교란인자를 충분히 측정할 수 있다고 하면 준실험설계로도 충분히 인과관계를 설명할 수 있다. 변수조작법(IV) , 차의 차 분석(DID) , 경향스코어 매칭(PS) , 회귀불연속 디자인(RDD) 등이 있다. Level 3. 관찰(Observation) 레벨 더욱 인과추론 하기에 취약한 관찰연구 디자인 \\(I\\). 조작변수법 (IV; Instrumental variable methods) - 조작변수법이란? 매우 어렵지만 이론상 완벽하게 설계된다면 측정되지 않은 교란인자 도 처리할 수 있는 방법. 외생변수 ; 모델의 밖에서 결정되어 주어진 변수 (설명변수로써 바람직하다). 모델의 잔차항 과 독립하게 된다. 내생변수 ; 모델 내에서 결정되는 변수 (설명변수로써 바람직하지 않다). 예를 들어 측정되지 않은 교란인자 가 있는 경우 영향을 받는 설명변수와 모델의 잔차항 사이에 상관 관계가 생겨버리고 이 설명변수는 내생변수 가 되어 내생성 바이어스 를 만든다. 이렇게 발생된 내생변수 를 외생화 하기 위해 도입된 변수 \\(Z\\)를 조작변수(IV) 라고 한다. 이러한 조작변수를 이용해, 설명변수가 결과에 미치는 영향을 평가하는 방법을 조작변수법 이라고 한다. \\([ 예시 ]\\) - 참의 관계 : \\(ln(wage) = a + b \\cdot educ + c \\cdot ability + u\\) 임금(Wage)와 교육년수(Education)와 능력(Ability)은 위와 같은 관계가 있다고 가정한다. 그러나 능력은 실제로 측정불가하기 때문에 교육수준만으로 임금과의 관계를 설명하는 모델을 했다고 하자. \\(ln(wage) = a' + b' \\cdot educ + v\\) 이 때, 능력(Ability)은 관측되지 않은 교란인자 가 되고 계수 \\(b'\\)에는 내생성 바이어스가 존재하게 된다. - 조작변수법의 과정 내생변수 를 피설명변수로 별도의 조작변수 \\(IV\\)를 통해 설명하는 모델을 작성한다. \\(\\begin{align} ln(wage) &amp;= a' + b' \\cdot educ + \\underline v \\\\ &amp;= a' + b' \\cdot educ + \\underline {c' \\cdot X+ v'} \\end{align}\\) \\(\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\) (C를 잔차항에 포함된 교란인자 라고 가정) \\(\\bf educ = \\alpha + \\beta \\cdot \\underline {IV} + \\gamma \\cdot X + \\epsilon\\) 조작변수 \\(\\bf IV\\)의 조건 Exclusion restriction : IV는 원래의 결과부분에 해당하는 변수(Wage)에게 개입변수(설명변수, Education)를 통해서만 영향을 줄 수있다. No instrument-outcome confounder：IV와 원래의 결과부분에 해당하는 변수(Wage)에게 동시에 영향을 주는 공통의 원인(L 또는 X) 이 존재하지 않아야 한다 Instrument relevance : 개입변수(설명변수, Education)에게는 확실히 영향을 주는 변수여야 한다. Monotonicity : 조작변수가 역효과를 내는 사람(Defiers)이 존재하지 않아야 한다. (완전히 반대로 움직이는 케이스) 이상의 조건을 만족하는 조작변수를 발견해, 이를 통해 교란인자에 의한 효과를 제거한다. 【그러나, 이러한 조건을 만족하는 조작변수를 찾아내는 것은 매우 어렵고 특히 비즈니스 현장에서는 거의 불가능에 가깝다.】 \\(I-I.\\) 처치의도에 의한 분석 (Intention to treat analysis) \\(\\space\\space\\space\\space\\space\\) - 그럼에도 불구하고 생각해보는 조작변수법(IV)의 활용 가능성 - 실제 개입에서는 개입의 대상이지만 따르지 않는 경우나 대상이 아니지만 따르는 경우와 같이 참가자가 개입의도와 반대로 움직이는 경우가 존재한다. '정책이나 치료와 같은 개입의 효과를 추정하기 위해서 개입의도대로 움직이는 부분집단만을 비교하는 것이 좋지 않을까' 라는 이론 개입을 행하는 참가자의 의도를 1과 0을 갖는 dummy 조작변수 \\(z\\) 로 생각한다. \\(\\begin{equation}z= \\left \\{\\begin{array}{l}1 (개입의도 있음) \\\\0 (개입의도없음)\\end{array}\\right.\\end{equation}\\) \\(d = zd_1 + (1-z)d_0\\) (\\(d\\)는 \\(z\\)가 1일 때 \\(d_1\\)이 되고, \\(z\\)가 0일 때 \\(d_0\\)이 된다.) \\(\\begin{equation}d= \\left \\{\\begin{array}{l}1 (실행) \\\\0 (실행하지않음)\\end{array}\\right.\\end{equation}\\) \\(y=dy_1 + (1-d)y_0\\) (마찬가지로 \\(y\\)는 \\(d\\)가 1일 때 \\(y_1\\)이 되고, \\(d\\)가 0일 때 \\(y_0\\)이 된다.) 조작변수\\(z\\)의 가정 \\(\\bf (y_0,y_1) \\perp z|d,\\) : 변수 \\(d\\)에 의해 \\(z\\)와 \\(y\\)가 \\(d\\)-seperate 되므로 Exclusion restriction 와 No instrument-outcome confounder 만족 \\(\\bf d_{i1} \\geq d_{i0}\\) : Monotonicity 만족 (제비에 뽑히면 공립에 가고, 제비에 떨어지면 사립에 가는 Defiers는 존재하지 않는다고) (\\(d\\)와 \\(z\\)의 정의에 의해 Instrument relevance는 자동으로 만족) 설계자의 의도 \\(z\\) 참가자의 의사 \\(d\\) Notation 상황의 해석 1 1 \\(d_1\\) = 1 개입의 대상이 되어서 참가자가 개입의도에 맞게 따르는 경우 1 0 \\(d_1\\) = 0 개입의 대상이 되었지만 참가자가 개입의도에 따르지 않는 경우 (noncompliance) 0 1 \\(d_0\\) = 1 개입의 대상이 아님에도 불구하고 개입의도의 방향으로 움직이는 경우 (noncompliance) 0 0 \\(d_0\\) = 0 개입의 대상이 아니였기 때문에 개입의도에 따르지 않는 경우 - 국소적 평균효과(LATE; local average treatment effect) 정의 ; \\(\\Large LATE = E(y_1-y_0|d_1=1,d_0=0)\\) 의미 ; 개입의도의 방향대로 움직여주는 부분집합에서만 측정한 효과 - LATE의 추정 조작변수 \\(z\\)의 가정에 의해, \\(\\begin{align} E(y|z=1) - E(y|z=0) &amp;= E(dy_1+(1-d)y_0|z=1) - E(dy_1+(1-d)y_0| z=0)\\\\ &amp;= E(d_1y_1+(1-d_1)y_0|z=1)-E(d_0y_1+(1-d_0)y_0|z=0) \\\\ &amp;= E(d_1y_1 + (1-d)y_0)-E(d_0y_1 + (1-d_0)y_0)\\\\ &amp;= E((d_1-d_0)(y_1-y_0)) \\\\ &amp;\\space \\\\ &amp;\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\cdots d_1-d_0는\\space\\{-1,0,1\\},\\space\\space Monotonicity가정에\\space\\space의해\\space\\space p(d_1-d_0=-1)=0 \\space\\space 이므로\\\\ &amp;\\space \\\\ &amp;=\\sum_{a=-1,0,1}aE(y_1-y_0|d_1-d_0 = a)p(d_1-d_0 = a) \\\\ &amp;= \\underline {E(y_1-y_0|d_1-d_0=1)} \\space p(d_1-d_0=1) \\end{align}\\) 위 식의 우변에 \\(E(y_1-y_0|d_1-d_0=1)\\)가 \\(\\bf LATE\\) 의 정의가 되므로, \\(\\begin{align} {\\bf LATE} &amp;= E(y_1-y_0|d_1-d_0=1) \\\\ &amp;\\space \\\\ &amp;= \\cfrac{E(y|z=1) - E(y|z=0)}{p(d_1-d_0=1)} \\\\&amp;\\space \\\\ &amp;= \\cfrac{E(y|z=1) - E(y|z=0)}{ p(d_1=1,d_0=0)} \\\\ &amp;\\space \\\\ &amp;= \\cfrac{E(y|z=1) - E(y|z=0)}{\\{p(d_1=1,d_0=1) + p(d_1=1,d_0=0)\\} - p(d_0=1,d_1=1)} \\\\ &amp;\\space \\\\ &amp;= \\cfrac{E(y|z=1) - E(y|z=0)}{p(d_1=1)-p(d_0=1)} \\\\ &amp;\\space \\\\ &amp;= {\\bf \\cfrac{E(y|z=1) - E(y|z=0)}{E(d|z=1)-E(d|z=0)}} \\end{align}\\) 로 바꿔쓰는 것이 가능해, 이것은 \\(z\\)가 2진변수(binary variable)인 경우의 조작변수추정량 과 같고, \\(\\bf LATE\\)는 이것으로 추정가능하게 된다. [예시] 콜롬비아에서 이루어진 '바우쳐제도'는 학업성적 향상의 효과가 있었을까? [상황설명] - 바우쳐제도란, 제비뽑기로 장학생을 선정해서 사립 중학교의 수업료 절반을 부담해주는 제도이다. - 그러나 바우쳐제도 만으로 수업료를 감당하기 힘들어 제비뽑기에서 선발되어도 사립중학교의 입학을 포기하는 학생들이 존재했다. - 부모님들의 경제적능력이 좋거나 사립학교를 선호하는 학생들은 제비뽑기에서 떨어져도 사립학교에 입학했다. [가정 (실제 데이터가 아님) ] - 1,000명의 학생이 제비를 뽑아 당첨된 학생은 300명이였다. - 제비에 당첨된 300명의 학업성적의 평균은 80점 - 제비에 당첨되지 않은 700명의 학업성적은 60점 - 제비에 당첨됐을 때 사립학교에 진학학 확률은 90% - 제비에 당첨되지 않았음에도 사립학교에 진학할 확률은 15% \\(\\begin{equation}z= \\left \\{\\begin{array}{l}1 (제비뽑기당첨) \\\\0 (제비뽑기탈락)\\end{array}\\right.\\end{equation}\\) \\(d = zd_1 + (1-z)d_0\\) \\(\\begin{equation}d= \\left \\{\\begin{array}{l}1 (사립학교진학) \\\\0 (공립학교진학)\\end{array}\\right.\\end{equation}\\) \\(y=dy_1 + (1-d)y_0\\) (성적) 여기서 우리가 궁금한 것은 [바우쳐제도] \\(\\rightarrow\\) [사립학교진학] \\(\\rightarrow\\) [성적향상] 의 인과스토리(causal story)를 가진 효과이다. 그러므로 우리가 관심있는 케이스는 제비뽑기에 붙으면 사립학교에 가고 떨어지면 공립학교에 진학할 학생 이다. 즉, 제비뽑기에 붙던 안붙던 사립학교에 갈 학생 (\\(d_1=1,d_0=1\\))이나 붙던 안붙던 공립학교에 갈 학생 (\\(d_1=0,d_0=0\\))은 고려의 대상이 아니다. 따라서, \\(ATE = E(y_1-y_0)\\) 를 구하면 단순히 사립학교와 공립학교의 성적 차이를 구하게 된다. 이 경우 \\({\\bf LATE} = E(y_1-y_0|d_1=1,d_0=0)\\) 를 구하는 것이 바람직할 것이다. \\({\\bf LATE}\\)의 추정 \\(E(y|z=1) = 80\\) \\(E(y|z=0) = 60\\) \\(E(d|z=1) = 0.9\\) \\(E(d|z=0) = 0.15\\) \\(\\begin{align} LATE &amp;= \\cfrac{E(y|z=1) - E(y|z=0)}{E(d|z=1)-E(d|z=0)}\\\\ &amp;\\space \\\\ &amp;= \\cfrac{80-60}{0.9-0.15} \\fallingdotseq 26.6666 \\end{align}\\) 국소적 평균효과(LATE)의 관점에서 26.66점의 성적향상효과가 있었다고 추정할 수 있다. 【결론】이와 같이 준실험으로써의 조작변수법은 상당이 어렵지만 \\(\\bf LATE\\) 의 아이디어로써의 조작변수법은 생각해볼만 하다. * Reference 해당 포스트는 유튜브 채널「データの科学のメソドロジー」의 山田典一님의 강의를 틀로 내용을 정리 &amp; 추가 했음을 밝힙니다. 그 외 참조 調査観察データの統計科学―因果推論・選択バイアス・データ融（星野崇宏） 捜査変数法（一橋大学経済研究所, 北村 行伸） 操作変数法Instrumental variable methodsに関するブログ (津川友介)","link":"/2020/12/04/CN2/"},{"title":"【Uplift Modeling】변수의 선택방법에 대하여","text":"해당 포스트는 Zhenyu Zhao at el. \"Feature Selection Methods for Uplift Modeling\" (2020)의 내용을 번역 및 정리한 내용임을 밝힙니다. * Introduction feature selection 방법은 각 feature에 대해 중요도 점수(importance score)를 계산한 뒤 점수를 바탕으로 랭크를 매긴다. Uplift model은 이렇듯 가장 중요하다고 판단된 변수들만을 가지고 만들어 질 수 있다. Uplift modeling에서 중요한 변수들에게만 집중하는 것은 몇가지의 이득을 가져다 준다. (1). 훈련을 위한 빠른 계산처리 (2). overfitting 문제를 피함으로써 더욱 정확한 예측이 가능 (3). 데이터 파이프라인의 낮은 유지비용 (4). 더욱 쉬운 모델 해석과 진단 이렇듯 feature selection은 Uplift modeling에 있어서 중요한 문제임에도 불구하고 지금까지 관련 문헌에서 거의 논의되어오지 못했다. 전통적인 머신러닝에 있어서의 변수선택방법의 연구는 V. Bolon-Canedo et al.(2013), G. Chandrashekar &amp; F. Sahin(2014), J. Tang(2014)과 같은 논문들에서 잘 논의되어있지만, 이것들은 Uplift modeling에서 최적의 변수선택 방법은 아니다. 이 논문에서는 방법론적이고 경험적인 평가 관점에서 변수선택을 다룬다. * 일반적인 변수선택 방법과의 관계 일반적인 변수선택법의 종류 filter methods wrapped methods embedded methods 일반적인 변수선택법이 Uplift modeling에서 최선이 아닌 이유 분류문제를 생각했을때 일반적 변수선택법의 목적은 feature에 기반하여 outcome이 각 클래스에 해당될 확률의 예측하는 것이다. 그러므로 feature의 중요도는 클래스 확률과 관계가 깊다. 반면에 Uplift model의 목적은 CATE를 예측하는 것이다. 그러므로 여기서 좋은 feature는 클래스 확률이 아니라 치료효과를 예측할 수 있게 해주는 것이어야 한다. 이 두가지 예측대상이 항상 일치할 필요는 없으므로 Uplift modeling에서 일반적 변수선택법은 최선이 아닐 수 있다. * uplift modeling을 위한 변수선택 방법 A. Filter Methods 이 방법은 각 feature에 대하여 치료효과와 feature간의 한계관계(marginal relationship)를 기반으로 중요도 점수(Importance score)를 계산한다. 이것은 한번에 하나의 feature에 대한 간단한 계산만 이루어지므로 빠른 전처리 단계이다. - F filter 치료여부변수와 확인하고자하는 feature 그리고 그들의 교호작용항(interaction term)을 사용하여 outcome변수를 예측하는 선형회귀모델이다. 중요도 점수(importance score)는 교호작용항의 계수에 대한 F-통계값 으로 정의된다. 이 통계값이 크면 해당 feature는 강한 heterogeneous treatment effect와 상관이 있다는 것을 의미한다. - LR filter (Likelihood ratio) 여기서는 로지스틱 회귀모형의 교호작용항 계수에 대한 likelihood ratio 검정 통계량으로 정의한다. - Filter method with K bins 여기에는 Piotr Rzepakowski &amp; Szymon Jaroszewicz (2012)에서 제안된 uplift tree의 분할기준으로 부터 세가지 방법이 존재한다. 주어진 feature에 대해 이 방법은 먼저 샘플을 feature의 백분위를 기준으로 K개의 bin으로 나눈다. (여기서 K는 하이퍼파라미터) 중요도 점수는 이러한 K개의 bins에 대한 처리효과의 divergence measure로 정의된다. 구체적으로, outcome 변수에 C개의 클래스가 있다고 가정해보자. \\(P_k = (p_{k1},...,p_{kC})\\) 와 \\(Q_k = (q_{k1},...,q_{kC})\\)가 각각 치료군과 대조군의 \\(k\\)번째(\\(k=1,...,K\\)) bin에서의 클래스별 sample의 비율이라고 했을 때, 중요도 점수는 이하와 같이 정의된다. \\(\\Delta = \\sum^K_{k=1}\\cfrac{N_k}{N}D(P_k:Q:k)\\) \\(N_k\\) : \\(k\\)번째 bin의 샘플사이즈 \\(N\\) : 전체 샘플 사이즈 \\(D\\) : distribution divergence - Kullback-Leibler divergence (denoted as KL ) - the squared Euclidean distance(denoted as ED ) - the chi-squared divergence (denoted as \\(\\chi^2\\) ) \\(KL(P_k:Q_k)=\\sum^n_{i=1}p_{ki}log\\cfrac{p_{ki}}{q_{ki}}\\) \\(ED(P_k:Q_k)=\\sum^n_{i=1}(p_{ki}-q_{ki})^2\\) \\(\\chi^2(P_k:Q_k)=\\sum^n_{i=1}\\cfrac{(p_{ki}-q_{ki})^2}{q_{ki}}\\) B. Embedded Methods 이 방법은 uplift model를 훈련시킬 때 나오는 부산물로 변수의 중요성을 얻는다. 이것은 meta-learner과 uplift tree 둘다에서 얻어질 수 있다. - Meta-learner feature 중요도는 base-learner로 부터 얻어진다. 예를 들어 Two Model approach 에서는 feature의 중요도점수는 두 base-learner가 산출한 embedding된 중요도 점수의 합으로 정의될 수 있다. - Uplift tree feature에 대한 중요도 점수는 Tree에서 Tree node가 분할되는 동안의 손실함수에 대한 누적기여로 정의할 수 있다. 이는 대상이 특별한 분할 기준이 있는 Uplift tree라는 점을 제외하면 일반적으로 잘 알려진 classification tree의 embedded feature 중요도와 유사하다. 각 분할에서 우리는 distribution divergence 의 증가분(gain) 을 계산한다. \\(\\Delta = \\sum_{k=left,\\space right} D(P_k:Q_k)- D(P:Q)\\) (\\(P,Q\\)는 각각 치료군과 대조군의 Outcome distribution) feature의 중요도 점수는 해당 feature가 사용된 노드 분할로 부터 발생하는 모든 \\(\\Delta\\)를 더하는 것으로 계산할 수 있다. 이후 생략된 내용 ; 위에서 소개한 변수선택 방법들의 평가 (synthetic data &amp; real-world data), 논문이 실제 적용에서 추천하는 방법 등","link":"/2020/12/17/Selection/"},{"title":"【Uplift Modeling】도입의 배경에 대해 생각해보자","text":"해당 포스트는 Towards data science 에 게재된 블로그 'Uplift Modeling: A Quick Introduction'의 내용을 정리 &amp; 추가한 내용임을 밝힙니다. * Introduction \"누가 미래에 구매를 할 것 같은가 ?\" 고전적인 경향성 모델(propensity model) 이 하는 것은 원래 구매로 이어지려고 한 고객을 머신러닝을 이용해 발견해낼 뿐이다. 이러한 모델은 원래 구매를 하려고 했었던 고객과 캠페인에 의해 구매설득이 필요한 고객을 구분하지 않는다. 이번엔 새롭게 캠페인(treatment) 을 통한 프로모션을 한다고 생각해보자. 과연 누구를 타겟으로 해야할까. \"어떠한 고객이 캠페인을 통한 매상이 높을 것 인가?\" 위와 같은 질문을 기준으로 기댓값이 높은 사람을 타겟으로 할 수 있을 것이다. 이것을 예측해서 타겟팅을 하는 모델을 Outcome model 이라고 할 수있다. 즉, 타겟변수를 \\(Outcome = P(buy|treatment)\\) 로 설정한 것이다. \"캠페인이 고객에게 실제 우리회사 제품의 구매를 유발했나 ?\" \" 이미 사려고 했던 사람에게 캠페인을 하는 낭비 를 하지는 않았나?\" \"캠페인이 누군가의 구매를 더욱 악화 시키지는 않았나?\" 그러나 Uplift modeling 은 위와 같은 더욱 중요한 질문에 답하고자 한다. 이것은 타겟변수를 \\(Lift = P(buy|treatment) - P(buy|no treatment)\\)로 둔 것 과 같다. 위의 그림 (Yi and Frost 2018a) 과 같이 고객이 캠페인의 대상이 되는지 여부와 그에 따른 고객의 행동에 따라 4가지 세그먼트로 고객의 타입을 분류할 수 있다. 'persuadables' : 마케팅 캠페인에 노출이 되면 구매를 하지만 노출되지 않으면 구매하지 않는 그룹 \\(Lift = P(buy|treatment) - P(buy|no treatment) = 1\\) 'sure things' : 캠페인과 관계없이 어짜피 구매할 예정인 그룹 \\(Lift = P(buy|treatment) - P(buy|no treatment) = 0\\) 'lost causes' : 캠페인과 관계없이 어짜피 구매하지 않을 그룹 \\(Lift = P(buy|treatment) - P(buy|no treatment) = 0\\) 'sleeping dogs' : 캠페인에 노출되지 않으면 구매하지만 오히려 노출될 경우 구매를 하지 않게되는 그룹 ('이런 광고에 돈을 쓰는 회사의 제품을 구매하고 싶지 않아!' 혹은 '나의 프라이버시가 이용되는 곳에 돈을 쓰고 싶지 않아!' 등과 같은 이유) \\(Lift = P(buy|treatment) - P(buy|no treatment) = -1\\) 모든 고객들에 대해 소속된 세그먼트를 미리 알 수 있는 이상적인 세계가 존재한다면, 그에 따라 'Persuadables' 세그먼트의 고객들만 타겟에 넣고 'Sleeping dogs' 세그먼트는 절대 고객은 넣지 않을 것이다. 그러나 현실에서는 각 고객이 어느 세그먼트의 고객인지 아는 것은 불가능하다. 그 대신, 통계의 힘과 머신러닝으로 해당고객과 \"비슷한 고객\"이 평균적으로 어느 세그먼트에 속해 있는지 는 알 수 있을 것이다. 이것이 Uplift modeling이 우리에게 알려주는 것이다. 모든 개인은 -1 부터 1 사이의 lift값을 갖게 되고 우리는 이 값을 통해 타겟을 결정할 것이다. 만약 모델이 정확하다면, 높은 lift값을 가진 고객에게 더 높은 캠페인 효과를 기대할 수 있을 것이고 낮은 lift값의 고객에게는 낮은 캠페인 효과가 나타날 것이다. * Uplift modeling의 접근방법 Uplift modeling은 특정고객에게 캠페인을 제공하는것이 이득인지 아닌지를 결정하는 task를 위해 만들어졌고, 이것은 어떤 고객이 어떤 세그먼트에 속하는지 결정하는 모델을 만드는 것 이며, 결과적으로 마케팅 수단이 고객의 구매로 이어지는 확률을 결정하는 것을 돕는 모델링 이다. 이러한 Uplift modeling은 여러가지 접근 방법으로 연구되어오고 있다. 다른 포스팅에서 이러한 다양한 접근방법에 대해 자세히 다루게 될 것이다.","link":"/2020/12/17/UM-overview/"},{"title":"【Uplift Modeling】Uplift tree에 관한 논문 내용 번역","text":"해당 포스팅은 Tree-based Uplift Modeling에 관련된 논문 및 문헌들의 번역임을 밝힙니다. Radcliffe &amp; Surry (2011) Real-World Uplift Modelling with Significance-Based Uplift Trees Section6.1 Tree-based Uplift Modeling CART와 같이 두 가지로 분할하는 일반적 tree-based model의 split(분할)을 결정하는 기준의 아래의 두가지의 바람직한 속성들은 서로 trade-off 관계에 있다. 두가지 하위그룹의 outcome을 최대화 화는 것 그러한 두가지 그룹의 size의 차를 최소화 하는 것 일반적으로 극단적인 outcome을 보이는 작은 그룹을 찾는 것은 어렵지 않기 때문에 이것들은 본질적으로 충돌하는 경향이 있다. 예를 들어, 단 한명의 구매자 (100%의 구매율)만을 split해서 떼어내는 경우를 생각해볼 수 있다. 우리는 같은 관점으로, 다만 분할된 그룹들간의 outcome의 차이가 아닌 분할된 그룹들간의 Uplift의 차이를 Uplif trees의 split 조건으로써 접근할 것이다. Hansotia &amp; Rukstales (2001)의 방법은 Trade-off를 무시하고 직접적으로 Uplift의 차이(\\(\\Delta\\Delta p\\))를 사용한 결과이다. 우리는 이 접근법으로 좋은 결과를 얻지 못했다. 우리는 split의 기준으로써 Qini를 직접적으로 이용하는 방법 또한 시도했다. Qini는 분할된 하위그룹들의 Size와 Uplift 변화를 모두 고려한다. 우리는 전체적인 Uplift model의 성능을 평가하는데 유용한 Qini를 찾았지만 이것을 split의 기준으로 사용하는데는 제한적인 성공밖에 얻지 못하였다. Qini가 rank의 순서를 매기는 것만을 측정한다는 사실이 이러한 결과의 원인이 되었을 것이다. 또한 그룹간의 size의 차이를 일종의 penalty로 간주하여 원래의 uplift 차이를 조정하는 특별한 접근법을 취할 수도 있다. 만약 원래의 uplift 차이가 \\(\\Delta\\)이고 두개의 하위그룹의 size가 \\(N_L\\) \\(N_R\\)이라고 한다면, 어떠한 k값에 대하여 penalty를 부여받은 split 조건의 후보는 이하와 같을 수 있다. \\(\\Delta / (\\cfrac{N_L+N_R}{2min(N_L,N_R)})^k\\) 이 분모의 penalty는 하위그룹의 size가 서로 같을 때 1을 갖고, 서로 달라질 수 록 큰 값을 갖는다. (결과적으로 penalty를 받은 uplift는 원래보다 작은 값으로 평가된다.) 어떠한 k에 대한 또다른 penalty의 대안은 이하와 같다. \\(\\Delta (1- {\\large \\lvert \\frac{N_L-N_R}{N_L+N_R} \\rvert}^k)\\) 여기서 penalty는 하위그룹의 size가 같을 때 0이 되고 사이즈가 달라지면서 1에 가까워 진다. (두 경우 모두 k는 경험적으로 설정되어야 할 하이퍼파라미터이다.) 그러나 우리는 실제 세상의 어떠한 문제에 대해서도 잘 작동하는 penalty를 찾지 못했다. George Fei's blog (2019) Modeling Uplift Directly: Uplift Decision Tree with KL Divergence and Euclidean Distance as Splitting Criteria - Uplift Decision Tree의 뒤에 있는 이론에 대해 각각의 분할기준(split criterion)이 다른 여러 Uplift Decision Tree 알고리즘이 존재한다. 여기서, 우리는 Piotr Rzepakowski &amp; Szymon Jaroszewicz (2012)에 등장하는 정보 이론적 분할기준(information theoretical splitting criteria)에 대해 논의할 것이다. Single treatment uplift decision tree의 경우에, 각 node는 두개의 분리된 outcome 을 포함한다. 하나는 치료군의 결과이고 다른 하나는 대조군의 결과이다. Uplift를 최대화 하기 위해, 우리는 Tree를 타고 내려가면서 분할되는 두가지의 분포를 최대한 다르게 만들고자 한다. 쿨백-라이블러 발산(Kullback-Leibler divergence)과 유클리드 제곱거리(squared Euclidean Distance)는 정보이론에서 분포간의 divergence를 측정하는 두가지 방법이다. Equation 1. \\(KL(P:Q) = \\sum_ip_ilog\\cfrac{p_i}{q_i}\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\) [Kullback-Leibler Divergence between Two Distributions] \\(E(P:Q) = \\sum_i(p_i-q_i)^2\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\)[Squared Euclidean Distance between Two Distributions] 아래첨자 \\(i\\)는 각각의 outcome class \\(p_i\\)와 \\(q_i\\)는 각각 치료군과 대조군에 있어서 outcome class \\(i\\)가 될 확률 Tree에서 분할되어야 할 node에서, 위의 두가지 방법 중 하나를 이용해 outcome분포의 divergence를 계산할 수 있다. tree node를 children nodes로 분할시키는 'A' test 이후에 우리는 'A' test의 조건하에서 outcome class distribution의 conditional divergence를 비슷하게 측정할 수 있다. Equation 2. [Conditional Divergence for a Given 'A' Test] \\(D{\\large(}P^T(Y):P^C(Y)|A{\\large)} = \\sum_a \\cfrac{N(a)}{N}D{\\large(}P^T(Y|a):P^C(Y|a)\\large)\\) \\(a\\) : 각 자식 노드 \\(N\\) : 부모노드에 있는 개체(instance)들의 총 수 \\(N(a)\\) : 자식노드 \\(a\\)에 있는 개체들의 수 \\(D\\) : divergence measure \\(P^T(Y) , P^C(Y)\\) : outcome class distribution \\(|a\\) : 자식노드 \\(a\\)의 outcome class distribution 최적의 분할를 위해, 우리는 치료군과 대조군 사이의 outcome class distibution 간의 divergence의 증가분(gain)를 최대화 하려고 한다. 바꿔말하자면, 아래와 같은 식을 최대화 할 것이다. Equation 3. [Gain in Class Distribution Divergence for a Given 'A' Test] \\(D_{gain}(A) = D{\\large(}P^T(Y):P^C(Y)|A{\\large)}-D{\\large(}P^T(Y):P^C(Y){\\large)}\\) 우변의 첫번째 항은 위에서 언급된 Conditional Divergence for a Given 'A' Test 우변의 두번째 항은 부모노드의 outcome class distribution divergence - 이 이론을 설명하기 위한 Example Uplift decision tree가 치료와 대조 class distribution의 증가분을 최대화하여 node를 어떻게 분할시키는지 더 잘 설명하기 위해 다음의 예를 제시한다. 주어진 Tree node에 8명의 고객에 해당하는 총 8개의 데이터 포인트가 있으며, 치료군과 대조군에 각각 4명의 고객이 있다고 상상해보자. 치료 그룹의 고객 4명중 3명이 캠페인에 반응(전환; convert)했고, 대조 그룹의 고객 4명 중 2명이 반응을 하였다. 우리는 치료군과 대조군 사이의 outcome class distibution 간의 divergence의 증가분(gain)를 최대화 하도록 이 노드를 분할하는 방법을 찾고 싶다. [자식노드의 결과에 존재하는 분포 차이를 최대화하여 decision tree node가 분할 되는 예] 이론적으로 Uplift decision tree의 분할기준은 여러가지의 분할(Multiway splits)와 호환된다. 그러나 실제 구현에서는 이 예에서와 같이 분할이 두개의 하위 노드만 생성하는 이진 분할이 더 일반적이다. 우리는 위의 그림에 나타난 분할가 우리가 찾고있는 최적의 분할이라고 주장하고자 한다. 이러한 주장을 증명하기 위해, 먼저 유클리드 제곱거리(squared Euclidean Distance)를 통해 divergence를 측정하보자. 1. 먼저 부모노드의 class distribution의 divergence를 구한다. \\(D{\\large(}P^T(Y):P^C(Y){\\large)} = \\sum_{\\large i \\in \\{converted, not\\space converted \\}}(p_i - q_i)^2 = (0.75 - 0.5)^2 + (0.25 - 0.5)^2 = 0.125\\) 이것은 단순히 반응률(전환률; conversion rate)의 치료군과 대조군 간 유클리드 제곱거리와 비반응률(비전환률; non-conversion rate)의 치료군과 대조군 간의 유클리드 제곱거리 더한 값이다. 2. 부모노드에서와 같이 분할된 두개의 자식노드에서도 class distribution divergence들을 각각 구한다. In left child node , \\(\\sum_{\\large i \\in \\{converted, not\\space converted \\}}(p_i - q_i)^2 = (1 - 0)^2 + (0 - 1)^2 = 2\\) In right child node , \\(\\sum_{\\large i \\in \\{converted, not\\space converted \\}}(p_i - q_i)^2 = (0 - 1)^2 + (1 - 0)^2 = 2\\) 3. 분할를 통한 divergence의 개선에 미친 두 자식노드의 상대적인 영향을 정규화하기 위해, 분할의 조건하에서 outcome class distribution의 conditional divergence를 구한다. (Eq.2) \\(D{\\large(}P^T(Y):P^C(Y)|A{\\large)} = \\sum_{\\large a \\in \\{left\\space child,\\space right\\space child \\} }\\cfrac{N(a)}{N} D{\\large (} P^T(Y|a) : P^C(Y|a){\\large)} = \\cfrac{5}{8}\\cdot2 + \\cfrac{3}{8}\\cdot2 = 2\\) 4. 분할가 이루어졌을 때, 치료군과 대조군 사이의 outcome class distibution 간의 divergence의 증가분(gain)을 구한다. (Eq.3) \\(D_{gain}(A) = D{\\large(}P^T(Y):P^C(Y)|A{\\large)}-D{\\large(}P^T(Y):P^C(Y){\\large)} = 2-0.125 = 1.875\\) 두 개의 자손의 class distribution이 가장 다를 때 (즉 divergence가 가장 클 때) 두 자손의 유클리드 제곱거리가 가장 최대화 되므로, 위의 계산 결과는 최대값이라고 할 수있다. 다시 말해, 왼쪽 자식노드의 클래스 분포는 치료군과 통제군을 비교했을 때 가장 Persuadables에 가까운 분포가 되게끔 하고, 오른쪽 자식노드의 클래스 분포는 가장 Sleeping Dogs에 가까운 분포가 되게끔 하는 split을 선택하는 것이다. 모델이 훈련될 때, 이용가능한 특징량의 여러가지 다양한 값에 대해 여러 split을 반복하면서 이러한 최적화 split이 찾아질 것이다. - 잠재적인 준(準)최적 분할 (Potential Suboptimal Splits) 위에서 제시한 분할 전략에 존재할 수 있는 이하의 두가지 잠재적인 문제 에 대처해야할 필요가 있다. 1. 고르지 못한 치료/통제군의 분할 먼저, 고르지 못한 치료/통제군의 분할는 알고리즘이 대부분의 치료개체들을 하나의 하위나무에 집어넣고 그 나무에 거의 통제클래스의 개체들이 존재하지 않을때 일어난다. 이것은 분할에 사용된 특징량이 치료할당 라벨과 높은 상관관계를 가진다는 것을 의미한다. 즉 Uplift modeling의 필수적인 가정인 Unconfounded assumption 이 위반된다는 것을 의미한다. 더욱이 모든 leaf node는 충분한 치료와 통제 개체들을 포함해야 하므로 이러한 분할는 앞으로의 분할를 더욱 어렵게 만들 것이다. 2. 여러개의 자손노드로 나누는 분할를 선택하는 알고리즘의 경향성 여러개의 자손노드로 나누는 분할는, 훈련데이터에 적용되었을 때 더 높은 증가분(gain)을 갖는 경향성이 있기 때문에 발생한다. 그러나 테스트데이터에는 제대로 추론해내지못하며 결과적으로 overfitting을 발생시킨다. 아래에 제시된 정규화인수(Normalization factor)들은 앞에 언급한 바이어스를 시정하기 위해 고안되었다. 쿨백-라이블러 발산과 유클리드 제곱거리를 통한 두가지 분할기준과 마찬가지로 이 또한 두가지 다른 유형의 정규화값을 가진다. Equation 4 [Normalization Value for Splitting Based on KL Divergence] \\(I(A)=H(\\cfrac{N^T}{N},\\cfrac{N^C}{N})KL(P^T(A):P^C(A))+\\cfrac{N^T}{N}H(P^T(A))+\\cfrac{N^C}{N}H(P^C(A))+\\cfrac{1}{2}\\) Equation 5 [Normalization Value for Splitting Based on Euclidean Distance] \\(J(A) = Gini(\\cfrac{N^T}{N},\\cfrac{N^C}{N})E(P^T(A):P^C(A))+\\cfrac{N^T}{N}Gini(P^T(A))+\\cfrac{N^C}{N}Gini(P^C(A))+\\cfrac{1}{2}\\) 두 penalty항이 상당히 비슷하기 때문에, 여기서는 유클리드 제곱거리에 대해서만 논할 것이다. (Eq.5) \\(J(A)=\\) ⅰ. \\(Gini(\\cfrac{N^T}{N},\\cfrac{N^C}{N})\\cdot E(P^T(A):P^C(A))\\) 첫번째 항은 고르지 못한 치료/통제군의 분할을 예방한다. 이 항의 앞부분은 부모노드의 지니 불순도(Gini impurity)\\(^{[*1]}\\)이고, 부모노드의 치료/통제의 불균형이 클 수록 0에 가까워지는 값이다. 이렇게 설정된 이유는 부모노드에 이미 큰 치료/통제 불균형이 존재하는 경우, 결과적으로 따라오는 자식노드의 불균형에 대해 계속적으로 처벌하는 것은 공정하지 않기 때문이다. 이 항의 뒷부분은 모든 자식노드에서의 치료비율과 통제비율간의 유클리드 제곱거리이다. 이 값은 모든 자식노드에서 두 비율이 동일한 경우에만 최소화된다. ⅱ. \\(+\\cfrac{N^T}{N}Gini(P^T(A))+\\cfrac{N^C}{N}Gini(P^C(A))\\) 이어지는 두 항은 여러개의 자손노드로 분할되는 것에 대해 penalty를 부여한다. 이는 같은 문제를 전통적인 decision tree algorithm이 처리하는 방식과 비슷하다. 지니 불순도는 분할에 의해 자손노드의 개수가 증가할 때 증가한다. 예를 들어 두개의 동등한 자손노드로 분할가 이루어 질 때 \\(1 - 0.5^2 -0.5^2 = 0.5\\) 가 되고, 4개의 동등한 자손노드로 분할될 때 \\(1-4\\cdot 0.25^4 = 0.75\\)가 된다. ⅲ. \\(+\\cfrac{1}{2}\\) 마지막 \\(\\cfrac{1}{2}\\) 항은. 작은 증가분(gain)을 갖지만 작은 정규화요인으로 나눔으로써 과대평과되는 분할를 선호하지 않기 위해 존재한다. \\(^{[*1]}:\\) 지니 불순도는 부분 집합에서 무작위로 선택한 원소가 부분 집합의 라벨 분포에 따라 무작위로 라벨을 붙인 경우 얼마나 자주 잘못 라벨을 붙이는지를 측정한 것이다. 라벨 \\(i\\)가 선택되는 확률 \\(p_i\\)과 실수할 확률\\(1-p_i\\)을 곱해서 모든 개체에 대해 합산해서 계산한다. \\(\\sum^J_{i=1}p_i(1-p_i)=\\sum^J_{i=1}(p_i-p_i^2)=\\sum^J_{i=1}p_i-\\sum^J_{i=1}p_i^2=1-\\sum^J_{i=1}p_i^2\\) Henrik Karlsson (2019) Uplift Modeling: Identifying Optimal Treatment Group Allocation and Whom to Contact to Maximize Return on Investment 4.1.3 Model Uplift Directly tree기반의 알고리즘은 데이터를 하위그룹으로 나누고 평가하기 위해 설계되었다. 이것은 차이를 치료군과 대조군간의 차이와 같이 차이(differences)를 모델링하는 데에 유용하다. tree기반의 방법은 uplift 분야에서 일반적으로 여러 연구자들에게 활용되어왔다. - General Tree-based Methods Tree기반 방법은 크게 나눠서 분할(splitting)와 가지치기(pruning)라는 두가지 스텝을 가지고 있다. 분할 스텝은 데이터를 분리해서 pure 한 노드를 가능한 한 생성하는 최적의 분할를 찾기 위해 노력한다. 가지치기 스텝은 나무의 일반화를 개선하지 못하는 노드나 가지들을 제거한다. 노드가 pure 하다는 것은 노드에 속한 모든 데이터 포인트가 가능한 한 가장 비슷하다는 것을 의미한다. tree알고리즘의 타입에 따라, 각 노드는 (CART tree와 같이) 두개의 노드로 나누어질 수 도있고, (CHAID tree와 같이) 여러개의 노드로 나누어질 수도 있다. 알고리즘은 모든 노드들이 완전히 pure 해지거나, 혹은 멈추는 기준을 만족할 때까지 노드를 계속해서 분할시키며 tree를 자라게한다. 만약 tree가 모든 노드가 pure 해질 때까지 자란다면, 모델은 훈련데이터를 완벽히 정확하게 분류할 것이다. 그러나 그 결과는 overfitting되어 새로운 데이터에 잘 일반화되지 않을 것이다. tree의 분할지점을 정하기 위해 정보 이득(information gain)을 계산하고, 정보 이득이 가장 높은 잠재적 분할가 수행될 것이다. 정보이득은 자식노드에 할당된 데이터의 비율에 노드의 순도(purity)를 곱하여 추정한다. CART나 Quinlan's C4.5 tree와 같은 많은 tree기반의 방법들이 이러한 하향식으로 노드를 분할한 뒤 도움이 되지 않는 분할을 가지치기하는 2step 접근방법을 사용한다. 이러한 접근방법을 활용하는 이유는 tree method가 매우 선형적이지 않고 그에 따라 선택된 특징량들의 상호작용에 강하게 의존하기 때문이다. 예를 들어, 주어진 분할가 현재 노드에서만 평가될 때 의미가 없어 보일 수 있지만, 그보다 더 아래로 분할될 때 현재 분할와 관련지어져 매우 중요해질 수 있다. 즉 각 분할은 미래의 분할 가능성을 무시한 현재 노드에서 평가되므로, 분할가 많은 깊은 tree를 만들고 그 후에 충분히 기여하지 못한 분할를 가지치기하는 것이다. tree의 깊이를 제한하는 정지 기준을 삽입하여 가지치기 작업을 tree에 적용하거나 두 가지를 함께 적용함으로써 오버피팅을 피할 수 있다. 가지치기 작업은 사용 중인 tree의 종류에 따라 유의성 시험에 근거하여 분할 전 또는 tree의 성장이 끝난 후에 수행할 수 있다. 후자의 방법이 더 일반적이다. 일반적으로 깊게 자라는 것이 허용된 decision tree는 동일한 데이터셋으로 학습을 했음에도 불구하고 서로 다른 tree들 간의 바이어스가 낮고 분산이 높다. (low bias and high variance \\(\\rightarrow\\) Overfitting ) 깊은 tree 모델은 데이터를 잘 분류할 수 있기 때문에 바람직하다고 할 수있지만, 서로 다른 decision tree 간의 높은 분산이 robust\\(^{[*2]}\\)하지 못한 결과를 낳는다. 이러한 decision tree간의 분산을 줄이기 위해 Random forest algorithm이 개발되었다. 이것은 많은 decision tree를 만들고 각 tree의 결과를 평균하여 더 robust한 결과를 얻는다. 이것은 모델에서 약간 더 많은 바이어스라는 cost를 수반하지만, 그 결과로 분산이 감소한다. Random forest는 Bagging을 사용하고 각각의 tree들을 다른 특징의 부분집합으로 훈련시켜 deep tree의 효과를 훨씬 더 평균화하는 데 도움을 준다. 이 보고서에서는 uplift random forest는 특징량갯수의 제곱근을 사용하여 각 tree를 훈련시킨다. \\(^{[*2]}:\\) 머신러닝 알고리즘에서 robust는 일반적으로 알고리즘의 강건성을 가리킨다. 머신러닝 알고리즘이 robust하다고 간주되려면 testing error가 training error와 일치해야 하거나 데이터 집합에 노이즈를 추가한 후에도 성능이 안정적이어야 한다. - Tree-based Methods for Estimating Uplift Tree기반 알고리즘을 사용하여 Uplift Modeling을 할 때는 Uplift가 포착될 수 있도록 분할기준을 조정한다. 문헌에 따르면 Uplift를 가장 잘 추정하기 위해 분할기준을 조정하는 몇 가지 방법이 제시되어 있으며, 어떤 방법이 가장 좋은지에 대한 합의는 아직 이루어지지 않은 것으로 보인다. Hansotia and Rukstales (2002)는 '각 자식노드(binary)에서의 치료군과 대조군의 확률 차이' 사이의 차이를 최대화 하기 위한 분할기준을 제시했다. Rzepakowski &amp; Jaroszewicz (2012)는 정보이론으로 부터 '차이'의 개념을 분할 기준으로 도입했는데, Tree기반의 알고리즘이 치료군과 대조군 사이의 분포적 차이를 최대화하려고 노력함으로써 상승을 포착한다. 이 보고서는 Rzepakowski &amp; Jaroszewicz (2012)의 분할 기준을 사용할 것이다. Distributional divergence(분포의 차이)란 q(x)를 p(x)의 근사치로 사용할 때 손실되는 정보의 양을 나타내는 척도로, 여기서 q(x)는 일반적으로 표본데이터를 나타내고 p(x)는 이론적인 분포로부터 도출된 데이터로 나타내어진다. 이 divergence는 두 확률분포 사이의 \"거리\"이지만, 대칭적이거나 삼각부등식을 만족할 필요가 없으므로 미터법 거리보다 약한 척도이다. divergence 척도를 분할기준으로 사용할 경우 모든 노드에서 치료군과 대조군 사이의 차이를 최대화하려고 한다. tree들의 앙상블을 사용하려고 할 때, 예측되는 Uplift값은 개별 tree에서의 예측 Uplift값을 평균하여 얻는다. 분할기준으로 사용되는 네 가지 다른 divergence 척도는 아래에서 확인할 수 있다. Rzepakowski &amp; Jaroszewicz(2012)는 Uplift을 포착하기 위해 분할 기준이 충족해야 하는 세 가지 항목을 제시한다. 치료군과 대조군의 class 분포가 모든 분할에서 동일할 경우 분할기준치를 최소값으로 평가해야 한다. Uplift는 치료군과 대조군 사이의 가능한 가장 큰 분포차이를 만들어냄으로써 포착되기 때문에, 두 집단이 동일할 때는 분할기준치가 최소값으로 평가되는 것이 타당하다. 분할기준치는 test가 치료군과 대조군에서의 각 outcome과 통계적으로 독립되어 있는 경우 0으로 평가해야 한다. 일반적인 decision tree에서는 outcome과 통계적으로 독립된 분할가 tree를 개선시키지 못하므로 분할의 기준으로 사용해서는 안된다고 명시하고 있다. 그러나 uplift modeling에서는 분포를 이전보다 더 유사하게 만들 수 있으며, 이는 음의 분할기준치를 갖는 것을 의미한다. 즉 독립적인 분할가 발생할 수 있는 최악의 분할가 아닐 수 있음을 의미한다. 대조군의 크기가 0일 경우의 분할기준치는 decision tree가 사용하는 표준 분할기준치까지 감소시켜야한다. 이 보고서는 Uplift random forest와 함께 네 가지 서로 다른 분할기준을 다룬다. 각각은 \\(P=(p_1,\\cdots,p_n)\\)과 \\(Q=(q_1,\\cdots,q_n)\\)의 분포 사이의 divergece 값을 계산한다. Kullback-Leibler divergence : \\(KL(P:Q)=\\sum_ip_ilog\\cfrac{p_i}{q_i}\\) squared Euclidean distance : \\(ED(P:Q)=\\sum_i(p_i-q_i)^2\\) \\(\\chi^2\\)-divergence : \\(\\chi^2(P:Q)=\\sum_i\\cfrac{(p_i-q_i)^2}{q_i}\\) L1-norm divergence : \\(L1(P:Q)=\\sum_i|p_i-q_i|\\) (Kullback-Leibler divergence, squared Euclidean distance, \\(\\chi^2\\)-divergence는 Rzepakowski and Jaroszewicz (2012b)에 소개되었고, L1-norm divergence는 Guelman, Guill´en, and P´erez-Mar´ın (2015)에서 소개되었다.) Random forest 모델은 주어진 군에 속하는 구매의 조건부 확률을 반환한다. Uplift score은 이하와 같은 식으로 계산된다. \\(Uplift\\space score = P(purchase|treatment\\space group) - P(purchase|control\\space group)\\) Score가 높다는 것은 치료로 인한 구매가능성이 높다는 것을 가정하고 있으므로 score를 내림차순으로 분류해야 한다. score가 음수인것은 치료를 하지 않는 것이 그개인의 구매확률이 더 높다는 의미이다. uplift를 직접적으로 모델링 하는 것의 장점은 이진적인(binary) 목적변수와 연속적인(continuous) 목적변수 모두에 적용할 수 있다는 점이다.","link":"/2020/12/17/Uplift-tree/"}],"tags":[{"name":"Causal Inference","slug":"Causal-Inference","link":"/tags/Causal-Inference/"},{"name":"Bayesian Network","slug":"Bayesian-Network","link":"/tags/Bayesian-Network/"},{"name":"Uplift modeling","slug":"Uplift-modeling","link":"/tags/Uplift-modeling/"},{"name":"Feature Selection","slug":"Feature-Selection","link":"/tags/Feature-Selection/"},{"name":"Uplift Tree","slug":"Uplift-Tree","link":"/tags/Uplift-Tree/"}],"categories":[{"name":"Prerequisite","slug":"Prerequisite","link":"/categories/Prerequisite/"},{"name":"Causal Inference","slug":"Prerequisite/Causal-Inference","link":"/categories/Prerequisite/Causal-Inference/"},{"name":"UPLIFT MODELING","slug":"UPLIFT-MODELING","link":"/categories/UPLIFT-MODELING/"},{"name":"b.Bayesian Network","slug":"Prerequisite/Causal-Inference/b-Bayesian-Network","link":"/categories/Prerequisite/Causal-Inference/b-Bayesian-Network/"},{"name":"a.Overall","slug":"Prerequisite/Causal-Inference/a-Overall","link":"/categories/Prerequisite/Causal-Inference/a-Overall/"},{"name":"b.Feature Selection","slug":"UPLIFT-MODELING/b-Feature-Selection","link":"/categories/UPLIFT-MODELING/b-Feature-Selection/"},{"name":"a.Overall","slug":"UPLIFT-MODELING/a-Overall","link":"/categories/UPLIFT-MODELING/a-Overall/"},{"name":"c.Methods","slug":"UPLIFT-MODELING/c-Methods","link":"/categories/UPLIFT-MODELING/c-Methods/"},{"name":"2.Tree-based Algorithm","slug":"UPLIFT-MODELING/c-Methods/2-Tree-based-Algorithm","link":"/categories/UPLIFT-MODELING/c-Methods/2-Tree-based-Algorithm/"}]}