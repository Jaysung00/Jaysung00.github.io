<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"
  xmlns:atom="http://www.w3.org/2005/Atom"
  xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Jay Sung&#39;s DS blog</title>
    <link>https://jaysung00.github.io/</link>
    
    <atom:link href="https://jaysung00.github.io/rss2.xml" rel="self" type="application/rss+xml"/>
    
    <description></description>
    <pubDate>Sun, 06 Dec 2020 08:31:09 GMT</pubDate>
    <generator>http://hexo.io/</generator>
    
    <item>
      <title>【Causal Inference②】조작변수법(IV)에 관하여</title>
      <link>https://jaysung00.github.io/2020/12/04/CN2/</link>
      <guid>https://jaysung00.github.io/2020/12/04/CN2/</guid>
      <pubDate>Fri, 04 Dec 2020 08:34:44 GMT</pubDate>
      
      <description>&lt;hr /&gt;</description>
      
      
      
      <content:encoded><![CDATA[<hr><a id="more"></a><h1><span id="rct를-사용할-수-없을-때는-어떻게-할까">* RCT를 사용할 수 없을 때는 어떻게 할까?</span></h1><hr><p>Level 1. 실험(Experimental) 레벨 (개입연구)</p><ul><li>관찰자(해석자)가 개입의 계획을 세워서 데이터를 수집 <span class="math inline">\(\rightarrow\)</span> RCT (무작위화비교실험)</li></ul><p><br></p><h3><span id="blacktriangleright-level-2-준실험quasi-experimental-레벨"><span class="math inline">\(\blacktriangleright\)</span> Level 2. 준실험(Quasi Experimental) 레벨</span></h3><ul><li><p>비교적 질 좋은 관찰연구 정도의 느낌</p></li><li><p>실험데이터가 아니라 <strong>관찰데이터</strong> 를 사용해서, 개입의 여부 등으로 결과에의 영향을 추정</p></li><li><p><strong>측정되지 않은 교란인자</strong>를 처리할 수 있는 것은 사실상 RCT만이 쉽게 가능하지만, <strong>모든 교란인자를 충분히 측정할 수 있다고 하면</strong> 준실험설계로도 충분히 인과관계를 설명할 수 있다.</p></li><li><p><strong>변수조작법(IV)</strong> , <strong>차의 차 분석(DID)</strong> , <strong>경향스코어 매칭(PS)</strong> , <strong>회귀불연속 디자인(RDD)</strong> 등이 있다.</p></li></ul><p><br></p><p>Level 3. 관찰(Observation) 레벨</p><ul><li>더욱 인과추론 하기에 취약한 관찰연구 디자인</li></ul><p><br></p><hr><h1><span id="i-조작변수법-iv-instrumental-variable-methods"><span class="math inline">\(I\)</span>. 조작변수법 (IV; Instrumental variable methods)</span></h1><hr><h3><span id="-조작변수법이란">- 조작변수법이란?</span></h3><ul><li>매우 어렵지만 이론상 완벽하게 설계된다면 <strong>측정되지 않은 교란인자</strong> 도 처리할 수 있는 방법.</li></ul><p><br></p><ul><li><p><strong>외생변수</strong> ; 모델의 밖에서 결정되어 주어진 변수 (설명변수로써 바람직하다).</p><ul><li><strong>모델의 잔차항</strong> 과 독립하게 된다.</li></ul></li></ul><p><br></p><ul><li><p><strong>내생변수</strong> ; 모델 내에서 결정되는 변수 (설명변수로써 바람직하지 않다).</p><ul><li>예를 들어 <em>측정되지 않은 교란인자</em> 가 있는 경우 영향을 받는 <strong>설명변수와 모델의 잔차항 사이에 상관</strong> 관계가 생겨버리고 이 설명변수는 <strong>내생변수</strong> 가 되어 <em>내생성 바이어스</em> 를 만든다.</li></ul></li></ul><p><br></p><ul><li><p>이렇게 발생된 <strong>내생변수</strong> 를 <strong>외생화</strong> 하기 위해 도입된 변수 <span class="math inline">\(Z\)</span>를 <strong>조작변수(IV)</strong> 라고 한다.</p></li><li><p>이러한 조작변수를 이용해, 설명변수가 결과에 미치는 영향을 평가하는 방법을 <strong>조작변수법</strong> 이라고 한다.</p></li></ul><p><br></p><blockquote><p><span class="math inline">\([ 예시 ]\)</span><br><img src="https://i.imgur.com/Q8xihRF.png" width="550px"><br>- 참의 관계 : <span class="math inline">\(ln(wage) = a + b \cdot educ + c \cdot ability + u\)</span></p></blockquote><p>임금(Wage)와 교육년수(Education)와 능력(Ability)은 위와 같은 관계가 있다고 가정한다.</p><p>그러나 능력은 실제로 측정불가하기 때문에 교육수준만으로 임금과의 관계를 설명하는 모델을 했다고 하자.</p><ul><li><span class="math inline">\(ln(wage) = a&#39; + b&#39; \cdot educ + v\)</span></li></ul><p>이 때, 능력(Ability)은 <strong>관측되지 않은 교란인자</strong> 가 되고 계수 <span class="math inline">\(b&#39;\)</span>에는 내생성 바이어스가 존재하게 된다.</p><p><br></p><h3><span id="-조작변수법의-과정">- 조작변수법의 과정</span></h3><p><strong>내생변수</strong> 를 피설명변수로 별도의 조작변수 <span class="math inline">\(IV\)</span>를 통해 설명하는 모델을 작성한다.</p><ul><li><span class="math inline">\(\begin{align} ln(wage) &amp;= a&#39; + b&#39; \cdot educ + \underline v \\ &amp;= a&#39; + b&#39; \cdot educ + \underline {c&#39; \cdot X+ v&#39;} \end{align}\)</span></li></ul><p><span class="math inline">\(\space\space\space\space\space\space\space\space\space\space\space\space\space\)</span> (C를 잔차항에 포함된 <em>교란인자</em> 라고 가정)</p><ul><li><span class="math inline">\(\bf educ = \alpha + \beta \cdot \underline {IV} + \gamma \cdot X + \epsilon\)</span><br><br><br><img src="https://i.imgur.com/SJ5bifx.png" width="600px"></li></ul><p><br></p><ul><li><p><strong>조작변수 <span class="math inline">\(\bf IV\)</span>의 조건</strong></p><ol type="1"><li><p><code>Exclusion restriction</code> : IV는 원래의 결과부분에 해당하는 변수(Wage)에게 개입변수(설명변수, Education)를 통해서만 영향을 줄 수있다.</p></li><li><p><code>No instrument-outcome confounder</code>：IV와 원래의 결과부분에 해당하는 변수(Wage)에게 동시에 영향을 주는 <strong>공통의 원인(L 또는 X)</strong> 이 존재하지 않아야 한다</p></li><li><p><code>Instrument relevance</code> : 개입변수(설명변수, Education)에게는 확실히 영향을 주는 변수여야 한다.</p></li><li><p><code>Monotonicity</code> : 조작변수가 역효과를 내는 사람(Defiers)이 존재하지 않아야 한다. (완전히 반대로 움직이는 케이스)</p></li></ol></li></ul><p>이상의 조건을 만족하는 조작변수를 발견해, 이를 통해 교란인자에 의한 효과를 제거한다.<br><br></p><h4><span id="그러나-이러한-조건을-만족하는-조작변수를-찾아내는-것은-매우-어렵고-특히-비즈니스-현장에서는-거의-불가능에-가깝다">【그러나, 이러한 조건을 만족하는 조작변수를 찾아내는 것은 매우 어렵고 특히 비즈니스 현장에서는 거의 불가능에 가깝다.】</span></h4><p><br></p><hr><h2><span id="i-i-처치의도에-의한-분석-intention-to-treat-analysis"><span class="math inline">\(I-I.\)</span> 처치의도에 의한 분석 (Intention to treat analysis)</span></h2><h3><span id="spacespacespacespacespace-그럼에도-불구하고-생각해보는-조작변수법iv의-활용-가능성"><span class="math inline">\(\space\space\space\space\space\)</span> - 그럼에도 불구하고 생각해보는 조작변수법(IV)의 활용 가능성</span></h3><hr><p><br><br>- 실제 개입에서는 개입의 대상이지만 따르지 않는 경우나 대상이 아니지만 따르는 경우와 같이 참가자가 개입의도와 반대로 움직이는 경우가 존재한다.</p><ul><li><p><em>'정책이나 치료와 같은 개입의 효과를 추정하기 위해서 개입의도대로 움직이는 부분집단만을 비교하는 것이 좋지 않을까'</em> 라는 이론</p></li><li><p>개입을 행하는 참가자의 의도를 <strong>1과 0을 갖는 dummy 조작변수 <span class="math inline">\(z\)</span></strong> 로 생각한다.</p></li></ul><p><img src="https://i.imgur.com/qCI2qOc.png" width="600px"></p><p><br></p><ul><li><span class="math inline">\(\begin{equation}z= \left \{\begin{array}{l}1　(개입의도 있음) \\0　(개입의도없음)\end{array}\right.\end{equation}\)</span></li></ul><p><br></p><ul><li><span class="math inline">\(d = zd_1 + (1-z)d_0\)</span><br>(<span class="math inline">\(d\)</span>는 <span class="math inline">\(z\)</span>가 1일 때 <span class="math inline">\(d_1\)</span>이 되고, <span class="math inline">\(z\)</span>가 0일 때 <span class="math inline">\(d_0\)</span>이 된다.)</li></ul><p><br></p><ul><li><span class="math inline">\(\begin{equation}d= \left \{\begin{array}{l}1　(실행) \\0　(실행하지않음)\end{array}\right.\end{equation}\)</span></li></ul><p><br></p><ul><li><span class="math inline">\(y=dy_1 + (1-d)y_0\)</span><br>(마찬가지로 <span class="math inline">\(y\)</span>는 <span class="math inline">\(d\)</span>가 1일 때 <span class="math inline">\(y_1\)</span>이 되고, <span class="math inline">\(d\)</span>가 0일 때 <span class="math inline">\(y_0\)</span>이 된다.)</li></ul><p><br></p><ul><li><p>조작변수<span class="math inline">\(z\)</span>의 가정</p><ul><li><p><span class="math inline">\(\bf (y_0,y_1) \perp z|d,\)</span> : 변수 <span class="math inline">\(d\)</span>에 의해 <span class="math inline">\(z\)</span>와 <span class="math inline">\(y\)</span>가 <a href="https://jaysung00.github.io/2020/11/14/BN1/"><span class="math inline">\(d\)</span>-seperate</a> 되므로 <code>Exclusion restriction</code> 와 <code>No instrument-outcome confounder</code> 만족</p></li><li><p><span class="math inline">\(\bf d_{i1} \geq d_{i0}\)</span> : <code>Monotonicity</code> 만족 (제비에 뽑히면 공립에 가고, 제비에 떨어지면 사립에 가는 Defiers는 존재하지 않는다고)</p></li><li><p>(<span class="math inline">\(d\)</span>와 <span class="math inline">\(z\)</span>의 정의에 의해 <code>Instrument relevance</code>는 자동으로 만족)</p></li></ul></li></ul><p><br></p><table><thead><tr class="header"><th style="text-align: center;">설계자의 의도 <span class="math inline">\(z\)</span></th><th style="text-align: center;">참가자의 의사 <span class="math inline">\(d\)</span></th><th style="text-align: center;">Notation</th><th style="text-align: left;">상황의 해석</th></tr></thead><tbody><tr class="odd"><td style="text-align: center;">1</td><td style="text-align: center;">1</td><td style="text-align: center;"><span class="math inline">\(d_1\)</span> = 1</td><td style="text-align: left;">개입의 대상이 되어서 참가자가 개입의도에 맞게 따르는 경우</td></tr><tr class="even"><td style="text-align: center;">1</td><td style="text-align: center;">0</td><td style="text-align: center;"><span class="math inline">\(d_1\)</span> = 0</td><td style="text-align: left;">개입의 대상이 되었지만 참가자가 개입의도에 따르지 않는 경우 (noncompliance)</td></tr><tr class="odd"><td style="text-align: center;">0</td><td style="text-align: center;">1</td><td style="text-align: center;"><span class="math inline">\(d_0\)</span> = 1</td><td style="text-align: left;">개입의 대상이 아님에도 불구하고 개입의도의 방향으로 움직이는 경우 (noncompliance)</td></tr><tr class="even"><td style="text-align: center;">0</td><td style="text-align: center;">0</td><td style="text-align: center;"><span class="math inline">\(d_0\)</span> = 0</td><td style="text-align: left;">개입의 대상이 아니였기 때문에 개입의도에 따르지 않는 경우</td></tr></tbody></table><p><br></p><h3><span id="-국소적-평균효과late-local-average-treatment-effect">- <strong>국소적 평균효과(LATE; local average treatment effect)</strong></span></h3><p><br></p><ul><li><p>정의 ; <span class="math inline">\(\Large LATE = E(y_1-y_0|d_1=1,d_0=0)\)</span></p></li><li><p>의미 ; 개입의도의 방향대로 움직여주는 부분집합에서만 측정한 효과</p></li></ul><p><br></p><h3><span id="-late의-추정">- LATE의 추정</span></h3><p><br></p><p>조작변수 <span class="math inline">\(z\)</span>의 가정에 의해,</p><p><span class="math inline">\(\begin{align} E(y|z=1) - E(y|z=0) &amp;= E(dy_1+(1-d)y_0|z=1) - E(dy_1+(1-d)y_0| z=0)\\ &amp;= E(d_1y_1+(1-d_1)y_0|z=1)-E(d_0y_1+(1-d_0)y_0|z=0) \\ &amp;= E(d_1y_1 + (1-d)y_0)-E(d_0y_1 + (1-d_0)y_0)\\ &amp;= E((d_1-d_0)(y_1-y_0)) \\ &amp;\space \\ &amp;\space\space\space\space\space\space\space\space\space\space\space\cdots d_1-d_0는\space\{-1,0,1\},\space\space Monotonicity가정에\space\space의해\space\space p(d_1-d_0=-1)=0 \space\space 이므로\\ &amp;\space \\ &amp;=\sum_{a=-1,0,1}aE(y_1-y_0|d_1-d_0 = a)p(d_1-d_0 = a) \\ &amp;= \underline {E(y_1-y_0|d_1-d_0=1)} \space p(d_1-d_0=1) \end{align}\)</span></p><p><br></p><p>위 식의 우변에 <span class="math inline">\(E(y_1-y_0|d_1-d_0=1)\)</span>가 <span class="math inline">\(\bf LATE\)</span> 의 정의가 되므로,</p><p><br></p><p><span class="math inline">\(\begin{align} {\bf LATE} &amp;= E(y_1-y_0|d_1-d_0=1) \\ &amp;\space \\ &amp;= \cfrac{E(y|z=1) - E(y|z=0)}{p(d_1-d_0=1)} \\&amp;\space \\ &amp;= \cfrac{E(y|z=1) - E(y|z=0)}{ p(d_1=1,d_0=0)} \\ &amp;\space \\ &amp;= \cfrac{E(y|z=1) - E(y|z=0)}{\{p(d_1=1,d_0=1) + p(d_1=1,d_0=0)\} - p(d_0=1,d_1=1)} \\ &amp;\space \\ &amp;= \cfrac{E(y|z=1) - E(y|z=0)}{p(d_1=1)-p(d_0=1)} \\ &amp;\space \\ &amp;= {\bf \cfrac{E(y|z=1) - E(y|z=0)}{E(d|z=1)-E(d|z=0)}} \end{align}\)</span></p><p><br></p><p>로 바꿔쓰는 것이 가능해, 이것은 <span class="math inline">\(z\)</span>가 2진변수(binary variable)인 경우의 <strong>조작변수추정량</strong> 과 같고, <span class="math inline">\(\bf LATE\)</span>는 이것으로 추정가능하게 된다.</p><p><br></p><hr><p><br></p><blockquote><p>[예시]<br><strong>콜롬비아에서 이루어진 '바우쳐제도'는 학업성적 향상의 효과가 있었을까?</strong></p></blockquote><blockquote><p>[상황설명]<br>- 바우쳐제도란, 제비뽑기로 장학생을 선정해서 사립 중학교의 수업료 절반을 부담해주는 제도이다.<br>- 그러나 바우쳐제도 만으로 수업료를 감당하기 힘들어 제비뽑기에서 선발되어도 사립중학교의 입학을 포기하는 학생들이 존재했다.<br>- 부모님들의 경제적능력이 좋거나 사립학교를 선호하는 학생들은 제비뽑기에서 떨어져도 사립학교에 입학했다.</p></blockquote><blockquote><p>[가정 (실제 데이터가 아님) ]<br>- 1,000명의 학생이 제비를 뽑아 당첨된 학생은 300명이였다.<br>- 제비에 당첨된 300명의 학업성적의 평균은 80점<br>- 제비에 당첨되지 않은 700명의 학업성적은 60점<br>- 제비에 당첨됐을 때 사립학교에 진학학 확률은 90%<br>- 제비에 당첨되지 않았음에도 사립학교에 진학할 확률은 15%</p></blockquote><p><br></p><ul><li><span class="math inline">\(\begin{equation}z= \left \{\begin{array}{l}1　(제비뽑기당첨) \\0　(제비뽑기탈락)\end{array}\right.\end{equation}\)</span></li></ul><p><br></p><ul><li><span class="math inline">\(d = zd_1 + (1-z)d_0\)</span></li></ul><p><br></p><ul><li><span class="math inline">\(\begin{equation}d= \left \{\begin{array}{l}1　(사립학교진학) \\0　(공립학교진학)\end{array}\right.\end{equation}\)</span></li></ul><p><br></p><ul><li><span class="math inline">\(y=dy_1 + (1-d)y_0\)</span> (성적)</li></ul><p><br></p><ul><li><p>여기서 우리가 궁금한 것은 <strong>[바우쳐제도] <span class="math inline">\(\rightarrow\)</span> [사립학교진학] <span class="math inline">\(\rightarrow\)</span> [성적향상]</strong> 의 인과스토리(causal story)를 가진 효과이다.</p></li><li><p>그러므로 우리가 관심있는 케이스는 <strong>제비뽑기에 붙으면 사립학교에 가고 떨어지면 공립학교에 진학할 학생</strong> 이다.</p></li><li><p>즉, 제비뽑기에 붙던 안붙던 사립학교에 갈 학생 (<span class="math inline">\(d_1=1,d_0=1\)</span>)이나 붙던 안붙던 공립학교에 갈 학생 (<span class="math inline">\(d_1=0,d_0=0\)</span>)은 고려의 대상이 아니다.</p></li></ul><p><br></p><ul><li><p>따라서, <span class="math inline">\(ATE = E(y_1-y_0)\)</span> 를 구하면 단순히 사립학교와 공립학교의 성적 차이를 구하게 된다.</p></li><li><p>이 경우 <span class="math inline">\({\bf LATE} = E(y_1-y_0|d_1=1,d_0=0)\)</span> 를 구하는 것이 바람직할 것이다.</p></li></ul><p><br></p><ul><li><p><strong><span class="math inline">\({\bf LATE}\)</span>의 추정</strong></p><ul><li><p><span class="math inline">\(E(y|z=1) = 80\)</span></p></li><li><p>E(y|z=0) = 60$</p></li><li><p><span class="math inline">\(E(d|z=1) = 0.9\)</span></p></li><li><p><span class="math inline">\(E(d|z=0) = 0.15\)</span></p></li><li><p><span class="math inline">\(\begin{align} LATE &amp;= \cfrac{E(y|z=1) - E(y|z=0)}{E(d|z=1)-E(d|z=0)}\\ &amp;\space \\ &amp;= \cfrac{80-60}{0.9-0.15} \fallingdotseq 26.6666 \end{align}\)</span></p></li><li><p>국소적 평균효과(LATE)의 관점에서 26.66점의 성적향상효과가 있었다고 추정할 수 있다.</p></li></ul></li></ul><p><br></p><h4><span id="결론이와-같이-준실험으로써의-조작변수법은-상당이-어렵지만-bf-late-의-아이디어로써의-조작변수법은-생각해볼만-하다">【결론】이와 같이 준실험으로써의 조작변수법은 상당이 어렵지만 <span class="math inline">\(\bf LATE\)</span> 의 아이디어로써의 조작변수법은 생각해볼만 하다.</span></h4><p><br></p><hr><h2><span id="reference">* Reference</span></h2><p>해당 포스트는 <a href="https://www.youtube.com/watch?v=u8hsTkLg2xc&amp;t=159s">유튜브 채널「データの科学のメソドロジー」의 山田典一님의 강의</a>를 틀로 내용을 정리 &amp; 추가 했음을 밝힙니다.</p><p>그 외 참조</p><p><a href="https://www.amazon.co.jp/dp/4000069721/ref=cm_sw_r_tw_dp_U_x_5LQxEbXZJDK4H">調査観察データの統計科学―因果推論・選択バイアス・データ融（星野崇宏）</a></p><p><a href="http://www.ier.hit-u.ac.jp/~kitamura/lecture/Hit/08Statsys5.pdf">捜査変数法（一橋大学経済研究所, 北村 行伸）</a></p><p><a href="https://healthpolicyhealthecon.com/2015/02/23/experiment-and-quasi-experiment-1/">操作変数法Instrumental variable methodsに関するブログ (津川友介)</a></p>]]></content:encoded>
      
      
      <category domain="https://jaysung00.github.io/categories/KOR/">KOR</category>
      
      <category domain="https://jaysung00.github.io/categories/KOR/%ED%86%B5%EA%B3%84%EC%A0%81%EC%9D%B8%EA%B3%BC%EC%B6%94%EB%A1%A0/">통계적인과추론</category>
      
      <category domain="https://jaysung00.github.io/categories/KOR/%ED%86%B5%EA%B3%84%EC%A0%81%EC%9D%B8%EA%B3%BC%EC%B6%94%EB%A1%A0/ML/">ML</category>
      
      
      <category domain="https://jaysung00.github.io/tags/causal/">causal</category>
      
      <category domain="https://jaysung00.github.io/tags/%ED%86%B5%EA%B3%84%EC%A0%81-%EC%9D%B8%EA%B3%BC%EC%B6%94%EB%A1%A0/">통계적 인과추론</category>
      
      
      <comments>https://jaysung00.github.io/2020/12/04/CN2/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>【Causal Inference①】인과추론의 목적과 RCT에 관하여</title>
      <link>https://jaysung00.github.io/2020/11/30/CI1/</link>
      <guid>https://jaysung00.github.io/2020/11/30/CI1/</guid>
      <pubDate>Mon, 30 Nov 2020 02:39:29 GMT</pubDate>
      
      <description>&lt;hr /&gt;</description>
      
      
      
      <content:encoded><![CDATA[<hr><a id="more"></a><h1><span id="인과추론causal-inference으로-뭘-할-수-있는데">* 인과추론(Causal Inference)으로 뭘 할 수 있는데?</span></h1><hr><blockquote><p>"A 아이스크림을 공중파 CF에 내보냈을때, 해당 아이스크림의 매상은 얼마나 올랐을까?"</p></blockquote><blockquote><p>"전 사원 대상 Python 연수 프로그램을 설치 했을때, 사원 들의 일의 능률은 얼마나 올랐을까?"</p></blockquote><p>이와 같은 질문들은 비즈니스에서 일상적으로 흔히 나올 수 있는 질문들이다.</p><p>하지만 이에 대해 <strong>깊은 고찰 없이 단순하게 효과를 정의하고 평가함</strong> 으로써, 우리는 수많은 <strong>바이어스</strong> 를 만들어 내고 있다.</p><p>공중파 CF의 효과를 계산하기 위해 단순히 CF 전후의 매상의 차이를 계산해서, CF와 관계없이 시기적으로 날씨가 더워져서 오른 맥주의 매상까지도 <strong>CF의 효과</strong>로써 평가해버린다.</p><p>또한 Python 연수를 신청한 사람들은 그렇지 않은 사원들보다 원래부터 우수한 사람이 많을수 있다. 원래부터 일의 능률이 높은 연수자그룹과 비연수자 그룹의 능률을 단순 비교해서 원래의 차이까지도 <strong>python연수의 효과</strong>로 평가해버린다.</p><p>이처럼 인과추론의 목적를 철저하게 비즈니스적 관점에서 보자면 <strong>어떠한 시책의 정확한 효과측정</strong> 을 위한 이론 &amp; 기술 분야라고 할 수 있다.</p><p><br></p><hr><h1><span id="inference-의-신뢰성의-3단계">* Inference 의 신뢰성의 3단계</span></h1><hr><h3><span id="level-1-실험experimental-레벨">Level 1. 실험(Experimental) 레벨</span></h3><ul><li><p><strong>RCT (Randomized Controlled Trial; 무작위화 비교 실험)</strong></p></li><li><p>3가지 기본요건</p><p>(1). <strong>비교</strong> : <code>Control Group</code>과 <code>Treatment Group</code> 의 비교를 통해 독립변수가 종속변수에 영향을 미쳤는지 확인하는 과정</p><p>(2). <strong>조작</strong> : 시간적으로 독립변수가 먼저 발생하고 그 후에 뒤따라 종속변수가 발생함을 입증하기 위해, 임의로 독립변수를 의도적인 시기에 발생하도록하고 이에 뒤따른 종속변수의 변화를 측정하도록 시간적 순서를 조작하는 것 <em>(인과성의 선후관계)</em></p><p>(3). <strong>통제</strong> : 허위적 관계가 아닌 것을 입증하기 위해, 독립변수를 제외한 종속변수에 영향을 미칠 수 있는 여러 변수들이 종속변수에 영향을 미치지 못하도록 상황을 의도적으로 통제하는 것</p></li></ul><h3><span id="level-2-준실험quasi-experimental-레벨">Level 2. 준실험(Quasi Experimental) 레벨</span></h3><ul><li><p><code>Level 1</code>의 실험설계는 인과관계를 명확히 구명할 수 있지만, 인위적 통제가 어렵거나 윤리적 문제등으로 인해 (<em>특히 비즈니스의 경우 제한된 예산 등에 의해</em>) 실제 활용이 매우 어렵다. 이에 따라 비록 실험 설계에는 미치지 못하지만, 그 대안적인 방법으로 활용되는 방법이다.</p></li><li><p>대표적인 방법</p><p>(1). <strong>시계열 설계(time-series design)</strong> : 비교집단을 별도로 설정하기 곤란한 경우에 <em>하나의 집단</em> 을 선택해서, 독립변수 도입의 전후상태를 비교하는 방법이다. 외적요인에 대한 통제가 어렵기 때문에 (각 기간마다 외부의 영향이 다르다), 위험이 있을 수 있다. 이를 개선하기 위해서는 같은 조사를 여러 집단에서 되풀이하여 실시하여 같은 결과를 얻을 수 있는지 확인할 필요가 있다.</p><p>(2). <strong>비동일 통제집단 설계(nonequivalent control group design)</strong> : 비동일 통제집단 설계는 실험설계의 통제집단 전후비교와 유사하지만 <em>비교집단을 무작위로 선정하지 않는다</em> 는 차이가 있다. 비동일 통제집단 설계는 무작위배치 이외의 방법(매칭, 기존집단의 선정 등)으로 <code>Control Group</code> 및 <code>Treatment Group</code>을 선정한다.</p><p>이외에도 <strong>변수조작법(IV)</strong> , <strong>차의 차 분석(DID)</strong> , <strong>경향스코어 매칭(PS)</strong> , <strong>회귀불연속 디자인(RDD)</strong> 등이 있다.</p></li></ul><h3><span id="level-3-관찰observation-레벨">Level 3. 관찰(Observation) 레벨</span></h3><ul><li><p><em>독립변수를 조작할 수 없고, 연구대상을 무작위할 수 없는 경우</em> 이다. 어느 한 시점에서 독립변수와 종속변수 모두를 측정해서 상관관계를 파악하는데에 그친다.</p></li><li><p>선후관계가 파악되지 않았고, 무작위화를 통해 동일한 집단에서 비교하지 못했으므로 부적절한 해석을 하게 될 위험을 가지고 있다.</p></li><li><p><strong>확증편향</strong> <span class="math inline">\(^{[*1]}\)</span>(confirmation bias) 이나 <strong>사후해석편향</strong> <span class="math inline">\(^{[*2]}\)</span>(hindsight bias)에 영향을 받기 쉽다. 예를 들어, 시책 담당자가 좋은 결과만을 보고 싶다고 하면 집계의 방법을 유리하게 설정해서 유리한 결과가 나오도록 하는 것이 얼마든지 가능하므로 주의가 필요하다.</p><ul><li><p><code>Level 3</code>은 <code>Level 1</code>&amp; <code>Level 2</code>를 한 후에 추가적으로 검토하는 용도.</p></li><li><p>또한, 집계의 방법을 미리 정해놓는 것을 통해, 자의적으로 변경해서 입맛에 맞는 해석을 하지 않는 것이 중요하다.</p></li></ul></li></ul><p><br></p><p>####【여기서 기억해야 할 것】 Lv1 <span class="math inline">\(\rightarrow\)</span> Lv2 <span class="math inline">\(\rightarrow\)</span> Lv3 의 순서로 시책의 효과를 검토해가는 것이 중요하다!!</p><p><br></p><p>&lt;span style="font-size: 85%;&gt; <span class="math inline">\(^{[*1]}:\)</span> 원하는 정보를 선택적으로 모으는 등의 가지고 있는 신념을 확인하려는 경향성. </p><p>&lt;span style="font-size: 85%;&gt; <span class="math inline">\(^{[*2]}:\)</span> 어떤 사건이 발생한 후, 사전에 그런 일이 일어날 것으로 예상했었다는 식으로 문제를 처리하는 것. 실제로는 벌어진 사건에 대해 전혀 대비를 하지 못하고, 그 원인을 냉정하게 규명해야 함에도 불구하고 "충분히 예측했던 일"이라며 자기 확신에 빠지는 것.</p><hr><h1><span id="potential-outcome-framework">* Potential Outcome Framework</span></h1><hr><ul><li><p><strong>처치(Treatment) 혹은 개입(Intervention)이 이뤄졌는지 여부</strong></p><p><span class="math inline">\(\begin{equation}Z_i= \left \{\begin{array}{l}1　(Treated) \\0　(Untreated)\end{array}\right.\end{equation}\)</span><br><br></p></li><li><p><strong>종속변수(DV; Dependent Variable) 혹은 목적변수(Criterion Variable)</strong> ; 개입을 받은 경우와 받지 않은 경우 두가지로 나타낼 수 있다.<br><em>(실제로는 어느 한쪽만 관찰가능하지만)</em></p><p><span class="math inline">\(\begin{equation}Y_i= \left \{\begin{array}{l}Y_i^{(1)}　(Z_i = 1) \\Y_i^{(0)}　(Z_i = 0)\end{array}\right.\end{equation}\)</span></p><p><span class="math inline">\(\Rightarrow Y_i = Y_i^{(0)}(1- Z_i) + Y_i^{(1)}Z_i\)</span></p></li></ul><p><br></p><ul><li><p>이와 같이, 샘플 <span class="math inline">\(i\)</span> 에 대하여 개입을 받은 경우의 결과 <span class="math inline">\(Y^{(1)}\)</span> 와 받지 않은 경우의 결과 <span class="math inline">\(Y^{(0)}\)</span> 간의 차이가 개입의 진정한 <strong>처치효과(TE; Treatment Effect)</strong> 라고 가정하는 것을 <strong>Potential Outcome Framework</strong> 라고 한다.</p><p><span class="math inline">\(\bf \tau_{TE} = Y^{(1)}-Y^{(0)}\)</span></p></li></ul><p><br></p><ul><li><p>모든 샘플 <span class="math inline">\(i\)</span> 에 대해 각각의 처치효과를 구하는 것은 까다롭기 떄문에, 그룹간의 비교로써 <strong>평균처치효과(ATE; Average Treatment Effect)</strong> 를 다루는 경우도 많다.</p><p><span class="math inline">\(\bf \tau_{ATE}= E[Y^{(1)}]-E[Y^{(0)}]\)</span></p></li></ul><p><br></p><hr><h1><span id="level-1-실험레벨-인과추론의-기초-rct">* Level 1. 실험레벨 ; 인과추론의 기초, RCT</span></h1><hr><h3><span id="-rct의-특징">- RCT의 특징</span></h3><ul><li><p>비즈니스의 관점에서는 <strong>AB테스트</strong> 라고 할 수 있다.</p></li><li><p>RCT (Randomized Controlled Trial; 무작위화 비교 실험)를 통해 <code>Control Group</code>과 <code>Treatment Group</code>을 무작위하게 나눔으로써 <strong>두 그룹간의 동질성</strong> 을 기대할 수 있다.</p></li><li><p>측정된 교란인자(confounding factors)<span class="math inline">\(^{[*1]}\)</span>는 물론, <strong>측정되지 않은 교란인자</strong> 에 대해서도 비교군과 대조군의 균형을 이룬다.<br>(측정되지 않은 교란인자 까지 처리할 수 있는 실험디자인은 <strong>RCT</strong>와 완벽하게 설계된 조작변수법(IV), 분할시계열디자인(ITS) 밖에 존재하지 않는다.)</p></li><li><p>그로 인해 모든 연구 디자인 중 가장 높은 내적타당성<span class="math inline">\(^{[*2]}\)</span>을 기대할 수 있다.</p></li><li><p>즉 RCT에서는 이론상, <span class="math inline">\(ATU = ATT = ATE\)</span>을 기대할 수 있다.</p><p>( <span class="math inline">\(ATU\)</span> <em>(Average Treatment Effect on the Untreated)</em> <span class="math inline">\(= E[Y^{(1)}|Z=0] - E[Y^{(0)}|Z=0]\)</span> )</p><p>( <span class="math inline">\(ATT\)</span> <em>(Average Treatment Effect on the Treated)</em> <span class="math inline">\(= E[Y^{(1)}|Z=1] - E[Y^{(0)}|Z=1]\)</span> )</p><p>( <span class="math inline">\(\bf ATE\)</span> <strong>(Average Treatment Effect)</strong> <span class="math inline">\(\bf = E[Y^{(1)}] - E[Y^{(0)}]\)</span> )</p></li></ul><p><br></p><p><img src="https://i.imgur.com/waDPtS0.png" width="600px"></p><p>[*] 위의 표에서 <code>Control Group</code>의 <span class="math inline">\(Y_i^{(1)}\)</span>과 <code>Treatment Group</code>의 <span class="math inline">\(Y_i^{(0)}\)</span>은 실제로 관찰 불가능한 반사실적 <strong>Potential Outcome</strong> 이다.</p><p><br></p><h3><span id="-rct의-의의">- RCT의 의의</span></h3><ul><li><p><strong>선택바이어스(Selection Bias)</strong> 의 제거</p></li><li><p>조작변수 이외의 다른 변수들을 통제하지 못한 채 <code>Control Group</code>과 <code>Treatment Group</code> 선택하게 되면, 그룹간의 동질성을 확보하지 못하여 <strong>교란변수(confounding factor)</strong> 에 의해 효과가 왜곡 될 수있다. 이러한 것을 <strong>선택 바이어스</strong> 라고 한다.</p></li><li><p>RCT는 완전 무작위로 처치그룹을 선택하기 때문에 <strong>선택 바이어스</strong> 에서 자유로워질 수 있다.</p></li></ul><p><br></p><h3><span id="-rct의-약점">- RCT의 약점</span></h3><p>(1). 비용(예산, 시간 등)이 많이 든다.</p><p>(2). 외적타당성(일반화 가능성)<span class="math inline">\(^{[*3]}\)</span></p><ul><li>RCT에서는 비용의 문제로 인해 외부조건을 통제하게 되고 그로인해 외적타당성은 낮아질 수 있다.</li></ul><p>(3). noncompliance 문제</p><ul><li>RCT에서 무작위로 그룹을 배분해도 거기에 따르지 않는 사람이 생겨서 나타나는 문제</li></ul><p>(4). <em>(특히 기업의 AB테스트에서)</em> 다른 RCT를 같은 대상자에 겹쳐서 실행하게 될 경우, 그에 따른 바이어스가 생길 수 있다.</p><ul><li>통계적으로 처리하기가 상당히 복잡해진다.</li></ul><p><br><br>&lt;span style="font-size: 85%;&gt; <span class="math inline">\(^{[*1]}:\)</span> '원인'과 '결과' 양쪽 모두에게 공통의 원인이 되는 요인. Graphical Model에서 공통부모, 분기로 표현되는 부분. 내생성(Endogeneity)으로도 표현한다. </p><p>&lt;span style="font-size: 85%;&gt; <span class="math inline">\(^{[*2]}:\)</span> 다른 외생변수들이 종속변수에 영향을 주지 않고 진정한 독립변수 의 효과인가의 타당성. </p><p>&lt;span style="font-size: 85%;&gt; <span class="math inline">\(^{[*3]}:\)</span> 내적타당성을 높이기 위해 실험조건을 엄격히 통제한다면 일반화 가능성이 낮아질 수 있다. 얼마나 일반적 현실에 확장 가능한지의 타당성. </p><hr><h2><span id="reference">* Reference</span></h2><p>해당 포스트는 <a href="https://www.youtube.com/watch?v=u8hsTkLg2xc&amp;t=159s">유튜브 채널「データの科学のメソドロジー」의 山田典一님의 강의</a>를 틀로 내용을 정리 &amp; 추가 했음을 밝힙니다.</p><p>그 외 참조</p><p><a href="https://www.amazon.co.jp/dp/4297111179/ref=cm_sw_r_tw_dp_U_x_-LQxEbJ8JDZ1N">効果検証入門〜正しい比較のための因果推論/計量経済学の基礎 （安井翔太）</a></p><p><a href="https://www.rieti.go.jp/jp/publications/dp/19j003.pdf">RCTをめぐる3つの問題とその解法（山口一男）</a></p><p><a href="https://healthpolicyhealthecon.com/2015/02/23/experiment-and-quasi-experiment-1/">実験（Experiment）と疑似実験（Quasi-experiment）に関する記事(津川友介)</a></p><p><a href="http://blog.daum.net/sangrimza/15612241">http://blog.daum.net/sangrimza/15612241</a></p><p><a href="https://m.blog.naver.com/PostView.nhn?blogId=lucifer246&amp;logNo=201407281&amp;proxyReferer=https:%2F%2Fwww.google.com%2F">https://m.blog.naver.com/PostView.nhn?blogId=lucifer246&amp;logNo=201407281&amp;proxyReferer=https:%2F%2Fwww.google.com%2F</a></p>]]></content:encoded>
      
      
      <category domain="https://jaysung00.github.io/categories/KOR/">KOR</category>
      
      <category domain="https://jaysung00.github.io/categories/KOR/%ED%86%B5%EA%B3%84%EC%A0%81%EC%9D%B8%EA%B3%BC%EC%B6%94%EB%A1%A0/">통계적인과추론</category>
      
      <category domain="https://jaysung00.github.io/categories/KOR/%ED%86%B5%EA%B3%84%EC%A0%81%EC%9D%B8%EA%B3%BC%EC%B6%94%EB%A1%A0/ML/">ML</category>
      
      
      <category domain="https://jaysung00.github.io/tags/causal/">causal</category>
      
      <category domain="https://jaysung00.github.io/tags/%ED%86%B5%EA%B3%84%EC%A0%81-%EC%9D%B8%EA%B3%BC%EC%B6%94%EB%A1%A0/">통계적 인과추론</category>
      
      
      <comments>https://jaysung00.github.io/2020/11/30/CI1/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>【 도대체 베이지안 네트워크가 뭐야? ①】</title>
      <link>https://jaysung00.github.io/2020/11/14/BN1/</link>
      <guid>https://jaysung00.github.io/2020/11/14/BN1/</guid>
      <pubDate>Sat, 14 Nov 2020 14:15:12 GMT</pubDate>
      
      <description>&lt;hr /&gt;</description>
      
      
      
      <content:encoded><![CDATA[<hr><a id="more"></a><h1><span id="베이지안-네트워크bn-bayesian-network-란">* 베이지안 네트워크(BN; Bayesian Network) 란?</span></h1><hr><ul><li>확률 변수(RV; Random variables)들 사이의 조건부 독립 등의 관계를 보임으로써, RV의 full joint distribution등을 간결하게 표현할 수 있는 <strong>그래프 표기법 (Graphical Notation)</strong> 이다.</li></ul><p><br></p><ul><li><p>여기서 <strong>그래프(Graph)</strong> 란, 수학에서 차트(Chart)와 대조되어 정의된 <code>node</code>와 <code>edge</code>의 집합</p><ul><li><p><code>edge</code>가 방향이 지정되어 있으면 <code>directed</code>, 그렇지 않으면 <code>undirected</code></p></li><li><p>그래프의 모든 <code>edge</code>가 <code>directed</code>일 때 <code>directed graph</code></p></li><li><p><code>directed edge</code>에서, 시작되는 쪽의 노드를 <code>parent node</code> 라고 하고 반대쪽은 <code>child node</code>라고 한다</p></li><li><p>복수의 연결된 <code>directed edge</code>의 방향이 같은 경우 이를 <code>directed path</code>라고 하고, <code>directed path</code>의 첫 번째 노드는 경로상의 모든 노드들의 <code>ancestor node</code>이고, 반대로 나머지 노드들은 첫번째 노드의 <code>descendant node</code>이다.</p></li><li><p><code>directed path</code>의 시작점과 끝점이 일치할 경우 이를 <code>cyclic</code>이라 하고, 그렇지 않은 경우 <code>acyclic</code>라고 한다.</p></li></ul></li></ul><p><br></p><ul><li><p><strong>베이지안 네트워크(BN)</strong> 의 <strong>Syntax</strong></p><ul><li><p><code>Network</code> 는 <code>Node</code>와 이들을 연결시키는 <code>Edge</code>로 구성된다</p></li><li><p><code>방향성 비순환 그래프(DAG; Directed Acyclic Graph)</code> 가 되어야 한다</p></li><li><p>개별 <code>Node</code>들은 RV인 <span class="math inline">\(X\)</span>에 대해 <span class="math inline">\(\bf P(X | Paranets(X))\)</span>를 의미한다.</p></li><li><p>개별 <code>Edge</code>들은 부모가 자식에게 주는 <strong>직접적인 영향(Direct Influence)</strong> 을 의미한다.</p></li></ul></li></ul><p><br></p><hr><h1><span id="먼저-확률에-대한-간단한-복습부터">* 먼저 확률에 대한 간단한 복습부터</span></h1><hr><ul><li><strong>베이지안 네트워크</strong> 라는 것은 결국 <em>확률변수(RV) 간의 관계</em> 를 표현한 것이다.<br></li><li><strong>확률</strong> 이라는 것은 <em>상대적인 빈도</em> 이다.<br><br></li></ul><blockquote><p>독립성 (Independence)</p></blockquote><ul><li><p><span class="math inline">\(P(A|B) = P(A)\)</span></p><p><span class="math inline">\(\Leftrightarrow P(A,B) = P(A)P(B)\)</span></p><p><span class="math inline">\(\Leftrightarrow P(B|A) = P(B)\)</span>; A와 B가 독립이면, B는 A와 독립이다.</p><ul><li><p>사건B가 발생했다는 정보는 사건A가 발생할 확률에 추가적인 정보를 제공하지 못한다.</p></li><li><p>이는, 밑에 서술하는 Conditional Independence 와 대립되는 의미로 Marginal Independence 라고 할 수 있다.</p></li></ul></li></ul><p><br></p><blockquote><p>조건부 독립 (Conditional Independence)</p></blockquote><ul><li><p><span class="math inline">\(P(A|B,C) = P(A|C)\)</span></p><ul><li>사건C가 주어졌을 때 두 사건 A와 B가 독립인 경우, 이것은 C라는 조건하에서 <em>조건부 독립</em> 이다.</li></ul></li></ul><p><br></p><blockquote><p>조건부 확률 (Conditional Probability)</p></blockquote><ul><li><p><span class="math inline">\(P(A= true|B=true)\)</span></p><ul><li><p>"Probablity of A given B"</p></li><li><p>B가 주어졌을 때, A의 확률<br><br></p></li></ul></li></ul><blockquote><p>결합 확률 (joint Probability)</p></blockquote><ul><li><p><span class="math inline">\(P(A= true, B=true)\)</span></p><ul><li><p>"the probability of A=true <strong>and</strong> B=true"</p></li><li><p>A=true와 B=true가 동시에 만족할 확률</p></li><li><p><strong>조건부 확률과 결합 확률의 관계</strong> 는 일반적으로, <span class="math inline">\(P(X|Y) =\cfrac{P(X,Y)}{P(Y)}\)</span><br><br></p></li></ul></li></ul><blockquote><p>총 확률 법칙 (Law of Total Probability)</p></blockquote><ul><li><p>"Summing out" or "Marginalization"</p></li><li><p><span class="math inline">\(P(A) = \sum_kP(A,B_k) = \sum_kP(A|B_k)P(B_k)\)</span></p><ul><li><p><span class="math inline">\(P(A) = \sum_kP(A,B_k)\)</span> 는 <span class="math inline">\(B_1,B_2,...,B_n\)</span>이 각각 상호배반적인 집합이고 이들의 합집합이 전체집합이 되므로 성립 (marginalize)</p></li><li><p><span class="math inline">\(\sum_kP(A,B_k) = \sum_kP(A|B_k)P(B_k)\)</span>는 조건부확률과 결합확률의 관계를 이용하면 유도가능<br><br></p></li></ul></li><li><p>이로 인한 이점은, <span class="math inline">\(P(A)\)</span>를 직접 구하는 것보다, <span class="math inline">\(P(A|B_k)\)</span>와 같은 조건부확률을 구해서 합치는 것이 일반적으로 더 수월하다는 것이다.</p></li><li><p>혹은 결합확률을 알고 있을 때, 여러가지 확률을 계산 할 수 있다.</p><ul><li><p>예를들어, 결합확률인 <span class="math inline">\(P(a,b,c,d)\)</span>를 알고 있을 때, <span class="math inline">\(P(c|b)\)</span>는 이렇게 표현할 수 있다</p></li><li><p><span class="math inline">\(P(c|b) = \sum_a \sum_d P(a,c,d|b) = \cfrac{1}{P(b)}\sum_a \sum_d {\bf P(a,b,c,d)}\)</span></p></li><li><p>그러나 joint의 경우에는 parameter의 수가 exponential하게 늘어나게 된다! (Chain Rule의 필요성)</p></li></ul></li></ul><p><br></p><blockquote><p>확률의 연쇄법칙 (Chain Rule for probability)</p></blockquote><ul><li><p>모든 joint distribution에 대해, 결합확률과 조건부확률의 관계에 의해 언제나 이하와 같이 표현할 수 있다.</p></li><li><p><span class="math inline">\(P(a,b,c,...,z) = P(a|b,c,...,z)P(b,c,....,z)\)</span></p></li><li><p>이것을 반복적으로 하면, <span class="math inline">\(P(a,b,c,...,z) = P(a|b,c,...,z)P(b|c,...,z)P(c|d,...,z)...P(z)\)</span>로 표현 가능하다. (Factorization)</p></li></ul><p><br></p><blockquote><p>곱 분해 법칙 (Rule of product decomposition)</p></blockquote><ul><li><p>Bayesian Network에서는 그래프에 속한 RV의 결합분포(joint distribution)는 <code>family</code>의 모든 조건부 분포 <span class="math inline">\(P(Child|Parent)\)</span>의 곱<span class="math inline">\(^{[*1]}\)</span>으로 표현 할 수 있다. <em>(시리즈의 다음 포스트의 Factorization of Bayes Network 내용 참조)</em></p></li><li><p><span class="math inline">\(P(x_1,x_2,...,x_n) = \prod _iP(x_i|Parents(x_i))\)</span></p><ul><li><p>Parents는 직접적으로 연결되어 영향을 받는 변수만을 의미!</p></li><li><p>예를 들어, <span class="math inline">\(X\rightarrow Y \rightarrow Z\)</span> 인 그래프에서 <span class="math inline">\(P(X=x, Y=y, Z=z)\)</span>를 구하는 것을 생각해보자</p></li><li><p>원래는 가능한 모든 조합의 <span class="math inline">\((x, y, z)\)</span>에 해당하는 확률 테이블을 만들어야 한다</p></li><li><p>그러나, 이 법칙을 이용하면 <span class="math inline">\(P(X=x, Y=y, Z=z) = P(X=x)P(Y=y|X=x)P(Z=z|Y=y)\)</span>로 간결하게 표현 가능</p></li><li><p>이처럼 고차원을 저차원으로 만들어 <em>차원의 저주(curse of dimensionality)</em> 에서도 비교적 자유로워 질 수 있다.</p></li></ul></li></ul><p><br></p><p>&lt;span style="font-size: 85%;&gt; <span class="math inline">\(^{[*1]}:\)</span> 이렇게 정의되는 원래는 뒤에서 기술하는 베이지안 네트워크의 Typical Local Structures Rules와 관련 되어있다. </p><hr><h1><span id="베이지안-네트워크의-rules-of-typical-local-structures">* 베이지안 네트워크의 Rules of Typical Local Structures</span></h1><hr><p><br></p><blockquote><p>Rule 1. 사슬 혹은 폭포형 (Chain or Cascading)</p></blockquote><p><img src="https://i.imgur.com/IF5m1WL.png"></p><ul><li><p>변수<span class="math inline">\(X\)</span>와 변수<span class="math inline">\(Y\)</span>의 사이에 하나의 방향성 경로 만 있고 변수<span class="math inline">\(Z\)</span>가 해당 경로를 가로막고 있는 경우, <strong><span class="math inline">\(Z\)</span>가 조건부로 주어졌을때 두 변수 <span class="math inline">\(X\)</span>와 <span class="math inline">\(Y\)</span>는 조건부 독립</strong> 이다.</p></li><li><p><span class="math inline">\(X \perp Y|Z\)</span><br><span class="math inline">\(\Leftrightarrow P(Y|X,Z) = P(Y|Z)\)</span></p></li></ul><p><br></p><blockquote><p>Rule 2. 분기 혹은 공통부모형 (Fork or Common parent)</p></blockquote><p><img src="https://i.imgur.com/mIdGQWD.png"></p><ul><li><p>변수 <span class="math inline">\(Z\)</span>가 <span class="math inline">\(X\)</span>와 <span class="math inline">\(Y\)</span>의 공통 원인이고 <span class="math inline">\(X\)</span>와 <span class="math inline">\(Y\)</span>사이에 단 하나의 경로가 있는 경우, <strong><span class="math inline">\(Z\)</span>의 조건이 주어졌을 때 <span class="math inline">\(X\)</span>와 <span class="math inline">\(Y\)</span>는 조건부 독립</strong> 이다.</p></li><li><p><span class="math inline">\(X \perp Y | Z\)</span><br><span class="math inline">\(\Leftrightarrow P(X,Y|Z) = P(X|Z)P(Y|Z)\)</span></p></li></ul><p><br></p><blockquote><p>Rule 3. 충돌부 혹은 V-구조 (Collider or V-structure)</p></blockquote><p><img src="https://i.imgur.com/9HLO4Ad.png"></p><ul><li><p>변수 <span class="math inline">\(Z\)</span>가 두 변수 <span class="math inline">\(X\)</span>와 <span class="math inline">\(Y\)</span> 사이의 충돌 노드이고 <span class="math inline">\(X\)</span>와 <span class="math inline">\(Y\)</span> 사이에 단 <em>하나의 경로</em> 만 있을 경우, <strong><span class="math inline">\(X\)</span>와 <span class="math inline">\(Y\)</span>는 비조건부 독립(underconditionally independent)</strong> 이다. 그러나 <strong><span class="math inline">\(Z\)</span> 또는 <span class="math inline">\(Z\)</span>의 <code>descendant</code>을 조건부로 하였을 때 <span class="math inline">\(X\)</span>와 <span class="math inline">\(Y\)</span>는 종속적일 가능성</strong> 이 있다.</p></li><li><p><span class="math inline">\(\sim (X \perp Y|Z)\)</span><br><span class="math inline">\(\Leftrightarrow P(X,Y,Z)=P(X)P(Y)P(Z|X,Y)\)</span></p></li><li><p>즉 <span class="math inline">\(Z\)</span>가 not given 일 때는 독립이지만, 반대로 <span class="math inline">\(Z\)</span>가 given으로 주어지면 <span class="math inline">\(X\)</span>, <span class="math inline">\(Y\)</span>가 종속적이 될 가능성이 생겨버린다.</p></li></ul><p><br></p><hr><h1><span id="bayes-ball-algorithm">* Bayes Ball Algorithm</span></h1><hr><ul><li><p>목적 ; <span class="math inline">\(X \perp Y | Z\)</span> (<span class="math inline">\(Z\)</span>가 given일 때 <span class="math inline">\(X\)</span>와 <span class="math inline">\(Y\)</span>가 독립) 이 성립하는지 여부를 판정하기 위한 알고리즘</p></li><li><p><span class="math inline">\(X\)</span>에서 공이 출발한다고 가정했을 때 <span class="math inline">\(Y\)</span>까지 공이 도달하는지 확인하는 방법</p></li><li><p>여기서 공은 <code>Information</code>을 의미하고 화살표는 공의 움직임을 의미한다. 노드 간이 직접적인 edge로 연결되어 있지 않더라도 공이 굴러가서 도달할 수 있다면 <code>Indirect influence</code>가 존재하기때문에 두 변수는 <code>depedent</code>하다는 것을 의미한다.</p></li></ul><p><br></p><blockquote><p>Rule 1의 경우</p></blockquote><p>(1). <span class="math inline">\(Z\)</span>가 given이 아닐 때, 공은 지나갈 수 있다. (<span class="math inline">\(X, Y\)</span>는 종속)<br><img src="https://i.imgur.com/A5X39bt.png" width="298px"></p><p>(2). <span class="math inline">\(Z\)</span>가 <strong>given</strong> 일 때, 공은 지나갈 수 없다. (<span class="math inline">\(X \perp Y|Z\)</span>)<br><img src="https://i.imgur.com/k6dl20u.png" width="300px"></p><p><br></p><blockquote><p>Rule 2의 경우</p></blockquote><p>(1). <span class="math inline">\(Z\)</span>가 given이 아닐 때, 공은 지나갈 수 있다. (<span class="math inline">\(X, Y\)</span>는 종속)<br><img src="https://i.imgur.com/8mPvc3A.png" width="300px"></p><p>(2). <span class="math inline">\(Z\)</span>가 <strong>given</strong> 일 때, 공은 지나갈 수 없다. (<span class="math inline">\(X \perp Y|Z\)</span>)</p><p><img src="https://i.imgur.com/hssut55.png" width="300px"></p><p><br></p><blockquote><p>Rule 3의 경우</p></blockquote><p>(1). <span class="math inline">\(Z\)</span>가 <strong>given이 아닐 때, 공은 지나갈 수 없다.</strong> (<span class="math inline">\(\bf X \perp Y\)</span>)<br><img src="https://i.imgur.com/yhO2p9I.png" width="300px"></p><p>(2). <span class="math inline">\(X_C\)</span>가 <strong>given</strong> 일 때, 반대로 path가 생겨서 공이 지나갈 수 있게 된다. (<span class="math inline">\(X, Y\)</span>는 <strong>종속</strong> <span class="math inline">\(|Z\)</span>)</p><p><img src="https://i.imgur.com/Y6SAkrl.png" width="300px"></p><p><br></p><blockquote><p>Bayes Ball Algorithm 연습</p></blockquote><p><img src="https://i.imgur.com/7He2cq7.png" width="350px"></p><p><br></p><ul><li><p><strong>문제 1.</strong> <span class="math inline">\(X_1\perp X_4|X_2\)</span></p><p>두가지 경로로 공을 굴릴 수 있다.</p><p>(1). <span class="math inline">\(X_1 \rightarrow {\bf X_2}(given) \rightarrow X_4\)</span> 의 경로는 <span class="math inline">\(X_2\)</span>가 사슬의 given으로 막혀있으므로 지나갈 수 없다.</p><p>(2). <span class="math inline">\(X_1 \rightarrow X_3 \rightarrow X_5 \rightarrow X_6 \leftarrow {\bf X_2}(given) \rightarrow X_4\)</span> 의 경로는 <span class="math inline">\(X_6\)</span>가 충돌부의 not given으로 막혀있으므로 지나갈 수 없다.</p><p>따라서 어떠한 경로로도 볼은 지나갈수 없으므로 <strong><span class="math inline">\(X_2\)</span>가 given일 때 <span class="math inline">\(X_1\)</span>와 <span class="math inline">\(X_4\)</span>는 독립</strong> 이다.</p></li></ul><p><br></p><ul><li><p><strong>문제 2.</strong> <span class="math inline">\(X_2\perp X_5|X_1\)</span></p><p>두가지 경로로 공을 굴릴 수 있다.</p><p>(1). <span class="math inline">\(X_2 \rightarrow X_6 \leftarrow X_5\)</span> 의 경로는 <span class="math inline">\(X_6\)</span>가 충돌부의 not given으로 막혀있으므로 지나갈 수 없다.</p><p>(2). <span class="math inline">\(X_2 \leftarrow {\bf X_1}(given) \rightarrow X_3 \rightarrow X_5\)</span> 의 경로는 <span class="math inline">\(X_1\)</span>가 분기의 given으로 막혀있으므로 지나갈 수 없다.</p><p>따라서 어떠한 경로로도 볼은 지나갈수 없으므로 <strong><span class="math inline">\(X_1\)</span>가 given일 때 <span class="math inline">\(X_2\)</span>와 <span class="math inline">\(X_5\)</span>는 독립</strong> 이다.</p></li></ul><p><br></p><ul><li><p><strong>문제 3.</strong> <span class="math inline">\(X_1\perp X_6|\{X_2, X_3\}\)</span></p><p>두가지 경로로 공을 굴릴 수 있다.</p><p>(1). <span class="math inline">\(X_1 \rightarrow {\bf X_2}(given) \rightarrow X_6\)</span> 의 경로는 <span class="math inline">\(X_2\)</span>가 사슬의 given으로 막혀있으므로 지나갈 수 없다.</p><p>(2). <span class="math inline">\(X_1 \rightarrow {\bf X_3}(given) \rightarrow X_5 \rightarrow X_6\)</span> 의 경로는 <span class="math inline">\(X_3\)</span>가 사슬의 given으로 막혀있으므로 지나갈 수 없다.</p><p>따라서 어떠한 경로로도 볼은 지나갈수 없으므로 <strong><span class="math inline">\(\{X_2, X_3\}\)</span>가 given일 때 <span class="math inline">\(X_1\)</span>와 <span class="math inline">\(X_6\)</span>는 독립</strong> 이다.</p></li></ul><p><br></p><ul><li><p><strong>문제 4.</strong> <span class="math inline">\(X_2\perp X_3|\{X_1, X_6\}\)</span></p><p>두가지 경로로 공을 굴릴 수 있다.</p><p>(1). <span class="math inline">\(X_2 \leftarrow {\bf X_1}(given) \rightarrow X_3\)</span> 의 경로는 <span class="math inline">\(X_1\)</span>가 분기의 given으로 막혀있으므로 지나갈 수 없다.</p><p>(2). <span class="math inline">\(X_2 \rightarrow {\bf X_6}(given) \leftarrow X_5 \leftarrow X_3\)</span> 의 경로는 <span class="math inline">\(X_6\)</span>가 충돌부의 given으로 뚫려있으므로 지나갈 수 있다.</p><p>따라서 두번째 경로로 볼은 지나갈 수 있으므로 <strong><span class="math inline">\(\{X_1, X_6\}\)</span>가 given일 때 <span class="math inline">\(X_2\)</span>와 <span class="math inline">\(X_3\)</span>는 독립이 성립하지 않는다.</strong></p></li></ul><p><br></p><hr><h1><span id="d-seperation의-정의">* <span class="math inline">\(d\)</span>-Seperation의 정의</span></h1><hr><ul><li><p><span class="math inline">\(d\)</span>는 방향성(directly)을 의미한다.</p></li><li><p>Bayesian Ball Algorithm으로 <span class="math inline">\(d\)</span>-Seperation을 확인할 수 있다.</p></li><li><p>정리하자면, 경로p가 조건부집합 <span class="math inline">\(\{W\}\)</span>에 의해 <span class="math inline">\(d\)</span>-Seperate된다는 명제는 이하와 필요충분조건이다.</p><ol type="1"><li><p>경로p는 조건부집합 <span class="math inline">\(\{W\}\)</span>에 속하는 중간노드 <span class="math inline">\(Z\)</span> 의 사슬 <span class="math inline">\(X \rightarrow Z \rightarrow Y\)</span> 또는 분기 <span class="math inline">\(X \leftarrow Z \rightarrow Y\)</span> 를 포함한다.</p></li><li><p>경로p는 조건부집합 <span class="math inline">\(\{W\}\)</span>에 속하지 않는 중간노드 <span class="math inline">\(Z&#39;\)</span> 의 충돌부 <span class="math inline">\(X \rightarrow Z&#39; \leftarrow Y\)</span> 를 포함한다.</p></li></ol></li></ul><p><br></p><hr><h2><span id="reference">* Reference</span></h2><p>해당 포스트는 <a href="https://www.edwith.org/machinelearning2__17/joinLectures/9782">Edwith에 개설된 문일철 교수님의 인공지능 및 기계학습 개론 II 강의</a>를 정리 &amp; 추가한 내용임을 밝힙니다.</p><p>추가 내용 참조</p><p><a href="http://www.kyobobook.co.kr/product/detailViewKor.laf?ejkGb=KOR&amp;mallGb=KOR&amp;barcode=9791125102236">의학 및 사회과학 연구를 위한 통계적 인과추론 （Judea Pearl, Madelyn Glymour, Nicholas P. Jewell）</a></p>]]></content:encoded>
      
      
      <category domain="https://jaysung00.github.io/categories/KOR/">KOR</category>
      
      <category domain="https://jaysung00.github.io/categories/KOR/%ED%86%B5%EA%B3%84%EC%A0%81%EC%9D%B8%EA%B3%BC%EC%B6%94%EB%A1%A0/">통계적인과추론</category>
      
      <category domain="https://jaysung00.github.io/categories/KOR/%ED%86%B5%EA%B3%84%EC%A0%81%EC%9D%B8%EA%B3%BC%EC%B6%94%EB%A1%A0/ML/">ML</category>
      
      
      <category domain="https://jaysung00.github.io/tags/causal/">causal</category>
      
      <category domain="https://jaysung00.github.io/tags/KMOOC/">KMOOC</category>
      
      
      <comments>https://jaysung00.github.io/2020/11/14/BN1/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>【 도대체 베이지안 네트워크가 뭐야? ②】</title>
      <link>https://jaysung00.github.io/2020/11/14/BN2/</link>
      <guid>https://jaysung00.github.io/2020/11/14/BN2/</guid>
      <pubDate>Sat, 14 Nov 2020 14:15:12 GMT</pubDate>
      
      <description>&lt;hr /&gt;</description>
      
      
      
      <content:encoded><![CDATA[<hr><a id="more"></a><h1><span id="factorization-of-bayes-network">* Factorization of Bayes Network</span></h1><hr><ul><li><p>그래프에 속한 RV의 결합분포(joint distribution)는 <code>family</code>의 모든 조건부 분포 <span class="math inline">\(P(Child|Parent)\)</span>의 곱으로 표현 할 수 있다.</p></li><li><p><span class="math inline">\(P(X_1,X_2,...,X_n) = \prod _iP(X_i|Parents(X_i))\)</span></p></li><li><p><code>곱 분해 법칙 (Rule of product decomposition)</code></p></li><li><p>확률의 연쇄법칙 <span class="math inline">\(P(a,b,c,...,z) = P(a|b,c,...,z)P(b,c,....,z)\)</span>에서 사슬과 분기의 Rule에 따르면 부모노드가 given이면 이상은 조상노드는 전부 독립이게 되므로 성립. (충돌부는 부모노드가 아니다.)</p></li><li><p>즉, Bayes Network의 정보를 통해 joint distribution를 계산할 때 parameter의 갯수를 줄일 수 있다.</p></li></ul><p><br></p><p><span class="math inline">\([ 예시 ]\)</span><br><img src="https://i.imgur.com/tl4t2Iz.png" width="350px"></p><p><br></p><ul><li><span class="math inline">\(P(X_1,X_2,X_3,X_4,X_5,X_6,X_7,X_8)\)</span>를 구한다고 하자.</li></ul><ol type="1"><li><p><strong>확률의 연쇄법칙 (Chain Rule for probability)</strong> 에 의해 아무런 Bayesian Network의 정보가 없다고 하더라도 <span class="math inline">\(P(X_1,X_2,X_3,...,X_8) = P(X_1|X_2,X_3,...,X_8)P(X_2|X_3,...,X_8)P(X_3|X_4,...,X_8)...P(X_8)\)</span> 로 Factorize 할 수 있다.</p></li><li><p><strong>곱 분해 법칙 (Rule of product decomposition)</strong> 에 의해 Bayesian Network의 정보를 활용하면 <span class="math inline">\(P(X_1,X_2,X_3,...,X_8) = P(X_1)P(X_2)P(X_3|X_1)P(X_4|X_2)P(X_5|X_2)P(X_6|X_3,X_4)P(X_7|X_6)P(X_8|X_5,X_6)\)</span> 로 훨씬 작은 parameter만으로 Factorize 가능하다.</p></li></ol><p><br></p><hr><h1><span id="plate-notation">* Plate Notation</span></h1><hr><blockquote><p><span class="math inline">\(\begin{align} P(D|\theta) &amp;= P(X_1,...,X_N|\mu,\sigma) \\ &amp;= \prod_i^N P(X_i|\mu,\sigma) \end{align}\)</span></p></blockquote><p><img src="https://i.imgur.com/QqfT9En.png" width="700px"></p><ul><li>이처럼 여러 개의 독립적인 RV들에 대해 위와 같이 <strong>Plate Notation</strong> 로 표현하는 것이 가능하다.</li></ul><p><br></p><hr><h1><span id="베이지안-네트워크에서의-확률추론">* 베이지안 네트워크에서의 확률추론</span></h1><hr><ul><li><p>BN에 있는 모든 random variables ;<br><span class="math inline">\(X = \{X1 ... X_N\}\)</span></p></li><li><p>주어진 증거 변수 (given evidence variables) ;<br><span class="math inline">\(X_V =\{X_{k+1}...X_N\}\)</span><br><span class="math inline">\(x_V\)</span>는 evidence values</p></li><li><p>명시적으로 다루지는 않지만 관계가 있어서 감안할 필요가 있는 변수 (hidden variables) ;<br><span class="math inline">\(X_H = X-X_V = \{X_1...X_k\}\)</span></p></li><li><p>hidden variables ; <span class="math inline">\(X_H = \{Y,Z\}\)</span></p><ul><li><span class="math inline">\(Y\)</span> : query variable (interested hidden variables)<br></li><li><span class="math inline">\(Z\)</span> : uninterested hidden variables</li></ul></li></ul><p><br></p><h3><span id="1-1-주변확률-marginal-probability">1-1 주변확률 (Marginal Probability)</span></h3><blockquote><p>증거 변수 <span class="math inline">\(X_V\)</span> 의 <strong>주변확률 (Marginal Probability)</strong> <span class="math inline">\(P(x_V)\)</span> 는?</p></blockquote><p>      <span class="math inline">\(\begin{align} P(x_V) &amp;=\sum_{X_H}P(X)=\sum_{X_H}P(X_H,X_V) \space\space\space\space\space\space\dots(1)\\ &amp;= \sum_{x_1}...\sum_{x_k}P(x_1...x_k,x_V)\space\space\space\space\space\space\space\space\space\dots(2) \end{align}\)</span></p><ul><li><p>(1). 모든 변수에 대해 <strong>full joint</strong> 된 것을 <span class="math inline">\(X_H\)</span>로 marginalize out한 것이라고 생각한다.</p></li><li><p>(2). 각각의 Hidden variable에 대해 marginalize out한 것이라고 생각한다.</p></li></ul><p><br></p><h3><span id="1-2-조건부-확률-conditional-probability">1-2. 조건부 확률 (Conditional Probability)</span></h3><blockquote><p>주어진 증거(evidence)의 집합<span class="math inline">\(x_V\)</span>이 있을때, <strong>query variable(주어지지 않았지만 관심있는 변수)</strong> 의 <strong>조건부 확률</strong> <span class="math inline">\(P(Y|x_V)\)</span>은?</p></blockquote><p>      <span class="math inline">\(\begin{align} P(Y|X_V) &amp;= \sum_ZP(Y,Z = z|x_V) \space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\dots(1)\\ &amp;= \sum_Z\cfrac{P(Y,Z,x_V)}{P(x_V)} = \sum_Z\alpha P(X) \space\space\space\space\space\space\space\space\space\space\dots(2)\\ &amp;= \sum_Z \cfrac{P(Y,Z,x_V)}{\sum_{y,z}P(Y=y, Z=z, x_V)}\space\space\space\space\space\space\space\space\space\dots(3) \end{align}\)</span><br><br></p><ul><li><p>(1). <span class="math inline">\(Z\)</span>를 joint로 넣어주면서 <span class="math inline">\(Z\)</span>에 대해 marginalize out 한다.</p></li><li><p>(2). 조건부 확률의 정의를 이용해, <span class="math inline">\(x_V\)</span>를 포함한 <strong>full joint</strong> 를 <span class="math inline">\(P(x_V)\)</span> (Marginal Probability)로 나눈다.<br>(<span class="math inline">\(\cfrac{1}{P(x_V)} = \alpha\)</span>라는 정규화 상수(normalization constant)의 곱으로 생각할수도 있다.)</p></li><li><p>(3). 분모의 주변확률은 Inference Question1처럼 <strong>full joint</strong> 를 모든 Hidden variable에 대해 marginalize 해서 구할 수 있다.</p></li></ul><p><br></p><hr><h1><span id="변수제거-알고리즘-variable-eliminatation-algorithm">* 변수제거 알고리즘 (Variable Eliminatation Algorithm)</span></h1><hr><p><img src="https://i.imgur.com/suXGsdJ.png" width="750px"></p><blockquote><p>위와 같이 주어진 상황에서 변수제거 알고리즘으로 <span class="math inline">\(P(J=j)\)</span>를 구해보자</p></blockquote><h3><span id="step1">* Step1</span></h3><ul><li>위의 준비를 통해 베이지안 네트워크 상에서 관심있는 확률의 추론을 위해서, <strong>full joint</strong> 를 구하고 uninterested hidden variable에 대해 <strong>Marginalize</strong> 한다.</li></ul><p><br></p><ul><li><span class="math inline">\(\sum_{A,E,B,M} P(J= j,A,E,B,M)\)</span></li></ul><p><br></p><h3><span id="step2">* Step2</span></h3><ul><li><p><strong>full joint</strong> 를 Bayesina Network의 정보를 이용해 <em>곱분해 법칙</em>으로 바꿔 쓴다.</p></li><li><p>분해한 곱의 나열순서는 <strong>topological order</strong> <span class="math inline">\(^{[*1]}\)</span> 를 따른다.</p></li><li><p><strong>topological order</strong> ; B, E, A, J, M</p></li></ul><p><br></p><ul><li><span class="math inline">\(\sum_{B,E,A,M} P(B)P(E)P(A|B,E)P(J=j|A)P(M|A)\)</span></li></ul><p><br></p><p>&lt;span style="font-size: 85%;&gt; <span class="math inline">\(^{[*1]}:\)</span> 들어오는 화살표가 없는 노드 부터 하나씩 선택하며 지우는 것을 반복할때 결정되는 순서 </p><h3><span id="step3">* Step3</span></h3><ul><li><p>순서를 유지한 채 각 <span class="math inline">\(\sum\)</span>가 관련없는 것을 밖으로 빼낸다.</p></li><li><p>제거할 변수의 순서는 뒤에서부터 정해진다.</p></li></ul><p><br></p><ul><li><span class="math inline">\(\space\space\space\sum_B P(B)\sum_EP(E)\sum_AP(A|B,E)P(J=j|A)\sum_MP(M|A)\)</span></li></ul><p><br></p><h3><span id="step4">* Step4</span></h3><ul><li>뒤에서 부터 <strong>function notation</strong>으로 바꿔주면서 변수를 지워나간다.</li></ul><p><br></p><ol type="1"><li><span class="math inline">\(\space\space\space\sum_B P(B)\sum_EP(E)\sum_AP(A|B,E)P(J=j|A) \underline {\sum_MP(M|A)}\)</span></li></ol><ul><li><p><span class="math inline">\(=\sum_B P(B)\sum_EP(E)\sum_AP(A|B,E)P(J=j|A) \underline {\bf f_1(A)}\)</span></p><ul><li>밑줄친 부분은 J와 <span class="math inline">\(d\)</span>-seperate이기 때문에 고려할 필요가 없다. 즉, A의 값과 상관없이 <span class="math inline">\(f_1(A)\)</span>는 1을 갖는다.</li></ul></li></ul><p><img src="https://i.imgur.com/EnN5hP3.png" width="220px"></p><p><br></p><ol start="2" type="1"><li><span class="math inline">\(=\sum_B P(B)\sum_EP(E)\underline{\sum_AP(A|B,E)P(J=j|A)}\)</span></li></ol><ul><li><p><span class="math inline">\(=\sum_B P(B)\sum_EP(E)\underline {\bf f_2(E,B)}\)</span></p><ul><li><span class="math inline">\(f_2(E,B)\)</span>는 이하와 같다.</li></ul></li></ul><p><img src="https://i.imgur.com/BOhvHDZ.png" width="750px"></p><p><br></p><ol start="3" type="1"><li><span class="math inline">\(=\sum_B P(B)\underline {\sum_EP(E)f_2(B,E)}\)</span></li></ol><ul><li><p><span class="math inline">\(=\sum_B P(B) \underline {\bf f_3(B)}\)</span></p><ul><li><span class="math inline">\(f_3(B)\)</span>는 이하와 같다.</li></ul></li></ul><p><img src="https://i.imgur.com/A3u5hM9.png" width="750px"></p><p><br></p><ol start="4" type="1"><li><span class="math inline">\(= \sum_BP(B)f_3(B)\)</span></li></ol><ul><li><p><span class="math inline">\(= P(B=b)f_3(B=b) + P(B= \sim b)f_3(B=\sim b)\)</span></p></li><li><p><span class="math inline">\(=0.001 * 0.849017 + 0.999 * 0.0513413 \fallingdotseq 0.052139\)</span></p></li><li><p>따라서, <span class="math inline">\(P(J=j) = 0.052139\)</span> 가 된다.</p></li></ul><p><br></p><hr><h2><span id="reference">* Reference</span></h2><p>해당 포스트는 <a href="https://www.edwith.org/machinelearning2__17/joinLectures/9782">Edwith에 개설된 문일철 교수님의 인공지능 및 기계학습 개론 II 강의</a>를 정리 &amp; 추가한 내용임을 밝힙니다.</p><p>추가 내용 참조</p><p><a href="https://www.youtube.com/watch?v=TZnEJ4wvLPY">https://www.youtube.com/watch?v=TZnEJ4wvLPY</a></p><p><a href="http://www.kyobobook.co.kr/product/detailViewKor.laf?ejkGb=KOR&amp;mallGb=KOR&amp;barcode=9791125102236">의학 및 사회과학 연구를 위한 통계적 인과추론 （Judea Pearl, Madelyn Glymour, Nicholas P. Jewell）</a></p>]]></content:encoded>
      
      
      <category domain="https://jaysung00.github.io/categories/KOR/">KOR</category>
      
      <category domain="https://jaysung00.github.io/categories/KOR/%ED%86%B5%EA%B3%84%EC%A0%81%EC%9D%B8%EA%B3%BC%EC%B6%94%EB%A1%A0/">통계적인과추론</category>
      
      <category domain="https://jaysung00.github.io/categories/KOR/%ED%86%B5%EA%B3%84%EC%A0%81%EC%9D%B8%EA%B3%BC%EC%B6%94%EB%A1%A0/ML/">ML</category>
      
      
      <category domain="https://jaysung00.github.io/tags/causal/">causal</category>
      
      <category domain="https://jaysung00.github.io/tags/KMOOC/">KMOOC</category>
      
      
      <comments>https://jaysung00.github.io/2020/11/14/BN2/#disqus_thread</comments>
      
    </item>
    
  </channel>
</rss>
