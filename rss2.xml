<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"
  xmlns:atom="http://www.w3.org/2005/Atom"
  xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Jay Sung&#39;s DS blog</title>
    <link>https://jaysung00.github.io/</link>
    
    <atom:link href="https://jaysung00.github.io/rss2.xml" rel="self" type="application/rss+xml"/>
    
    <description></description>
    <pubDate>Thu, 17 Dec 2020 02:00:59 GMT</pubDate>
    <generator>http://hexo.io/</generator>
    
    <item>
      <title>【Uplift Modeling】Uplift tree에 관한 논문 내용 번역</title>
      <link>https://jaysung00.github.io/2020/12/17/Uplift-tree/</link>
      <guid>https://jaysung00.github.io/2020/12/17/Uplift-tree/</guid>
      <pubDate>Thu, 17 Dec 2020 01:53:17 GMT</pubDate>
      
      <description>&lt;p&gt;해당 포스팅은 Tree-based Uplift Modeling에 관련된 논문 및 문헌들의 번역임을 밝힙니다.&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<p>해당 포스팅은 Tree-based Uplift Modeling에 관련된 논문 및 문헌들의 번역임을 밝힙니다.</p><a id="more"></a><hr><p><strong><a href="https://stochasticsolutions.com/pdf/sig-based-up-trees.pdf">Radcliffe &amp; Surry (2011)</a></strong></p><h2><span id="real-world-uplift-modelling-with-significance-based-uplift-trees">Real-World Uplift Modelling with Significance-Based Uplift Trees</span></h2><p><br></p><h4><span id="section61-tree-based-uplift-modeling">Section6.1 Tree-based Uplift Modeling</span></h4><p>CART와 같이 두 가지로 분할하는 일반적 tree-based model의 <code>split(분할)</code>을 결정하는 기준의 아래의 두가지의 바람직한 속성들은 서로 trade-off 관계에 있다.</p><ul><li><p>두가지 하위그룹의 <code>outcome</code>을 최대화 화는 것</p></li><li><p>그러한 두가지 그룹의 <code>size</code>의 차를 최소화 하는 것</p></li></ul><p>일반적으로 극단적인 <code>outcome</code>을 보이는 작은 그룹을 찾는 것은 어렵지 않기 때문에 이것들은 본질적으로 충돌하는 경향이 있다. 예를 들어, 단 한명의 구매자 (100%의 구매율)만을 <code>split</code>해서 떼어내는 경우를 생각해볼 수 있다.</p><p>우리는 같은 관점으로, 다만 분할된 그룹들간의 <code>outcome</code>의 차이가 아닌 분할된 그룹들간의 <code>Uplift</code>의 차이를 Uplif trees의 split 조건으로써 접근할 것이다.</p><p><a href="https://www.sciencedirect.com/science/article/abs/pii/S1094996802701618">Hansotia &amp; Rukstales (2001)</a>의 방법은 Trade-off를 무시하고 직접적으로 <code>Uplift</code>의 차이(<span class="math inline">\(\Delta\Delta p\)</span>)를 사용한 결과이다. 우리는 이 접근법으로 좋은 결과를 얻지 못했다.</p><p>우리는 split의 기준으로써 Qini를 직접적으로 이용하는 방법 또한 시도했다. Qini는 분할된 하위그룹들의 Size와 Uplift 변화를 모두 고려한다. 우리는 전체적인 Uplift model의 성능을 평가하는데 유용한 Qini를 찾았지만 이것을 split의 기준으로 사용하는데는 제한적인 성공밖에 얻지 못하였다. Qini가 rank의 순서를 매기는 것만을 측정한다는 사실이 이러한 결과의 원인이 되었을 것이다.</p><p>또한 그룹간의 size의 차이를 일종의 penalty로 간주하여 원래의 uplift 차이를 조정하는 특별한 접근법을 취할 수도 있다. 만약 원래의 uplift 차이가 <span class="math inline">\(\Delta\)</span>이고 두개의 하위그룹의 size가 <span class="math inline">\(N_L\)</span> <span class="math inline">\(N_R\)</span>이라고 한다면, 어떠한 k값에 대하여 penalty를 부여받은 split 조건의 후보는 이하와 같을 수 있다.</p><p><span class="math inline">\(\Delta / (\cfrac{N_L+N_R}{2min(N_L,N_R)})^k\)</span></p><p>이 분모의 penalty는 하위그룹의 size가 서로 같을 때 1을 갖고, 서로 달라질 수 록 큰 값을 갖는다. (결과적으로 penalty를 받은 uplift는 원래보다 작은 값으로 평가된다.)</p><p>어떠한 k에 대한 또다른 penalty의 대안은 이하와 같다.</p><p><span class="math inline">\(\Delta (1- {\large \lvert \frac{N_L-N_R}{N_L+N_R} \rvert}^k)\)</span></p><p>여기서 penalty는 하위그룹의 size가 같을 때 0이 되고 사이즈가 달라지면서 1에 가까워 진다. (두 경우 모두 k는 경험적으로 설정되어야 할 하이퍼파라미터이다.)</p><p>그러나 우리는 실제 세상의 어떠한 문제에 대해서도 잘 작동하는 penalty를 찾지 못했다.</p><hr><p><strong><a href="https://tech.wayfair.com/data-science/2019/10/modeling-uplift-directly-uplift-decision-tree-with-kl-divergence-and-euclidean-distance-as-splitting-criteria/">George Fei's blog (2019)</a></strong></p><h2><span id="modeling-uplift-directly-uplift-decision-tree-with-kl-divergence-and-euclidean-distance-as-splitting-criteria">Modeling Uplift Directly: Uplift Decision Tree with KL Divergence and Euclidean Distance as Splitting Criteria</span></h2><p><br></p><h4><span id="-uplift-decision-tree의-뒤에-있는-이론에-대해">- Uplift Decision Tree의 뒤에 있는 이론에 대해</span></h4><p>각각의 분할기준(split criterion)이 다른 여러 Uplift Decision Tree 알고리즘이 존재한다.</p><p><strong>여기서, 우리는 <a href="https://www.semanticscholar.org/paper/Uplift-Modeling-in-Direct-Marketing-Rzepakowski-Jaroszewicz/e979ba084f34345b2ac8783df2b4a3295ae9273f">Piotr Rzepakowski &amp; Szymon Jaroszewicz (2012)</a>에 등장하는 정보 이론적 분할기준(information theoretical splitting criteria)에 대해 논의할 것이다.</strong></p><p>Single treatment uplift decision tree의 경우에, 각 node는 두개의 분리된 outcome 을 포함한다. 하나는 치료군의 결과이고 다른 하나는 대조군의 결과이다.</p><p>Uplift를 최대화 하기 위해, 우리는 Tree를 타고 내려가면서 분할되는 두가지의 분포를 최대한 다르게 만들고자 한다.</p><p>쿨백-라이블러 발산(<a href="https://en.wikipedia.org/wiki/Relative_entropy">Kullback-Leibler divergence</a>)과 유클리드 제곱거리(squared Euclidean Distance)는 정보이론에서 분포간의 divergence를 측정하는 두가지 방법이다.</p><blockquote><p><strong>Equation 1.</strong><br><span class="math inline">\(KL(P:Q) = \sum_ip_ilog\cfrac{p_i}{q_i}\space\space\space\space\space\space\space\space\space\space\)</span> [Kullback-Leibler Divergence between Two Distributions]<br><span class="math inline">\(E(P:Q) = \sum_i(p_i-q_i)^2\space\space\space\space\space\space\space\space\space\space\)</span>[Squared Euclidean Distance between Two Distributions]</p></blockquote><ul><li>아래첨자 <span class="math inline">\(i\)</span>는 각각의 outcome class</li><li><span class="math inline">\(p_i\)</span>와 <span class="math inline">\(q_i\)</span>는 각각 치료군과 대조군에 있어서 outcome class <span class="math inline">\(i\)</span>가 될 확률</li></ul><p><br></p><p>Tree에서 분할되어야 할 node에서, 위의 두가지 방법 중 하나를 이용해 outcome분포의 divergence를 계산할 수 있다. tree node를 children nodes로 분할시키는 'A' test 이후에 우리는 'A' test의 조건하에서 outcome class distribution의 conditional divergence를 비슷하게 측정할 수 있다.</p><blockquote><p><strong>Equation 2.</strong> [Conditional Divergence for a Given 'A' Test]<br><span class="math inline">\(D{\large(}P^T(Y):P^C(Y)|A{\large)} = \sum_a \cfrac{N(a)}{N}D{\large(}P^T(Y|a):P^C(Y|a)\large)\)</span></p></blockquote><ul><li><span class="math inline">\(a\)</span> : 각 자식 노드</li><li><span class="math inline">\(N\)</span> : 부모노드에 있는 개체(instance)들의 총 수</li><li><span class="math inline">\(N(a)\)</span> : 자식노드 <span class="math inline">\(a\)</span>에 있는 개체들의 수</li><li><span class="math inline">\(D\)</span> : divergence measure</li><li><span class="math inline">\(P^T(Y) , P^C(Y)\)</span> : outcome class distribution</li><li><span class="math inline">\(|a\)</span> : 자식노드 <span class="math inline">\(a\)</span>의 outcome class distribution</li></ul><p><br></p><p>최적의 분할를 위해, 우리는 치료군과 대조군 사이의 outcome class distibution 간의 divergence의 증가분(gain)를 최대화 하려고 한다. 바꿔말하자면, 아래와 같은 식을 최대화 할 것이다.</p><blockquote><p><strong>Equation 3.</strong> [Gain in Class Distribution Divergence for a Given 'A' Test]<br><br> <span class="math inline">\(D_{gain}(A) = D{\large(}P^T(Y):P^C(Y)|A{\large)}-D{\large(}P^T(Y):P^C(Y){\large)}\)</span></p></blockquote><ul><li>우변의 첫번째 항은 위에서 언급된 Conditional Divergence for a Given 'A' Test</li><li>우변의 두번째 항은 부모노드의 outcome class distribution divergence</li></ul><p><br></p><h4><span id="-이-이론을-설명하기-위한-example">- 이 이론을 설명하기 위한 Example</span></h4><p>Uplift decision tree가 치료와 대조 class distribution의 증가분을 최대화하여 node를 어떻게 분할시키는지 더 잘 설명하기 위해 다음의 예를 제시한다.</p><p>주어진 Tree node에 8명의 고객에 해당하는 총 8개의 데이터 포인트가 있으며, 치료군과 대조군에 각각 4명의 고객이 있다고 상상해보자. 치료 그룹의 고객 4명중 3명이 캠페인에 반응(전환; convert)했고, 대조 그룹의 고객 4명 중 2명이 반응을 하였다. 우리는 치료군과 대조군 사이의 outcome class distibution 간의 divergence의 증가분(gain)를 최대화 하도록 이 노드를 분할하는 방법을 찾고 싶다.</p><p><img src="https://i.imgur.com/CUUFwx3.png" width="500px"><br>[자식노드의 결과에 존재하는 분포 차이를 최대화하여 decision tree node가 분할 되는 예]</p><p>이론적으로 Uplift decision tree의 분할기준은 여러가지의 분할(Multiway splits)와 호환된다. 그러나 실제 구현에서는 이 예에서와 같이 분할이 두개의 하위 노드만 생성하는 이진 분할이 더 일반적이다. 우리는 위의 그림에 나타난 분할가 우리가 찾고있는 최적의 분할이라고 주장하고자 한다. 이러한 주장을 증명하기 위해, 먼저 유클리드 제곱거리(squared Euclidean Distance)를 통해 divergence를 측정하보자.</p><p><br><br>1. 먼저 부모노드의 class distribution의 divergence를 구한다.</p><p><span class="math inline">\(D{\large(}P^T(Y):P^C(Y){\large)} = \sum_{\large i \in \{converted, not\space converted \}}(p_i - q_i)^2 = (0.75 - 0.5)^2 + (0.25 - 0.5)^2 = 0.125\)</span></p><p>이것은 단순히 반응률(전환률; conversion rate)의 치료군과 대조군 간 유클리드 제곱거리와 비반응률(비전환률; non-conversion rate)의 치료군과 대조군 간의 유클리드 제곱거리 더한 값이다.</p><p><br><br>2. 부모노드에서와 같이 분할된 두개의 자식노드에서도 class distribution divergence들을 각각 구한다.</p><p><em>In left child node</em> , <span class="math inline">\(\sum_{\large i \in \{converted, not\space converted \}}(p_i - q_i)^2 = (1 - 0)^2 + (0 - 1)^2 = 2\)</span></p><p><em>In right child node</em> , <span class="math inline">\(\sum_{\large i \in \{converted, not\space converted \}}(p_i - q_i)^2 = (0 - 1)^2 + (1 - 0)^2 = 2\)</span></p><p><br><br>3. 분할를 통한 divergence의 개선에 미친 두 자식노드의 상대적인 영향을 정규화하기 위해, 분할의 조건하에서 outcome class distribution의 conditional divergence를 구한다. (Eq.2)</p><p><span class="math inline">\(D{\large(}P^T(Y):P^C(Y)|A{\large)} = \sum_{\large a \in \{left\space child,\space right\space child \} }\cfrac{N(a)}{N} D{\large (} P^T(Y|a) : P^C(Y|a){\large)} = \cfrac{5}{8}\cdot2 + \cfrac{3}{8}\cdot2 = 2\)</span></p><p><br><br>4. 분할가 이루어졌을 때, 치료군과 대조군 사이의 outcome class distibution 간의 divergence의 증가분(gain)을 구한다. (Eq.3)</p><p><span class="math inline">\(D_{gain}(A) = D{\large(}P^T(Y):P^C(Y)|A{\large)}-D{\large(}P^T(Y):P^C(Y){\large)} = 2-0.125 = 1.875\)</span></p><p>두 개의 자손의 class distribution이 가장 다를 때 (즉 divergence가 가장 클 때) 두 자손의 유클리드 제곱거리가 가장 최대화 되므로, 위의 계산 결과는 최대값이라고 할 수있다.</p><p><br></p><p>다시 말해, <strong>왼쪽 자식노드의 클래스 분포는 치료군과 통제군을 비교했을 때 가장 <code>Persuadables</code>에 가까운 분포가 되게끔 하고, 오른쪽 자식노드의 클래스 분포는 가장 <code>Sleeping Dogs</code>에 가까운 분포가 되게끔 하는 split을 선택하는 것이다.</strong></p><p>모델이 훈련될 때, 이용가능한 특징량의 여러가지 다양한 값에 대해 여러 split을 반복하면서 이러한 최적화 split이 찾아질 것이다.</p><p><br></p><h4><span id="-잠재적인-준準최적-분할-potential-suboptimal-splits">- 잠재적인 준(準)최적 분할 (Potential Suboptimal Splits)</span></h4><p>위에서 제시한 분할 전략에 존재할 수 있는 이하의 <em>두가지 잠재적인 문제</em> 에 대처해야할 필요가 있다.</p><p><br> 1. 고르지 못한 치료/통제군의 분할</p><p>먼저, 고르지 못한 치료/통제군의 분할는 알고리즘이 대부분의 치료개체들을 하나의 하위나무에 집어넣고 그 나무에 거의 통제클래스의 개체들이 존재하지 않을때 일어난다. 이것은 분할에 사용된 특징량이 치료할당 라벨과 높은 상관관계를 가진다는 것을 의미한다. 즉 Uplift modeling의 필수적인 가정인 <strong>Unconfounded assumption</strong> 이 위반된다는 것을 의미한다. 더욱이 모든 leaf node는 충분한 치료와 통제 개체들을 포함해야 하므로 이러한 분할는 앞으로의 분할를 더욱 어렵게 만들 것이다.</p><p><br> 2. 여러개의 자손노드로 나누는 분할를 선택하는 알고리즘의 경향성</p><p>여러개의 자손노드로 나누는 분할는, 훈련데이터에 적용되었을 때 더 높은 증가분(gain)을 갖는 경향성이 있기 때문에 발생한다. 그러나 테스트데이터에는 제대로 추론해내지못하며 결과적으로 overfitting을 발생시킨다.</p><p>아래에 제시된 정규화인수(Normalization factor)들은 앞에 언급한 바이어스를 시정하기 위해 고안되었다. 쿨백-라이블러 발산과 유클리드 제곱거리를 통한 두가지 분할기준과 마찬가지로 이 또한 두가지 다른 유형의 정규화값을 가진다.</p><blockquote><p><strong>Equation 4</strong> [Normalization Value for Splitting Based on KL Divergence]<br><span class="math inline">\(I(A)=H(\cfrac{N^T}{N},\cfrac{N^C}{N})KL(P^T(A):P^C(A))+\cfrac{N^T}{N}H(P^T(A))+\cfrac{N^C}{N}H(P^C(A))+\cfrac{1}{2}\)</span></p></blockquote><blockquote><p><strong>Equation 5</strong> [Normalization Value for Splitting Based on Euclidean Distance]<br><span class="math inline">\(J(A) = Gini(\cfrac{N^T}{N},\cfrac{N^C}{N})E(P^T(A):P^C(A))+\cfrac{N^T}{N}Gini(P^T(A))+\cfrac{N^C}{N}Gini(P^C(A))+\cfrac{1}{2}\)</span></p></blockquote><p>두 penalty항이 상당히 비슷하기 때문에, 여기서는 유클리드 제곱거리에 대해서만 논할 것이다. (Eq.5)</p><p><span class="math inline">\(J(A)=\)</span></p><p>ⅰ. <span class="math inline">\(Gini(\cfrac{N^T}{N},\cfrac{N^C}{N})\cdot E(P^T(A):P^C(A))\)</span></p><ul><li><p>첫번째 항은 고르지 못한 치료/통제군의 분할을 예방한다.</p></li><li><p>이 항의 앞부분은 부모노드의 지니 불순도(Gini impurity)<span class="math inline">\(^{[*1]}\)</span>이고, 부모노드의 치료/통제의 불균형이 클 수록 0에 가까워지는 값이다. 이렇게 설정된 이유는 부모노드에 이미 큰 치료/통제 불균형이 존재하는 경우, 결과적으로 따라오는 자식노드의 불균형에 대해 계속적으로 처벌하는 것은 공정하지 않기 때문이다.</p></li><li><p>이 항의 뒷부분은 모든 자식노드에서의 치료비율과 통제비율간의 유클리드 제곱거리이다. 이 값은 모든 자식노드에서 두 비율이 동일한 경우에만 최소화된다.</p></li></ul><p><br></p><p>ⅱ. <span class="math inline">\(+\cfrac{N^T}{N}Gini(P^T(A))+\cfrac{N^C}{N}Gini(P^C(A))\)</span></p><ul><li><p>이어지는 두 항은 여러개의 자손노드로 분할되는 것에 대해 penalty를 부여한다.</p></li><li><p>이는 같은 문제를 전통적인 decision tree algorithm이 처리하는 방식과 비슷하다.</p></li><li><p>지니 불순도는 분할에 의해 자손노드의 개수가 증가할 때 증가한다. 예를 들어 두개의 동등한 자손노드로 분할가 이루어 질 때 <span class="math inline">\(1 - 0.5^2 -0.5^2 = 0.5\)</span> 가 되고, 4개의 동등한 자손노드로 분할될 때 <span class="math inline">\(1-4\cdot 0.25^4 = 0.75\)</span>가 된다.</p></li></ul><p><br></p><p>ⅲ. <span class="math inline">\(+\cfrac{1}{2}\)</span></p><ul><li>마지막 <span class="math inline">\(\cfrac{1}{2}\)</span> 항은. 작은 증가분(gain)을 갖지만 작은 정규화요인으로 나눔으로써 과대평과되는 분할를 선호하지 않기 위해 존재한다.</li></ul><p><br></p><p><span style="font-size: 85%"> <span class="math inline">\(^{[*1]}:\)</span> 지니 불순도는 부분 집합에서 무작위로 선택한 원소가 부분 집합의 라벨 분포에 따라 무작위로 라벨을 붙인 경우 얼마나 자주 잘못 라벨을 붙이는지를 측정한 것이다. 라벨 <span class="math inline">\(i\)</span>가 선택되는 확률 <span class="math inline">\(p_i\)</span>과 실수할 확률<span class="math inline">\(1-p_i\)</span>을 곱해서 모든 개체에 대해 합산해서 계산한다. <span class="math inline">\(\sum^J_{i=1}p_i(1-p_i)=\sum^J_{i=1}(p_i-p_i^2)=\sum^J_{i=1}p_i-\sum^J_{i=1}p_i^2=1-\sum^J_{i=1}p_i^2\)</span> </span></p><hr><p><strong><a href="https://www.diva-portal.org/smash/get/diva2:1328437/FULLTEXT01.pdf">Henrik Karlsson (2019)</a></strong></p><h2><span id="uplift-modeling-identifying-optimal-treatment-group-allocation-and-whom-to-contact-to-maximize-return-on-investment">Uplift Modeling: Identifying Optimal Treatment Group Allocation and Whom to Contact to Maximize Return on Investment</span></h2><p><br></p><h3><span id="413-model-uplift-directly">4.1.3 Model Uplift Directly</span></h3><p>tree기반의 알고리즘은 데이터를 하위그룹으로 나누고 평가하기 위해 설계되었다. 이것은 차이를 치료군과 대조군간의 차이와 같이 차이(differences)를 모델링하는 데에 유용하다. tree기반의 방법은 uplift 분야에서 일반적으로 여러 연구자들에게 활용되어왔다.</p><p><br></p><h4><span id="-general-tree-based-methods">- General Tree-based Methods</span></h4><p>Tree기반 방법은 크게 나눠서 분할(splitting)와 가지치기(pruning)라는 두가지 스텝을 가지고 있다.</p><p>분할 스텝은 데이터를 분리해서 <em>pure</em> 한 노드를 가능한 한 생성하는 최적의 분할를 찾기 위해 노력한다. 가지치기 스텝은 나무의 일반화를 개선하지 못하는 노드나 가지들을 제거한다.</p><p>노드가 <em>pure</em> 하다는 것은 노드에 속한 모든 데이터 포인트가 가능한 한 가장 비슷하다는 것을 의미한다. tree알고리즘의 타입에 따라, 각 노드는 (CART tree와 같이) 두개의 노드로 나누어질 수 도있고, (CHAID tree와 같이) 여러개의 노드로 나누어질 수도 있다.</p><p>알고리즘은 모든 노드들이 완전히 <em>pure</em> 해지거나, 혹은 멈추는 기준을 만족할 때까지 노드를 계속해서 분할시키며 tree를 자라게한다. 만약 tree가 모든 노드가 <em>pure</em> 해질 때까지 자란다면, 모델은 훈련데이터를 완벽히 정확하게 분류할 것이다. 그러나 그 결과는 overfitting되어 새로운 데이터에 잘 일반화되지 않을 것이다. tree의 분할지점을 정하기 위해 정보 이득(information gain)을 계산하고, 정보 이득이 가장 높은 잠재적 분할가 수행될 것이다.</p><p>정보이득은 자식노드에 할당된 데이터의 비율에 노드의 순도(purity)를 곱하여 추정한다.</p><p>CART나 Quinlan's C4.5 tree와 같은 많은 tree기반의 방법들이 이러한 하향식으로 노드를 분할한 뒤 도움이 되지 않는 분할을 가지치기하는 2step 접근방법을 사용한다. 이러한 접근방법을 활용하는 이유는 tree method가 매우 선형적이지 않고 그에 따라 선택된 특징량들의 상호작용에 강하게 의존하기 때문이다.</p><p>예를 들어, 주어진 분할가 현재 노드에서만 평가될 때 의미가 없어 보일 수 있지만, 그보다 더 아래로 분할될 때 현재 분할와 관련지어져 매우 중요해질 수 있다.<br>즉 각 분할은 미래의 분할 가능성을 무시한 현재 노드에서 평가되므로, 분할가 많은 깊은 tree를 만들고 그 후에 충분히 기여하지 못한 분할를 가지치기하는 것이다.</p><p>tree의 깊이를 제한하는 정지 기준을 삽입하여 가지치기 작업을 tree에 적용하거나 두 가지를 함께 적용함으로써 오버피팅을 피할 수 있다. 가지치기 작업은 사용 중인 tree의 종류에 따라 유의성 시험에 근거하여 분할 전 또는 tree의 성장이 끝난 후에 수행할 수 있다. 후자의 방법이 더 일반적이다.</p><p>일반적으로 깊게 자라는 것이 허용된 decision tree는 동일한 데이터셋으로 학습을 했음에도 불구하고 서로 다른 tree들 간의 바이어스가 낮고 분산이 높다. (low bias and high variance <span class="math inline">\(\rightarrow\)</span> <strong>Overfitting</strong> )</p><p>깊은 tree 모델은 데이터를 잘 분류할 수 있기 때문에 바람직하다고 할 수있지만, 서로 다른 decision tree 간의 높은 분산이 robust<span class="math inline">\(^{[*2]}\)</span>하지 못한 결과를 낳는다. 이러한 decision tree간의 분산을 줄이기 위해 Random forest algorithm이 개발되었다. 이것은 많은 decision tree를 만들고 각 tree의 결과를 평균하여 더 robust한 결과를 얻는다. 이것은 모델에서 약간 더 많은 바이어스라는 cost를 수반하지만, 그 결과로 분산이 감소한다. Random forest는 Bagging을 사용하고 각각의 tree들을 다른 특징의 부분집합으로 훈련시켜 deep tree의 효과를 훨씬 더 평균화하는 데 도움을 준다. 이 보고서에서는 uplift random forest는 특징량갯수의 제곱근을 사용하여 각 tree를 훈련시킨다.</p><p><br><br><span style="font-size: 85%"> <span class="math inline">\(^{[*2]}:\)</span> 머신러닝 알고리즘에서 robust는 일반적으로 알고리즘의 강건성을 가리킨다. 머신러닝 알고리즘이 robust하다고 간주되려면 testing error가 training error와 일치해야 하거나 데이터 집합에 노이즈를 추가한 후에도 성능이 안정적이어야 한다. </span></p><h4><span id="-tree-based-methods-for-estimating-uplift">- Tree-based Methods for Estimating Uplift</span></h4><p>Tree기반 알고리즘을 사용하여 Uplift Modeling을 할 때는 Uplift가 포착될 수 있도록 분할기준을 조정한다. 문헌에 따르면 Uplift를 가장 잘 추정하기 위해 분할기준을 조정하는 몇 가지 방법이 제시되어 있으며, 어떤 방법이 가장 좋은지에 대한 합의는 아직 이루어지지 않은 것으로 보인다. Hansotia and Rukstales (2002)는 '각 자식노드(binary)에서의 치료군과 대조군의 확률 차이' 사이의 차이를 최대화 하기 위한 분할기준을 제시했다.<br>Rzepakowski &amp; Jaroszewicz (2012)는 정보이론으로 부터 '차이'의 개념을 분할 기준으로 도입했는데, Tree기반의 알고리즘이 치료군과 대조군 사이의 분포적 차이를 최대화하려고 노력함으로써 상승을 포착한다. 이 보고서는 Rzepakowski &amp; Jaroszewicz (2012)의 분할 기준을 사용할 것이다.</p><p>Distributional divergence(분포의 차이)란 q(x)를 p(x)의 근사치로 사용할 때 손실되는 정보의 양을 나타내는 척도로, 여기서 q(x)는 일반적으로 표본데이터를 나타내고 p(x)는 이론적인 분포로부터 도출된 데이터로 나타내어진다. 이 divergence는 두 확률분포 사이의 "거리"이지만, 대칭적이거나 삼각부등식을 만족할 필요가 없으므로 미터법 거리보다 약한 척도이다. divergence 척도를 분할기준으로 사용할 경우 모든 노드에서 치료군과 대조군 사이의 차이를 최대화하려고 한다. tree들의 앙상블을 사용하려고 할 때, 예측되는 Uplift값은 개별 tree에서의 예측 Uplift값을 평균하여 얻는다. 분할기준으로 사용되는 네 가지 다른 divergence 척도는 아래에서 확인할 수 있다.</p><p><br></p><p>Rzepakowski &amp; Jaroszewicz(2012)는 Uplift을 포착하기 위해 분할 기준이 충족해야 하는 세 가지 항목을 제시한다.</p><ol type="1"><li><p>치료군과 대조군의 class 분포가 모든 분할에서 동일할 경우 분할기준치를 최소값으로 평가해야 한다.</p><ul><li>Uplift는 치료군과 대조군 사이의 가능한 가장 큰 분포차이를 만들어냄으로써 포착되기 때문에, 두 집단이 동일할 때는 분할기준치가 최소값으로 평가되는 것이 타당하다.</li></ul></li><li><p>분할기준치는 test가 치료군과 대조군에서의 각 outcome과 통계적으로 독립되어 있는 경우 0으로 평가해야 한다.</p><ul><li><p>일반적인 decision tree에서는 outcome과 통계적으로 독립된 분할가 tree를 개선시키지 못하므로 분할의 기준으로 사용해서는 안된다고 명시하고 있다.</p></li><li><p>그러나 uplift modeling에서는 분포를 이전보다 더 유사하게 만들 수 있으며, 이는 음의 분할기준치를 갖는 것을 의미한다. 즉 독립적인 분할가 발생할 수 있는 최악의 분할가 아닐 수 있음을 의미한다.</p></li></ul></li><li><p>대조군의 크기가 0일 경우의 분할기준치는 decision tree가 사용하는 표준 분할기준치까지 감소시켜야한다.</p></li></ol><p><br></p><p>이 보고서는 Uplift random forest와 함께 네 가지 서로 다른 분할기준을 다룬다. 각각은 <span class="math inline">\(P=(p_1,\cdots,p_n)\)</span>과 <span class="math inline">\(Q=(q_1,\cdots,q_n)\)</span>의 분포 사이의 divergece 값을 계산한다.</p><ul><li>Kullback-Leibler divergence :<br><span class="math inline">\(KL(P:Q)=\sum_ip_ilog\cfrac{p_i}{q_i}\)</span></li></ul><p><br></p><ul><li><p>squared Euclidean distance :</p><p><span class="math inline">\(ED(P:Q)=\sum_i(p_i-q_i)^2\)</span></p></li></ul><p><br></p><ul><li><span class="math inline">\(\chi^2\)</span>-divergence :<br><span class="math inline">\(\chi^2(P:Q)=\sum_i\cfrac{(p_i-q_i)^2}{q_i}\)</span></li></ul><p><br></p><ul><li><p>L1-norm divergence :</p><p><span class="math inline">\(L1(P:Q)=\sum_i|p_i-q_i|\)</span></p></li></ul><p>(Kullback-Leibler divergence, squared Euclidean distance, <span class="math inline">\(\chi^2\)</span>-divergence는 Rzepakowski and Jaroszewicz (2012b)에 소개되었고, L1-norm divergence는 Guelman, Guill´en, and P´erez-Mar´ın (2015)에서 소개되었다.)</p><p>Random forest 모델은 주어진 군에 속하는 구매의 조건부 확률을 반환한다. Uplift score은 이하와 같은 식으로 계산된다.</p><p><span class="math inline">\(Uplift\space score = P(purchase|treatment\space group) - P(purchase|control\space group)\)</span></p><p>Score가 높다는 것은 치료로 인한 구매가능성이 높다는 것을 가정하고 있으므로 score를 내림차순으로 분류해야 한다. score가 음수인것은 치료를 하지 않는 것이 그개인의 구매확률이 더 높다는 의미이다. uplift를 직접적으로 모델링 하는 것의 장점은 이진적인(binary) 목적변수와 연속적인(continuous) 목적변수 모두에 적용할 수 있다는 점이다.</p>]]></content:encoded>
      
      
      <category domain="https://jaysung00.github.io/categories/UPLIFT-MODELING/">UPLIFT MODELING</category>
      
      <category domain="https://jaysung00.github.io/categories/UPLIFT-MODELING/c-Methods/">c.Methods</category>
      
      <category domain="https://jaysung00.github.io/categories/UPLIFT-MODELING/c-Methods/2-Tree-based-Algorithm/">2.Tree-based Algorithm</category>
      
      
      <category domain="https://jaysung00.github.io/tags/Uplift-modeling/">Uplift modeling</category>
      
      <category domain="https://jaysung00.github.io/tags/Uplift-Tree/">Uplift Tree</category>
      
      
      <comments>https://jaysung00.github.io/2020/12/17/Uplift-tree/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>【Uplift Modeling】변수의 선택방법에 대하여</title>
      <link>https://jaysung00.github.io/2020/12/17/Selection/</link>
      <guid>https://jaysung00.github.io/2020/12/17/Selection/</guid>
      <pubDate>Thu, 17 Dec 2020 01:46:51 GMT</pubDate>
      
      <description>&lt;p&gt;해당 포스트는 &lt;a href=&quot;https://arxiv.org/pdf/2005.03447.pdf&quot;&gt;Zhenyu Zhao at el. &quot;Feature Selection Methods for Uplift Modeling&quot; (2020)&lt;/a&gt;의 내용을 기반으로, Uber사에서 개발한 파이썬 오픈소스 패키지 &lt;a href=&quot;https://github.com/uber/causalml&quot;&gt;CausalML&lt;/a&gt;에 구현된 소스코드들을 다루고 있습다.&lt;/p&gt;
&lt;hr /&gt;</description>
      
      
      
      <content:encoded><![CDATA[<p>해당 포스트는 <a href="https://arxiv.org/pdf/2005.03447.pdf">Zhenyu Zhao at el. "Feature Selection Methods for Uplift Modeling" (2020)</a>의 내용을 기반으로, Uber사에서 개발한 파이썬 오픈소스 패키지 <a href="https://github.com/uber/causalml">CausalML</a>에 구현된 소스코드들을 다루고 있습다.</p><hr><a id="more"></a><h1><span id="introduction">* Introduction</span></h1><hr><p>Feature Selection 방법은 각 feature에 대해 중요도 점수(importance score)를 계산한 뒤 점수를 바탕으로 랭크를 매긴다. Uplift model은 이렇듯 가장 중요하다고 판단된 변수들만을 가지고 만들어 질 수 있다. Uplift modeling에서 중요한 변수들에게만 집중하는 것은 몇가지의 이득을 가져다 준다.</p><ol type="1"><li>훈련을 위한 빠른 계산처리<br></li><li>overfitting 문제를 피함으로써 더욱 정확한 예측이 가능<br></li><li>데이터 파이프라인의 낮은 유지비용<br></li><li>더욱 쉬운 모델 해석과 진단</li></ol><p>이렇듯 feature selection은 Uplift modeling에 있어서 중요한 문제임에도 불구하고 지금까지 관련 문헌에서 거의 논의되어오지 못했다. 전통적인 머신러닝에 있어서의 변수선택방법의 연구는 V. <a href="https://www.researchgate.net/profile/Veronica_Bolon-Canedo/publication/257482053_A_review_of_feature_selection_methods_on_synthetic_data/links/549d23980cf2d6581ab4acc7.pdf">Bolon-Canedo et al.(2013)</a>, <a href="https://www.sciencedirect.com/science/article/abs/pii/S0045790613003066?via%3Dihub">G. Chandrashekar &amp; F. Sahin(2014)</a>, J. <a href="http://www.math.chalmers.se/Stat/Grundutb/GU/MSA220/S18/featselect.pdf">Tang(2014)</a>과 같은 논문들에서 잘 논의되어있지만, 이것들은 Uplift modeling에서 최적의 변수선택 방법은 아니다.</p><p>이 논문에서는 방법론적이고 경험적인 평가 관점에서 변수선택을 다룬다.</p><hr><h1><span id="일반적인-변수선택-방법과의-관계">* 일반적인 변수선택 방법과의 관계</span></h1><hr><h5><span id="일반적인-변수선택법의-종류">일반적인 변수선택법의 종류</span></h5><ol type="1"><li>filter methods<br></li><li>wrapped methods<br></li><li>embedded methods</li></ol><h5><span id="일반적인-변수선택법이-uplift-modeling에서-최선이-아닌-이유">일반적인 변수선택법이 Uplift modeling에서 최선이 아닌 이유</span></h5><ul><li><p>분류문제를 생각했을때 일반적 변수선택법의 목적은 feature에 기반하여 outcome이 각 클래스에 해당될 확률의 예측하는 것이다. 그러므로 feature의 중요도는 클래스 확률과 관계가 깊다.</p></li><li><p>반면에 Uplift model의 목적은 CATE를 예측하는 것이다. 그러므로 여기서 좋은 feature는 클래스 확률이 아니라 치료효과를 예측할 수 있게 해주는 것이어야 한다. 이 두가지 예측대상이 항상 일치할 필요는 없으므로 Uplift modeling에서 일반적 변수선택법은 최선이 아닐 수 있다.</p></li></ul><p><br></p><hr><h1><span id="uplift-modeling을-위한-변수선택-방법">* uplift modeling을 위한 변수선택 방법</span></h1><hr><h4><span id="예시로써-x1-x63-의-총-63개-feature-가-존재하는-가상의-data를-생각하자">예시로써 x1 , ... , x63 의 총 63개 feature 가 존재하는 가상의 data를 생각하자.</span></h4><p><img src="https://i.imgur.com/kNDqVcM.png" width="600px"></p><p><br></p><h4><span id="a-filter-methods">A. <em>Filter Methods</em></span></h4><p>이 방법은 각 feature에 대하여 치료효과와 feature간의 한계관계(marginal relationship)를 기반으로 중요도 점수(Importance score)를 계산한다. 이것은 한번에 하나의 feature에 대한 간단한 계산만 이루어지므로 빠른 전처리 단계이다.</p><h5><span id="1-f-filter">1. F filter</span></h5><h5><span id="-causalml-package에서-implementation">- <code>Causalml</code> package에서 implementation</span></h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> causalml.feature_selection.filters <span class="keyword">import</span> FilterSelect</span><br><span class="line">filter_f = FilterSelect() </span><br><span class="line">method = <span class="string">&#x27;F&#x27;</span></span><br><span class="line">f_imp = filter_f.get_importance(df, X_names, y_name, method, </span><br><span class="line">                      treatment_group = <span class="string">&#x27;treatment1&#x27;</span>)</span><br><span class="line"><span class="comment"># X_names는 features의 컬럼리스트</span></span><br><span class="line">f_imp</span><br></pre></td></tr></table></figure><p>[output]<br><img src="https://i.imgur.com/rZ69DlY.png" width="600px"></p><p><br></p><h5><span id="-코드의-동작-원리를-자세하게-살펴보자">- 코드의 동작 원리를 자세하게 살펴보자.</span></h5><p>치료여부변수(<span class="math inline">\(Z\)</span>)와 확인하고자하는 feature(<span class="math inline">\(x_i\)</span>) 그리고 그들의 교호작용항(interaction term)을 사용하여 outcome변수를 예측하는 선형회귀모델이다.</p><p><span class="math inline">\(y_{outcome} = \beta_0 + \beta_1Z + \beta_2x_i + \beta_3(Z\cdot x_i)\)</span></p><p>중요도 점수(importance score)는 교호작용항 <span class="math inline">\(\beta_3(Z\cdot x_i)\)</span>의 계수<span class="math inline">\(\beta_3\)</span>에 대한 F-통계값 으로 정의된다. 이 통계값이 크면 해당 feature는 강한 heterogeneous treatment effect와 상관이 있다는 것을 의미한다. <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line">method = <span class="string">&#x27;F&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># treatment_indicator column 생성 (treatment : 1 , control : 0)</span></span><br><span class="line">df = df[df[<span class="string">&#x27;treatment_group_key&#x27;</span>].isin([<span class="string">&#x27;control&#x27;</span>, <span class="string">&#x27;treatment1&#x27;</span>])]</span><br><span class="line">df[<span class="string">&#x27;treatment_indicator&#x27;</span>] = <span class="number">0</span></span><br><span class="line">df.loc[df[<span class="string">&#x27;treatment_group_key&#x27;</span>]==<span class="string">&#x27;treatment1&#x27;</span>,<span class="string">&#x27;treatment_indicator&#x27;</span>] = <span class="number">1</span></span><br><span class="line"></span><br><span class="line">all_result = pd.DataFrame()</span><br><span class="line"><span class="keyword">for</span> x_name_i <span class="keyword">in</span> X_names: </span><br><span class="line">    Y = df[<span class="string">&#x27;conversion&#x27;</span>]</span><br><span class="line">    X = df[[<span class="string">&#x27;treatment_indicator&#x27;</span>, x_name_i]]</span><br><span class="line">    X = sm.add_constant(X)</span><br><span class="line">    X[<span class="string">&#x27;&#123;&#125;-&#123;&#125;&#x27;</span>.<span class="built_in">format</span>(<span class="string">&#x27;treatment_indicator&#x27;</span>, x_name_i)] = X[[<span class="string">&#x27;treatment_indicator&#x27;</span>, x_name_i]].product(axis=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    model = sm.OLS(Y, X)</span><br><span class="line">    result = model.fit()</span><br><span class="line">    <span class="comment"># 교호작용의 중요도를 알고싶다</span></span><br><span class="line">    <span class="comment"># 교호작용항의 계수 β_3에 대해서만 f검정 </span></span><br><span class="line">    F_test = result.f_test(np.array([<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>]))</span><br><span class="line">    F_test_result = pd.DataFrame(&#123;</span><br><span class="line">        <span class="string">&#x27;feature&#x27;</span>: x_name_i, </span><br><span class="line">        <span class="string">&#x27;method&#x27;</span>: <span class="string">&#x27;F-statistic&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;score&#x27;</span>: F_test.fvalue[<span class="number">0</span>][<span class="number">0</span>], </span><br><span class="line">        <span class="string">&#x27;p_value&#x27;</span>: F_test.pvalue, </span><br><span class="line">        <span class="string">&#x27;misc&#x27;</span>: <span class="string">&#x27;df_num: &#123;&#125;, df_denom: &#123;&#125;&#x27;</span>.<span class="built_in">format</span>(F_test.df_num, F_test.df_denom), </span><br><span class="line">    &#125;, index=[<span class="number">0</span>]).reset_index(drop=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    one_result = F_test_result</span><br><span class="line">    </span><br><span class="line">    all_result = pd.concat([all_result, one_result])</span><br><span class="line"></span><br><span class="line">all_result = all_result.sort_values(by=<span class="string">&#x27;score&#x27;</span>, ascending=<span class="literal">False</span>)</span><br><span class="line">all_result[<span class="string">&#x27;rank&#x27;</span>] = all_result[<span class="string">&#x27;score&#x27;</span>].rank(ascending=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">all_result[<span class="string">&#x27;method&#x27;</span>] = method + <span class="string">&#x27; filter&#x27;</span></span><br><span class="line"></span><br><span class="line">all_result[[<span class="string">&#x27;method&#x27;</span>, <span class="string">&#x27;feature&#x27;</span>, <span class="string">&#x27;rank&#x27;</span>, <span class="string">&#x27;score&#x27;</span>, <span class="string">&#x27;p_value&#x27;</span>, <span class="string">&#x27;misc&#x27;</span>]]</span><br><span class="line">```  </span><br><span class="line"></span><br><span class="line">[output]  </span><br><span class="line">&lt;img src=&quot;https://i.imgur.com/rZ69DlY.png&quot; width=&quot;600px&quot;&gt;&lt;/img&gt;  </span><br><span class="line"></span><br><span class="line">&lt;br&gt;  </span><br><span class="line"></span><br><span class="line">각 feature 별로 F 통계량을 기준으로 scoring해서 점수가 높은 순으로 내림차순으로 반환한다. </span><br><span class="line"></span><br><span class="line">&lt;br&gt;  </span><br><span class="line"></span><br><span class="line"><span class="comment">##### 2. LR filter (Likelihood ratio)</span></span><br><span class="line"><span class="comment">##### - `Causalml` package에서 implementation</span></span><br><span class="line">```python</span><br><span class="line">method = <span class="string">&#x27;LR&#x27;</span></span><br><span class="line">lr_imp = filter_f.get_importance(df, X_names, y_name, method, </span><br><span class="line">                      treatment_group = <span class="string">&#x27;treatment1&#x27;</span>)</span><br><span class="line">lr_imp</span><br></pre></td></tr></table></figure></p><p>[output]<br><img src="https://i.imgur.com/1Rar2L8.png" width="450px"></p><p><br></p><p>여기서는 score를 로지스틱 회귀모형의 교호작용항 계수에 대한 likelihood ratio 검정 통계량으로 정의한다. 각 feature 별 LR 통계량을 기준으로 scoring해서 점수가 높은 순으로 내림차순으로 반환한다.</p><p><br></p><h5><span id="3-filter-method-with-k-bins">3. Filter method with K bins</span></h5><p>여기에는 <a href="https://www.semanticscholar.org/paper/Uplift-Modeling-in-Direct-Marketing-Rzepakowski-Jaroszewicz/e979ba084f34345b2ac8783df2b4a3295ae9273f">Piotr Rzepakowski &amp; Szymon Jaroszewicz (2012)</a>에서 제안된 uplift tree의 분할기준으로 부터 세가지 방법이 존재한다.</p><p><br></p><h5><span id="3-1-kullback-leibler-divergence">3-1. Kullback-Leibler divergence</span></h5><h5><span id="-causalml-package에서-implementation">- <code>Causalml</code> package에서 implementation</span></h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">method = <span class="string">&#x27;KL&#x27;</span></span><br><span class="line">kl_imp = filter_f.get_importance(df, X_names, y_name, method, </span><br><span class="line">                      treatment_group = <span class="string">&#x27;treatment1&#x27;</span>,</span><br><span class="line">                      n_bins=<span class="number">10</span>)</span><br></pre></td></tr></table></figure><p>[output]<br><img src="https://i.imgur.com/fgdy1vw.png" width="500px"></p><p><br></p><h5><span id="3-2-the-squared-euclidean-distance">3-2. the squared Euclidean distance</span></h5><h5><span id="-causalml-package에서-implementation">- <code>Causalml</code> package에서 implementation</span></h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">method = <span class="string">&#x27;ED&#x27;</span></span><br><span class="line">kl_imp = filter_f.get_importance(df, X_names, y_name, method, </span><br><span class="line">                      treatment_group = <span class="string">&#x27;treatment1&#x27;</span>,</span><br><span class="line">                      n_bins=<span class="number">10</span>)</span><br></pre></td></tr></table></figure><p>[output]<br><img src="https://i.imgur.com/AFzR2iL.png" width="500px"></p><p><br></p><h5><span id="3-3-the-chi-squared-divergence">3-3. the Chi-squared divergence</span></h5><h5><span id="-causalml-package에서-implementation">- <code>Causalml</code> package에서 implementation</span></h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">method = <span class="string">&#x27;Chi&#x27;</span></span><br><span class="line">kl_imp = filter_f.get_importance(df, X_names, y_name, method, </span><br><span class="line">                      treatment_group = <span class="string">&#x27;treatment1&#x27;</span>,</span><br><span class="line">                      n_bins=<span class="number">10</span>)</span><br></pre></td></tr></table></figure><p>[output]<br><img src="https://i.imgur.com/YTOLqlc.png" width="500px"></p><p><br></p><h5><span id="-코드의-동작-원리를-자세하게-살펴보자">- 코드의 동작 원리를 자세하게 살펴보자.</span></h5><p>주어진 feature에 대해 이 방법은 먼저 샘플을 feature의 백분위를 기준으로 K개의 bin으로 나눈다. (여기서 K는 하이퍼파라미터) 중요도 점수는 이러한 K개의 bins에 대한 처리효과의 divergence measure로 정의된다.</p><p>구체적으로, outcome 변수에 C개의 클래스가 있다고 가정해보자.</p><p><span class="math inline">\(P_k = (p_{k1},...,p_{kC})\)</span> 와 <span class="math inline">\(Q_k = (q_{k1},...,q_{kC})\)</span>가 각각 치료군과 대조군의 <span class="math inline">\(k\)</span>번째(<span class="math inline">\(k=1,...,K\)</span>) bin에서의 클래스별 sample의 비율이라고 했을 때, 중요도 점수는 이하와 같이 정의된다.</p><p><span class="math inline">\(\Delta = \sum^K_{k=1}\cfrac{N_k}{N}D(P_k:Q_k)\)</span></p><p><span class="math inline">\(N_k\)</span> : <span class="math inline">\(k\)</span>번째 bin의 샘플사이즈<br><span class="math inline">\(N\)</span> : 전체 샘플 사이즈<br><span class="math inline">\(D\)</span> : distribution divergence<br>- Kullback-Leibler divergence (denoted as <strong>KL</strong> )<br>- the squared Euclidean distance(denoted as <strong>ED</strong> )<br>- the chi-squared divergence (denoted as <strong>Chi</strong> )</p><ul><li><span class="math inline">\(KL(P_k:Q_k)=\sum^n_{i=1}p_{ki}log\cfrac{p_{ki}}{q_{ki}}\)</span></li></ul><p><br></p><ul><li><span class="math inline">\(ED(P_k:Q_k)=\sum^n_{i=1}(p_{ki}-q_{ki})^2\)</span></li></ul><p><br></p><ul><li><span class="math inline">\(\chi^2(P_k:Q_k)=\sum^n_{i=1}\cfrac{(p_{ki}-q_{ki})^2}{q_{ki}}\)</span></li></ul><p><br><br>[먼저 세개의 함수를 정의] <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_GetNodeSummary</span>(<span class="params">data,</span></span></span><br><span class="line"><span class="function"><span class="params">                        experiment_group_column=<span class="string">&#x27;treatment_group_key&#x27;</span>, </span></span></span><br><span class="line"><span class="function"><span class="params">                        y_name=<span class="string">&#x27;conversion&#x27;</span></span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        To count the conversions and get the probabilities by treatment groups. This function comes from the uplift tree algorithm, that is used for tree node split evaluation.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Parameters</span></span><br><span class="line"><span class="string">        ----------</span></span><br><span class="line"><span class="string">        data : DataFrame</span></span><br><span class="line"><span class="string">            The DataFrame that contains all the data (in the current &quot;node&quot;).  </span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Returns</span></span><br><span class="line"><span class="string">        -------</span></span><br><span class="line"><span class="string">        results : dict</span></span><br><span class="line"><span class="string">            Counts of conversions by treatment groups, of the form: </span></span><br><span class="line"><span class="string">            &#123;&#x27;control&#x27;: &#123;0: 10, 1: 8&#125;, &#x27;treatment1&#x27;: &#123;0: 5, 1: 15&#125;&#125;</span></span><br><span class="line"><span class="string">        nodeSummary: dict</span></span><br><span class="line"><span class="string">            Probability of conversion and group size by treatment groups, of </span></span><br><span class="line"><span class="string">            the form:</span></span><br><span class="line"><span class="string">            &#123;&#x27;control&#x27;: [0.490, 500], &#x27;treatment1&#x27;: [0.584, 500]&#125;</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># Note: results and nodeSummary are both dict with treatment_group_key</span></span><br><span class="line">        <span class="comment"># as the key.  So we can compute the treatment effect and/or </span></span><br><span class="line">        <span class="comment"># divergence easily.</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># Counts of conversions by treatment group</span></span><br><span class="line">        results_series = data.groupby([experiment_group_column, y_name]).size()</span><br><span class="line">        </span><br><span class="line">        treatment_group_keys = results_series.index.levels[<span class="number">0</span>].tolist()</span><br><span class="line">        y_name_keys = results_series.index.levels[<span class="number">1</span>].tolist()</span><br><span class="line"></span><br><span class="line">        results = &#123;&#125;</span><br><span class="line">        <span class="keyword">for</span> ti <span class="keyword">in</span> treatment_group_keys: </span><br><span class="line">            results.update(&#123;ti: &#123;&#125;&#125;) </span><br><span class="line">            <span class="keyword">for</span> ci <span class="keyword">in</span> y_name_keys:</span><br><span class="line">                results[ti].update(&#123;ci: results_series[ti, ci]&#125;) </span><br><span class="line"></span><br><span class="line">        <span class="comment"># Probability of conversion and group size by treatment group</span></span><br><span class="line">        nodeSummary = &#123;&#125;</span><br><span class="line">        <span class="keyword">for</span> treatment_group_key <span class="keyword">in</span> results: </span><br><span class="line">            n_1 = results[treatment_group_key][<span class="number">1</span>]</span><br><span class="line">            n_total = (results[treatment_group_key][<span class="number">1</span>] </span><br><span class="line">                       + results[treatment_group_key][<span class="number">0</span>])</span><br><span class="line">            y_mean = <span class="number">1.0</span> * n_1 / n_total</span><br><span class="line">            nodeSummary[treatment_group_key] = [y_mean, n_total]</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> results, nodeSummary </span><br></pre></td></tr></table></figure></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Divergence-related functions, from upliftpy</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_kl_divergence</span>(<span class="params">pk, qk</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Calculate KL Divergence for binary classification.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Parameters</span></span><br><span class="line"><span class="string">    ----------</span></span><br><span class="line"><span class="string">    pk (float): Probability of class 1 in treatment group</span></span><br><span class="line"><span class="string">    qk (float): Probability of class 1 in control group</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">if</span> qk &lt; <span class="number">0.1</span>**<span class="number">6</span>:</span><br><span class="line">        qk = <span class="number">0.1</span>**<span class="number">6</span></span><br><span class="line">    <span class="keyword">elif</span> qk &gt; <span class="number">1</span> - <span class="number">0.1</span>**<span class="number">6</span>:</span><br><span class="line">        qk = <span class="number">1</span> - <span class="number">0.1</span>**<span class="number">6</span></span><br><span class="line">    S = pk * np.log(pk / qk) + (<span class="number">1</span>-pk) * np.log((<span class="number">1</span>-pk) / (<span class="number">1</span>-qk))</span><br><span class="line">    <span class="keyword">return</span> S</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_evaluate_KL</span>(<span class="params">nodeSummary, control_group=<span class="string">&#x27;control&#x27;</span></span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Calculate the multi-treatment unconditional D (one node)</span></span><br><span class="line"><span class="string">    with KL Divergence as split Evaluation function.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Parameters</span></span><br><span class="line"><span class="string">    ----------</span></span><br><span class="line"><span class="string">    nodeSummary (dict): a dictionary containing the statistics for a tree node sample</span></span><br><span class="line"><span class="string">    control_group (string, optional, default=&#x27;control&#x27;): the name for control group </span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Notes</span></span><br><span class="line"><span class="string">    -----</span></span><br><span class="line"><span class="string">    The function works for more than one non-control treatment groups.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">if</span> control_group <span class="keyword">not</span> <span class="keyword">in</span> nodeSummary:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">    pc = nodeSummary[control_group][<span class="number">0</span>]</span><br><span class="line">    d_res = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> treatment_group <span class="keyword">in</span> nodeSummary:</span><br><span class="line">        <span class="keyword">if</span> treatment_group != control_group:</span><br><span class="line">            d_res += _kl_divergence(nodeSummary[treatment_group][<span class="number">0</span>], pc)</span><br><span class="line">    <span class="keyword">return</span> d_res</span><br></pre></td></tr></table></figure><p><br><br><strong>[Kullback-Leibler divergence를 이용한 Scoring의 과정]</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line">method = <span class="string">&#x27;KL&#x27;</span></span><br><span class="line">n_bins = <span class="number">10</span></span><br><span class="line"></span><br><span class="line">all_result = pd.DataFrame()</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> x_name_i <span class="keyword">in</span> X_names: </span><br><span class="line"></span><br><span class="line">    totalSize = <span class="built_in">len</span>(df.index)</span><br><span class="line">    x_bin = pd.qcut(df[x_name_i].values, n_bins, labels=<span class="literal">False</span>, </span><br><span class="line">                    duplicates=<span class="string">&#x27;raise&#x27;</span>)</span><br><span class="line">    d_children = <span class="number">0</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> i_bin <span class="keyword">in</span> <span class="built_in">range</span>(x_bin.<span class="built_in">max</span>() + <span class="number">1</span>): <span class="comment"># range(n_bins):</span></span><br><span class="line">        nodeSummary = _GetNodeSummary(</span><br><span class="line">            data=df.loc[x_bin == i_bin], </span><br><span class="line">            experiment_group_column=<span class="string">&#x27;treatment_group_key&#x27;</span>, y_name=<span class="string">&#x27;conversion&#x27;</span></span><br><span class="line">        )[<span class="number">1</span>]</span><br><span class="line">        nodeScore = _evaluate_KL(nodeSummary,</span><br><span class="line">                                     control_group=<span class="string">&#x27;control&#x27;</span>)</span><br><span class="line">        nodeSize = <span class="built_in">sum</span>([x[<span class="number">1</span>] <span class="keyword">for</span> x <span class="keyword">in</span> <span class="built_in">list</span>(nodeSummary.values())])</span><br><span class="line">        d_children += nodeScore * nodeSize / totalSize</span><br><span class="line"></span><br><span class="line">    parentNodeSummary = _GetNodeSummary(</span><br><span class="line">        data=df, experiment_group_column=<span class="string">&#x27;treatment_group_key&#x27;</span>, y_name=<span class="string">&#x27;conversion&#x27;</span></span><br><span class="line">    )[<span class="number">1</span>]</span><br><span class="line">    d_parent = _evaluate_KL(parentNodeSummary, </span><br><span class="line">                                    control_group=<span class="string">&#x27;control&#x27;</span>)</span><br><span class="line">            </span><br><span class="line">    d_res = d_children - d_parent</span><br><span class="line">        </span><br><span class="line">    one_result = pd.DataFrame(&#123;</span><br><span class="line">        <span class="string">&#x27;feature&#x27;</span>: x_name_i, </span><br><span class="line">        <span class="string">&#x27;method&#x27;</span>: method,</span><br><span class="line">        <span class="string">&#x27;score&#x27;</span>: d_res, </span><br><span class="line">        <span class="string">&#x27;p_value&#x27;</span>: <span class="literal">None</span>,</span><br><span class="line">        <span class="string">&#x27;misc&#x27;</span>: <span class="string">&#x27;number_of_bins: &#123;&#125;&#x27;</span>.<span class="built_in">format</span>(<span class="built_in">min</span>(n_bins, x_bin.<span class="built_in">max</span>()+<span class="number">1</span>)),<span class="comment"># format(n_bins),</span></span><br><span class="line">    &#125;, index=[<span class="number">0</span>]).reset_index(drop=<span class="literal">True</span>)</span><br><span class="line">    </span><br><span class="line">    all_result = pd.concat([all_result, one_result])</span><br><span class="line"></span><br><span class="line">all_result = all_result.sort_values(by=<span class="string">&#x27;score&#x27;</span>, ascending=<span class="literal">False</span>)</span><br><span class="line">all_result[<span class="string">&#x27;rank&#x27;</span>] = all_result[<span class="string">&#x27;score&#x27;</span>].rank(ascending=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">all_result[<span class="string">&#x27;method&#x27;</span>] = method + <span class="string">&#x27; filter&#x27;</span></span><br><span class="line"></span><br><span class="line">all_result[[<span class="string">&#x27;method&#x27;</span>, <span class="string">&#x27;feature&#x27;</span>, <span class="string">&#x27;rank&#x27;</span>, <span class="string">&#x27;score&#x27;</span>, <span class="string">&#x27;p_value&#x27;</span>, <span class="string">&#x27;misc&#x27;</span>]]</span><br></pre></td></tr></table></figure><p>[output]<br><img src="https://i.imgur.com/fgdy1vw.png" width="500px"></p><p><br></p><p><br></p><h4><span id="b-embedded-methods">B. <em>Embedded Methods</em></span></h4><p>이 방법은 uplift model를 훈련시킬 때 나오는 부산물로 변수의 중요성을 얻는다. 이것은 meta-learner과 uplift tree 둘다에서 얻어질 수 있다.</p><h5><span id="-meta-learner">- Meta-learner</span></h5><p>feature 중요도는 base-learner로 부터 얻어진다.<br>예를 들어 <em>Two Model approach</em> 에서는 feature의 중요도점수는 두 base-learner가 산출한 embedding된 중요도 점수의 합으로 정의될 수 있다.</p><p><br></p><h5><span id="-uplift-tree">- Uplift tree</span></h5><p>feature에 대한 중요도 점수는 Tree에서 Tree node가 분할되는 동안의 손실함수에 대한 누적기여로 정의할 수 있다. 이는 대상이 특별한 분할 기준이 있는 Uplift tree라는 점을 제외하면 일반적으로 잘 알려진 classification tree의 embedded feature 중요도와 유사하다. 각 분할에서 우리는 <strong>distribution divergence 의 증가분(gain)</strong> 을 계산한다.</p><p><span class="math inline">\(\Delta = \sum_{k=left,\space right} D(P_k:Q_k)- D(P:Q)\)</span><br>(<span class="math inline">\(P,Q\)</span>는 각각 치료군과 대조군의 Outcome distribution)</p><p>feature의 중요도 점수는 해당 feature가 사용된 노드 분할로 부터 발생하는 모든 <span class="math inline">\(\Delta\)</span>를 더하는 것으로 계산할 수 있다.</p><p><br></p><h4><span id="이후-생략된-내용">이후 생략된 내용 ;</span></h4><p>위에서 소개한 변수선택 방법들의 평가 (synthetic data &amp; real-world data), 논문이 실제 적용에서 추천하는 방법 등</p>]]></content:encoded>
      
      
      <category domain="https://jaysung00.github.io/categories/UPLIFT-MODELING/">UPLIFT MODELING</category>
      
      <category domain="https://jaysung00.github.io/categories/UPLIFT-MODELING/b-Feature-Selection/">b.Feature Selection</category>
      
      
      <category domain="https://jaysung00.github.io/tags/Uplift-modeling/">Uplift modeling</category>
      
      <category domain="https://jaysung00.github.io/tags/Feature-Selection/">Feature Selection</category>
      
      
      <comments>https://jaysung00.github.io/2020/12/17/Selection/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>【Uplift Modeling】도입의 배경에 대해 생각해보자</title>
      <link>https://jaysung00.github.io/2020/12/17/UM-overview/</link>
      <guid>https://jaysung00.github.io/2020/12/17/UM-overview/</guid>
      <pubDate>Thu, 17 Dec 2020 01:40:48 GMT</pubDate>
      
      <description>&lt;p&gt;해당 포스트는 &lt;a href=&quot;https://towardsdatascience.com/a-quick-uplift-modeling-introduction-6e14de32bfe0&quot;&gt;Towards data science 에 게재된 블로그 &#39;Uplift Modeling: A Quick Introduction&#39;&lt;/a&gt;의 내용을 정리 &amp;amp; 추가한 내용임을 밝힙니다.&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<p>해당 포스트는 <a href="https://towardsdatascience.com/a-quick-uplift-modeling-introduction-6e14de32bfe0">Towards data science 에 게재된 블로그 'Uplift Modeling: A Quick Introduction'</a>의 내용을 정리 &amp; 추가한 내용임을 밝힙니다.</p><a id="more"></a><hr><h1><span id="introduction">* Introduction</span></h1><hr><blockquote><p>"누가 미래에 구매를 할 것 같은가 ?"</p></blockquote><p>고전적인 <em>경향성 모델(propensity model)</em> 이 하는 것은 원래 구매로 이어지려고 한 고객을 머신러닝을 이용해 발견해낼 뿐이다. 이러한 모델은 원래 구매를 하려고 했었던 고객과 캠페인에 의해 구매설득이 필요한 고객을 구분하지 않는다.</p><p><br></p><hr><h4><span id="이번엔-새롭게-캠페인treatment-을-통한-프로모션을-한다고-생각해보자-과연-누구를-타겟으로-해야할까">이번엔 새롭게 캠페인(treatment) 을 통한 프로모션을 한다고 생각해보자. 과연 누구를 타겟으로 해야할까.</span></h4><p><br></p><blockquote><p>"어떠한 고객이 <strong>캠페인을 통한 매상이 높을 것</strong> 인가?"</p></blockquote><p>위와 같은 질문을 기준으로 기댓값이 높은 사람을 타겟으로 할 수 있을 것이다. 이것을 예측해서 타겟팅을 하는 모델을 <em>Outcome model</em> 이라고 할 수있다.</p><p>즉, 타겟변수를 <span class="math inline">\(Outcome = P(buy|treatment)\)</span> 로 설정한 것이다.</p><p><br></p><blockquote><p>"캠페인이 고객에게 실제 우리회사 제품의 구매를 <strong>유발했나</strong> ?"<br>" <strong>이미 사려고 했던 사람에게 캠페인을 하는 낭비</strong> 를 하지는 않았나?"<br>"캠페인이 누군가의 <strong>구매를 더욱 악화</strong> 시키지는 않았나?"</p></blockquote><p>그러나 <em>Uplift modeling</em> 은 위와 같은 더욱 중요한 질문에 답하고자 한다.</p><p>이것은 타겟변수를 <span class="math inline">\(Lift = P(buy|treatment) - P(buy|no treatment)\)</span>로 둔 것 과 같다.</p><p><br></p><p><img src="https://i.imgur.com/0YNzU0R.png" width="450px"></p><p><br></p><p>위의 그림 (Yi and Frost <a href="https://tech.wayfair.com/data-science/2018/10/pylift-a-fast-python-package-for-uplift-modeling/">2018a</a>) 과 같이 고객이 캠페인의 대상이 되는지 여부와 그에 따른 고객의 행동에 따라 4가지 세그먼트로 고객의 타입을 분류할 수 있다.</p><ul><li><p><strong>'persuadables'</strong> :<br>마케팅 캠페인에 노출이 되면 구매를 하지만 노출되지 않으면 구매하지 않는 그룹<br><span class="math inline">\(Lift = P(buy|treatment) - P(buy|no treatment) = 1\)</span></p></li><li><p><strong>'sure things'</strong> :<br>캠페인과 관계없이 어짜피 구매할 예정인 그룹<br><span class="math inline">\(Lift = P(buy|treatment) - P(buy|no treatment) = 0\)</span></p></li><li><p><strong>'lost causes'</strong> :<br>캠페인과 관계없이 어짜피 구매하지 않을 그룹<br><span class="math inline">\(Lift = P(buy|treatment) - P(buy|no treatment) = 0\)</span></p></li><li><p><strong>'sleeping dogs'</strong> :<br>캠페인에 노출되지 않으면 구매하지만 오히려 노출될 경우 구매를 하지 않게되는 그룹<br>('이런 광고에 돈을 쓰는 회사의 제품을 구매하고 싶지 않아!' 혹은 '나의 프라이버시가 이용되는 곳에 돈을 쓰고 싶지 않아!' 등과 같은 이유)<br><span class="math inline">\(Lift = P(buy|treatment) - P(buy|no treatment) = -1\)</span></p></li></ul><p><br></p><p>모든 고객들에 대해 소속된 세그먼트를 미리 알 수 있는 이상적인 세계가 존재한다면, 그에 따라 'Persuadables' 세그먼트의 고객들만 타겟에 넣고 'Sleeping dogs' 세그먼트는 절대 고객은 넣지 않을 것이다. 그러나 현실에서는 각 고객이 어느 세그먼트의 고객인지 아는 것은 불가능하다. 그 대신, 통계의 힘과 머신러닝으로 <strong>해당고객과 "비슷한 고객"이 평균적으로 어느 세그먼트에 속해 있는지</strong> 는 알 수 있을 것이다. 이것이 Uplift modeling이 우리에게 알려주는 것이다.</p><p>모든 개인은 -1 부터 1 사이의 lift값을 갖게 되고 우리는 이 값을 통해 타겟을 결정할 것이다.<br>만약 모델이 정확하다면, <strong>높은 lift값을 가진 고객에게 더 높은 캠페인 효과를 기대할 수 있을 것이고 낮은 lift값의 고객에게는 낮은 캠페인 효과가 나타날 것이다.</strong></p><p><br></p><hr><h1><span id="uplift-modeling의-접근방법">* Uplift modeling의 접근방법</span></h1><hr><p>Uplift modeling은 특정고객에게 캠페인을 제공하는것이 이득인지 아닌지를 결정하는 task를 위해 만들어졌고, 이것은 <strong>어떤 고객이 어떤 세그먼트에 속하는지 결정하는 모델을 만드는 것</strong> 이며, 결과적으로 <strong>마케팅 수단이 고객의 구매로 이어지는 확률을 결정하는 것을 돕는 모델링</strong> 이다.</p><p>이러한 Uplift modeling은 여러가지 접근 방법으로 연구되어오고 있다.</p><p>다른 포스팅에서 이러한 다양한 접근방법에 대해 자세히 다루게 될 것이다.</p>]]></content:encoded>
      
      
      <category domain="https://jaysung00.github.io/categories/UPLIFT-MODELING/">UPLIFT MODELING</category>
      
      <category domain="https://jaysung00.github.io/categories/UPLIFT-MODELING/a-Overall/">a.Overall</category>
      
      
      <category domain="https://jaysung00.github.io/tags/Uplift-modeling/">Uplift modeling</category>
      
      
      <comments>https://jaysung00.github.io/2020/12/17/UM-overview/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>【Causal Inference②】조작변수법(IV)에 관하여</title>
      <link>https://jaysung00.github.io/2020/12/04/CN2/</link>
      <guid>https://jaysung00.github.io/2020/12/04/CN2/</guid>
      <pubDate>Fri, 04 Dec 2020 08:34:44 GMT</pubDate>
      
      <description>&lt;hr /&gt;</description>
      
      
      
      <content:encoded><![CDATA[<hr><a id="more"></a><h1><span id="rct를-사용할-수-없을-때는-어떻게-할까">* RCT를 사용할 수 없을 때는 어떻게 할까?</span></h1><hr><p>Level 1. 실험(Experimental) 레벨 (개입연구)</p><ul><li>관찰자(해석자)가 개입의 계획을 세워서 데이터를 수집 <span class="math inline">\(\rightarrow\)</span> RCT (무작위화비교실험)</li></ul><p><br></p><h3><span id="blacktriangleright-level-2-준실험quasi-experimental-레벨"><span class="math inline">\(\blacktriangleright\)</span> Level 2. 준실험(Quasi Experimental) 레벨</span></h3><ul><li><p>비교적 질 좋은 관찰연구 정도의 느낌</p></li><li><p>실험데이터가 아니라 <strong>관찰데이터</strong> 를 사용해서, 개입의 여부 등으로 결과에의 영향을 추정</p></li><li><p><strong>측정되지 않은 교란인자</strong>를 처리할 수 있는 것은 사실상 RCT만이 쉽게 가능하지만, <strong>모든 교란인자를 충분히 측정할 수 있다고 하면</strong> 준실험설계로도 충분히 인과관계를 설명할 수 있다.</p></li><li><p><strong>변수조작법(IV)</strong> , <strong>차의 차 분석(DID)</strong> , <strong>경향스코어 매칭(PS)</strong> , <strong>회귀불연속 디자인(RDD)</strong> 등이 있다.</p></li></ul><p><br></p><p>Level 3. 관찰(Observation) 레벨</p><ul><li>더욱 인과추론 하기에 취약한 관찰연구 디자인</li></ul><p><br></p><hr><h1><span id="i-조작변수법-iv-instrumental-variable-methods"><span class="math inline">\(I\)</span>. 조작변수법 (IV; Instrumental variable methods)</span></h1><hr><h3><span id="-조작변수법이란">- 조작변수법이란?</span></h3><ul><li>매우 어렵지만 이론상 완벽하게 설계된다면 <strong>측정되지 않은 교란인자</strong> 도 처리할 수 있는 방법.</li></ul><p><br></p><ul><li><p><strong>외생변수</strong> ; 모델의 밖에서 결정되어 주어진 변수 (설명변수로써 바람직하다).</p><ul><li><strong>모델의 잔차항</strong> 과 독립하게 된다.</li></ul></li></ul><p><br></p><ul><li><p><strong>내생변수</strong> ; 모델 내에서 결정되는 변수 (설명변수로써 바람직하지 않다).</p><ul><li>예를 들어 <em>측정되지 않은 교란인자</em> 가 있는 경우 영향을 받는 <strong>설명변수와 모델의 잔차항 사이에 상관</strong> 관계가 생겨버리고 이 설명변수는 <strong>내생변수</strong> 가 되어 <em>내생성 바이어스</em> 를 만든다.</li></ul></li></ul><p><br></p><ul><li><p>이렇게 발생된 <strong>내생변수</strong> 를 <strong>외생화</strong> 하기 위해 도입된 변수 <span class="math inline">\(Z\)</span>를 <strong>조작변수(IV)</strong> 라고 한다.</p></li><li><p>이러한 조작변수를 이용해, 설명변수가 결과에 미치는 영향을 평가하는 방법을 <strong>조작변수법</strong> 이라고 한다.</p></li></ul><p><br></p><blockquote><p><span class="math inline">\([ 예시 ]\)</span><br><img src="https://i.imgur.com/Q8xihRF.png" width="550px"><br>- 참의 관계 : <span class="math inline">\(ln(wage) = a + b \cdot educ + c \cdot ability + u\)</span></p></blockquote><p>임금(Wage)와 교육년수(Education)와 능력(Ability)은 위와 같은 관계가 있다고 가정한다.</p><p>그러나 능력은 실제로 측정불가하기 때문에 교육수준만으로 임금과의 관계를 설명하는 모델을 했다고 하자.</p><ul><li><span class="math inline">\(ln(wage) = a&#39; + b&#39; \cdot educ + v\)</span></li></ul><p>이 때, 능력(Ability)은 <strong>관측되지 않은 교란인자</strong> 가 되고 계수 <span class="math inline">\(b&#39;\)</span>에는 내생성 바이어스가 존재하게 된다.</p><p><br></p><h3><span id="-조작변수법의-과정">- 조작변수법의 과정</span></h3><p><strong>내생변수</strong> 를 피설명변수로 별도의 조작변수 <span class="math inline">\(IV\)</span>를 통해 설명하는 모델을 작성한다.</p><ul><li><span class="math inline">\(\begin{align} ln(wage) &amp;= a&#39; + b&#39; \cdot educ + \underline v \\ &amp;= a&#39; + b&#39; \cdot educ + \underline {c&#39; \cdot X+ v&#39;} \end{align}\)</span></li></ul><p><span class="math inline">\(\space\space\space\space\space\space\space\space\space\space\space\space\space\)</span> (C를 잔차항에 포함된 <em>교란인자</em> 라고 가정)</p><ul><li><span class="math inline">\(\bf educ = \alpha + \beta \cdot \underline {IV} + \gamma \cdot X + \epsilon\)</span><br><br><br><img src="https://i.imgur.com/SJ5bifx.png" width="600px"></li></ul><p><br></p><ul><li><p><strong>조작변수 <span class="math inline">\(\bf IV\)</span>의 조건</strong></p><ol type="1"><li><p><code>Exclusion restriction</code> : IV는 원래의 결과부분에 해당하는 변수(Wage)에게 개입변수(설명변수, Education)를 통해서만 영향을 줄 수있다.</p></li><li><p><code>No instrument-outcome confounder</code>：IV와 원래의 결과부분에 해당하는 변수(Wage)에게 동시에 영향을 주는 <strong>공통의 원인(L 또는 X)</strong> 이 존재하지 않아야 한다</p></li><li><p><code>Instrument relevance</code> : 개입변수(설명변수, Education)에게는 확실히 영향을 주는 변수여야 한다.</p></li><li><p><code>Monotonicity</code> : 조작변수가 역효과를 내는 사람(Defiers)이 존재하지 않아야 한다. (완전히 반대로 움직이는 케이스)</p></li></ol></li></ul><p>이상의 조건을 만족하는 조작변수를 발견해, 이를 통해 교란인자에 의한 효과를 제거한다.<br><br></p><h4><span id="그러나-이러한-조건을-만족하는-조작변수를-찾아내는-것은-매우-어렵고-특히-비즈니스-현장에서는-거의-불가능에-가깝다">【그러나, 이러한 조건을 만족하는 조작변수를 찾아내는 것은 매우 어렵고 특히 비즈니스 현장에서는 거의 불가능에 가깝다.】</span></h4><p><br></p><hr><h2><span id="i-i-처치의도에-의한-분석-intention-to-treat-analysis"><span class="math inline">\(I-I.\)</span> 처치의도에 의한 분석 (Intention to treat analysis)</span></h2><h3><span id="spacespacespacespacespace-그럼에도-불구하고-생각해보는-조작변수법iv의-활용-가능성"><span class="math inline">\(\space\space\space\space\space\)</span> - 그럼에도 불구하고 생각해보는 조작변수법(IV)의 활용 가능성</span></h3><hr><p><br><br>- 실제 개입에서는 개입의 대상이지만 따르지 않는 경우나 대상이 아니지만 따르는 경우와 같이 참가자가 개입의도와 반대로 움직이는 경우가 존재한다.</p><ul><li><p><em>'정책이나 치료와 같은 개입의 효과를 추정하기 위해서 개입의도대로 움직이는 부분집단만을 비교하는 것이 좋지 않을까'</em> 라는 이론</p></li><li><p>개입을 행하는 참가자의 의도를 <strong>1과 0을 갖는 dummy 조작변수 <span class="math inline">\(z\)</span></strong> 로 생각한다.</p></li></ul><p><img src="https://i.imgur.com/qCI2qOc.png" width="600px"></p><p><br></p><ul><li><span class="math inline">\(\begin{equation}z= \left \{\begin{array}{l}1　(개입의도 있음) \\0　(개입의도없음)\end{array}\right.\end{equation}\)</span></li></ul><p><br></p><ul><li><span class="math inline">\(d = zd_1 + (1-z)d_0\)</span><br>(<span class="math inline">\(d\)</span>는 <span class="math inline">\(z\)</span>가 1일 때 <span class="math inline">\(d_1\)</span>이 되고, <span class="math inline">\(z\)</span>가 0일 때 <span class="math inline">\(d_0\)</span>이 된다.)</li></ul><p><br></p><ul><li><span class="math inline">\(\begin{equation}d= \left \{\begin{array}{l}1　(실행) \\0　(실행하지않음)\end{array}\right.\end{equation}\)</span></li></ul><p><br></p><ul><li><span class="math inline">\(y=dy_1 + (1-d)y_0\)</span><br>(마찬가지로 <span class="math inline">\(y\)</span>는 <span class="math inline">\(d\)</span>가 1일 때 <span class="math inline">\(y_1\)</span>이 되고, <span class="math inline">\(d\)</span>가 0일 때 <span class="math inline">\(y_0\)</span>이 된다.)</li></ul><p><br></p><ul><li><p>조작변수<span class="math inline">\(z\)</span>의 가정</p><ul><li><p><span class="math inline">\(\bf (y_0,y_1) \perp z|d,\)</span> : 변수 <span class="math inline">\(d\)</span>에 의해 <span class="math inline">\(z\)</span>와 <span class="math inline">\(y\)</span>가 <a href="https://jaysung00.github.io/2020/11/14/BN1/"><span class="math inline">\(d\)</span>-seperate</a> 되므로 <code>Exclusion restriction</code> 와 <code>No instrument-outcome confounder</code> 만족</p></li><li><p><span class="math inline">\(\bf d_{i1} \geq d_{i0}\)</span> : <code>Monotonicity</code> 만족 (제비에 뽑히면 공립에 가고, 제비에 떨어지면 사립에 가는 Defiers는 존재하지 않는다고)</p></li><li><p>(<span class="math inline">\(d\)</span>와 <span class="math inline">\(z\)</span>의 정의에 의해 <code>Instrument relevance</code>는 자동으로 만족)</p></li></ul></li></ul><p><br></p><table><thead><tr class="header"><th style="text-align: center;">설계자의 의도 <span class="math inline">\(z\)</span></th><th style="text-align: center;">참가자의 의사 <span class="math inline">\(d\)</span></th><th style="text-align: center;">Notation</th><th style="text-align: left;">상황의 해석</th></tr></thead><tbody><tr class="odd"><td style="text-align: center;">1</td><td style="text-align: center;">1</td><td style="text-align: center;"><span class="math inline">\(d_1\)</span> = 1</td><td style="text-align: left;">개입의 대상이 되어서 참가자가 개입의도에 맞게 따르는 경우</td></tr><tr class="even"><td style="text-align: center;">1</td><td style="text-align: center;">0</td><td style="text-align: center;"><span class="math inline">\(d_1\)</span> = 0</td><td style="text-align: left;">개입의 대상이 되었지만 참가자가 개입의도에 따르지 않는 경우 (noncompliance)</td></tr><tr class="odd"><td style="text-align: center;">0</td><td style="text-align: center;">1</td><td style="text-align: center;"><span class="math inline">\(d_0\)</span> = 1</td><td style="text-align: left;">개입의 대상이 아님에도 불구하고 개입의도의 방향으로 움직이는 경우 (noncompliance)</td></tr><tr class="even"><td style="text-align: center;">0</td><td style="text-align: center;">0</td><td style="text-align: center;"><span class="math inline">\(d_0\)</span> = 0</td><td style="text-align: left;">개입의 대상이 아니였기 때문에 개입의도에 따르지 않는 경우</td></tr></tbody></table><p><br></p><h3><span id="-국소적-평균효과late-local-average-treatment-effect">- <strong>국소적 평균효과(LATE; local average treatment effect)</strong></span></h3><p><br></p><ul><li><p>정의 ; <span class="math inline">\(\Large LATE = E(y_1-y_0|d_1=1,d_0=0)\)</span></p></li><li><p>의미 ; 개입의도의 방향대로 움직여주는 부분집합에서만 측정한 효과</p></li></ul><p><br></p><h3><span id="-late의-추정">- LATE의 추정</span></h3><p><br></p><p>조작변수 <span class="math inline">\(z\)</span>의 가정에 의해,</p><p><span class="math inline">\(\begin{align} E(y|z=1) - E(y|z=0) &amp;= E(dy_1+(1-d)y_0|z=1) - E(dy_1+(1-d)y_0| z=0)\\ &amp;= E(d_1y_1+(1-d_1)y_0|z=1)-E(d_0y_1+(1-d_0)y_0|z=0) \\ &amp;= E(d_1y_1 + (1-d)y_0)-E(d_0y_1 + (1-d_0)y_0)\\ &amp;= E((d_1-d_0)(y_1-y_0)) \\ &amp;\space \\ &amp;\space\space\space\space\space\space\space\space\space\space\space\cdots d_1-d_0는\space\{-1,0,1\},\space\space Monotonicity가정에\space\space의해\space\space p(d_1-d_0=-1)=0 \space\space 이므로\\ &amp;\space \\ &amp;=\sum_{a=-1,0,1}aE(y_1-y_0|d_1-d_0 = a)p(d_1-d_0 = a) \\ &amp;= \underline {E(y_1-y_0|d_1-d_0=1)} \space p(d_1-d_0=1) \end{align}\)</span></p><p><br></p><p>위 식의 우변에 <span class="math inline">\(E(y_1-y_0|d_1-d_0=1)\)</span>가 <span class="math inline">\(\bf LATE\)</span> 의 정의가 되므로,</p><p><br></p><p><span class="math inline">\(\begin{align} {\bf LATE} &amp;= E(y_1-y_0|d_1-d_0=1) \\ &amp;\space \\ &amp;= \cfrac{E(y|z=1) - E(y|z=0)}{p(d_1-d_0=1)} \\&amp;\space \\ &amp;= \cfrac{E(y|z=1) - E(y|z=0)}{ p(d_1=1,d_0=0)} \\ &amp;\space \\ &amp;= \cfrac{E(y|z=1) - E(y|z=0)}{\{p(d_1=1,d_0=1) + p(d_1=1,d_0=0)\} - p(d_0=1,d_1=1)} \\ &amp;\space \\ &amp;= \cfrac{E(y|z=1) - E(y|z=0)}{p(d_1=1)-p(d_0=1)} \\ &amp;\space \\ &amp;= {\bf \cfrac{E(y|z=1) - E(y|z=0)}{E(d|z=1)-E(d|z=0)}} \end{align}\)</span></p><p><br></p><p>로 바꿔쓰는 것이 가능해, 이것은 <span class="math inline">\(z\)</span>가 2진변수(binary variable)인 경우의 <strong>조작변수추정량</strong> 과 같고, <span class="math inline">\(\bf LATE\)</span>는 이것으로 추정가능하게 된다.</p><p><br></p><hr><p><br></p><blockquote><p>[예시]<br><strong>콜롬비아에서 이루어진 '바우쳐제도'는 학업성적 향상의 효과가 있었을까?</strong></p></blockquote><blockquote><p>[상황설명]<br>- 바우쳐제도란, 제비뽑기로 장학생을 선정해서 사립 중학교의 수업료 절반을 부담해주는 제도이다.<br>- 그러나 바우쳐제도 만으로 수업료를 감당하기 힘들어 제비뽑기에서 선발되어도 사립중학교의 입학을 포기하는 학생들이 존재했다.<br>- 부모님들의 경제적능력이 좋거나 사립학교를 선호하는 학생들은 제비뽑기에서 떨어져도 사립학교에 입학했다.</p></blockquote><blockquote><p>[가정 (실제 데이터가 아님) ]<br>- 1,000명의 학생이 제비를 뽑아 당첨된 학생은 300명이였다.<br>- 제비에 당첨된 300명의 학업성적의 평균은 80점<br>- 제비에 당첨되지 않은 700명의 학업성적은 60점<br>- 제비에 당첨됐을 때 사립학교에 진학학 확률은 90%<br>- 제비에 당첨되지 않았음에도 사립학교에 진학할 확률은 15%</p></blockquote><p><br></p><ul><li><span class="math inline">\(\begin{equation}z= \left \{\begin{array}{l}1　(제비뽑기당첨) \\0　(제비뽑기탈락)\end{array}\right.\end{equation}\)</span></li></ul><p><br></p><ul><li><span class="math inline">\(d = zd_1 + (1-z)d_0\)</span></li></ul><p><br></p><ul><li><span class="math inline">\(\begin{equation}d= \left \{\begin{array}{l}1　(사립학교진학) \\0　(공립학교진학)\end{array}\right.\end{equation}\)</span></li></ul><p><br></p><ul><li><span class="math inline">\(y=dy_1 + (1-d)y_0\)</span> (성적)</li></ul><p><br></p><ul><li><p>여기서 우리가 궁금한 것은 <strong>[바우쳐제도] <span class="math inline">\(\rightarrow\)</span> [사립학교진학] <span class="math inline">\(\rightarrow\)</span> [성적향상]</strong> 의 인과스토리(causal story)를 가진 효과이다.</p></li><li><p>그러므로 우리가 관심있는 케이스는 <strong>제비뽑기에 붙으면 사립학교에 가고 떨어지면 공립학교에 진학할 학생</strong> 이다.</p></li><li><p>즉, 제비뽑기에 붙던 안붙던 사립학교에 갈 학생 (<span class="math inline">\(d_1=1,d_0=1\)</span>)이나 붙던 안붙던 공립학교에 갈 학생 (<span class="math inline">\(d_1=0,d_0=0\)</span>)은 고려의 대상이 아니다.</p></li></ul><p><br></p><ul><li><p>따라서, <span class="math inline">\(ATE = E(y_1-y_0)\)</span> 를 구하면 단순히 사립학교와 공립학교의 성적 차이를 구하게 된다.</p></li><li><p>이 경우 <span class="math inline">\({\bf LATE} = E(y_1-y_0|d_1=1,d_0=0)\)</span> 를 구하는 것이 바람직할 것이다.</p></li></ul><p><br></p><ul><li><p><strong><span class="math inline">\({\bf LATE}\)</span>의 추정</strong></p><ul><li><p><span class="math inline">\(E(y|z=1) = 80\)</span></p></li><li><p><span class="math inline">\(E(y|z=0) = 60\)</span></p></li><li><p><span class="math inline">\(E(d|z=1) = 0.9\)</span></p></li><li><p><span class="math inline">\(E(d|z=0) = 0.15\)</span></p></li><li><p><span class="math inline">\(\begin{align} LATE &amp;= \cfrac{E(y|z=1) - E(y|z=0)}{E(d|z=1)-E(d|z=0)}\\ &amp;\space \\ &amp;= \cfrac{80-60}{0.9-0.15} \fallingdotseq 26.6666 \end{align}\)</span></p></li><li><p>국소적 평균효과(LATE)의 관점에서 26.66점의 성적향상효과가 있었다고 추정할 수 있다.</p></li></ul></li></ul><p><br></p><h4><span id="결론이와-같이-준실험으로써의-조작변수법은-상당이-어렵지만-bf-late-의-아이디어로써의-조작변수법은-생각해볼만-하다">【결론】이와 같이 준실험으로써의 조작변수법은 상당이 어렵지만 <span class="math inline">\(\bf LATE\)</span> 의 아이디어로써의 조작변수법은 생각해볼만 하다.</span></h4><p><br></p><hr><h2><span id="reference">* Reference</span></h2><p>해당 포스트는 <a href="https://www.youtube.com/watch?v=u8hsTkLg2xc&amp;t=159s">유튜브 채널「データの科学のメソドロジー」의 山田典一님의 강의</a>를 틀로 내용을 정리 &amp; 추가 했음을 밝힙니다.</p><p>그 외 참조</p><p><a href="https://www.amazon.co.jp/dp/4000069721/ref=cm_sw_r_tw_dp_U_x_5LQxEbXZJDK4H">調査観察データの統計科学―因果推論・選択バイアス・データ融（星野崇宏）</a></p><p><a href="http://www.ier.hit-u.ac.jp/~kitamura/lecture/Hit/08Statsys5.pdf">捜査変数法（一橋大学経済研究所, 北村 行伸）</a></p><p><a href="https://healthpolicyhealthecon.com/2015/02/23/experiment-and-quasi-experiment-1/">操作変数法Instrumental variable methodsに関するブログ (津川友介)</a></p>]]></content:encoded>
      
      
      <category domain="https://jaysung00.github.io/categories/Prerequisite/">Prerequisite</category>
      
      <category domain="https://jaysung00.github.io/categories/Prerequisite/Causal-Inference/">Causal Inference</category>
      
      <category domain="https://jaysung00.github.io/categories/Prerequisite/Causal-Inference/a-Overall/">a.Overall</category>
      
      
      <category domain="https://jaysung00.github.io/tags/Causal-Inference/">Causal Inference</category>
      
      <category domain="https://jaysung00.github.io/tags/Bayesian-Network/">Bayesian Network</category>
      
      
      <comments>https://jaysung00.github.io/2020/12/04/CN2/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>【Causal Inference①】인과추론의 목적과 RCT에 관하여</title>
      <link>https://jaysung00.github.io/2020/11/30/CI1/</link>
      <guid>https://jaysung00.github.io/2020/11/30/CI1/</guid>
      <pubDate>Mon, 30 Nov 2020 02:39:29 GMT</pubDate>
      
      <description>&lt;hr /&gt;</description>
      
      
      
      <content:encoded><![CDATA[<hr><a id="more"></a><h1><span id="인과추론causal-inference으로-뭘-할-수-있는데">* 인과추론(Causal Inference)으로 뭘 할 수 있는데?</span></h1><hr><blockquote><p>"A 아이스크림을 공중파 CF에 내보냈을때, 해당 아이스크림의 매상은 얼마나 올랐을까?"</p></blockquote><blockquote><p>"전 사원 대상 Python 연수 프로그램을 설치 했을때, 사원 들의 일의 능률은 얼마나 올랐을까?"</p></blockquote><p>이와 같은 질문들은 비즈니스에서 일상적으로 흔히 나올 수 있는 질문들이다.</p><p>하지만 이에 대해 <strong>깊은 고찰 없이 단순하게 효과를 정의하고 평가함</strong> 으로써, 우리는 수많은 <strong>바이어스</strong> 를 만들어 내고 있다.</p><p>공중파 CF의 효과를 계산하기 위해 단순히 CF 전후의 매상의 차이를 계산해서, CF와 관계없이 시기적으로 날씨가 더워져서 오른 맥주의 매상까지도 <strong>CF의 효과</strong>로써 평가해버린다.</p><p>또한 Python 연수를 신청한 사람들은 그렇지 않은 사원들보다 원래부터 우수한 사람이 많을수 있다. 원래부터 일의 능률이 높은 연수자그룹과 비연수자 그룹의 능률을 단순 비교해서 원래의 차이까지도 <strong>python연수의 효과</strong>로 평가해버린다.</p><p>이처럼 인과추론의 목적를 철저하게 비즈니스적 관점에서 보자면 <strong>어떠한 시책의 정확한 효과측정</strong> 을 위한 이론 &amp; 기술 분야라고 할 수 있다.</p><p><br></p><hr><h1><span id="inference-의-신뢰성의-3단계">* Inference 의 신뢰성의 3단계</span></h1><hr><h3><span id="level-1-실험experimental-레벨">Level 1. 실험(Experimental) 레벨</span></h3><ul><li><p><strong>RCT (Randomized Controlled Trial; 무작위화 비교 실험)</strong></p></li><li><p>3가지 기본요건</p><p>(1). <strong>비교</strong> : <code>Control Group</code>과 <code>Treatment Group</code> 의 비교를 통해 독립변수가 종속변수에 영향을 미쳤는지 확인하는 과정</p><p>(2). <strong>조작</strong> : 시간적으로 독립변수가 먼저 발생하고 그 후에 뒤따라 종속변수가 발생함을 입증하기 위해, 임의로 독립변수를 의도적인 시기에 발생하도록하고 이에 뒤따른 종속변수의 변화를 측정하도록 시간적 순서를 조작하는 것 <em>(인과성의 선후관계)</em></p><p>(3). <strong>통제</strong> : 허위적 관계가 아닌 것을 입증하기 위해, 독립변수를 제외한 종속변수에 영향을 미칠 수 있는 여러 변수들이 종속변수에 영향을 미치지 못하도록 상황을 의도적으로 통제하는 것</p></li></ul><h3><span id="level-2-준실험quasi-experimental-레벨">Level 2. 준실험(Quasi Experimental) 레벨</span></h3><ul><li><p><code>Level 1</code>의 실험설계는 인과관계를 명확히 구명할 수 있지만, 인위적 통제가 어렵거나 윤리적 문제등으로 인해 (<em>특히 비즈니스의 경우 제한된 예산 등에 의해</em>) 실제 활용이 매우 어렵다. 이에 따라 비록 실험 설계에는 미치지 못하지만, 그 대안적인 방법으로 활용되는 방법이다.</p></li><li><p>대표적인 방법</p><p>(1). <strong>시계열 설계(time-series design)</strong> : 비교집단을 별도로 설정하기 곤란한 경우에 <em>하나의 집단</em> 을 선택해서, 독립변수 도입의 전후상태를 비교하는 방법이다. 외적요인에 대한 통제가 어렵기 때문에 (각 기간마다 외부의 영향이 다르다), 위험이 있을 수 있다. 이를 개선하기 위해서는 같은 조사를 여러 집단에서 되풀이하여 실시하여 같은 결과를 얻을 수 있는지 확인할 필요가 있다.</p><p>(2). <strong>비동일 통제집단 설계(nonequivalent control group design)</strong> : 비동일 통제집단 설계는 실험설계의 통제집단 전후비교와 유사하지만 <em>비교집단을 무작위로 선정하지 않는다</em> 는 차이가 있다. 비동일 통제집단 설계는 무작위배치 이외의 방법(매칭, 기존집단의 선정 등)으로 <code>Control Group</code> 및 <code>Treatment Group</code>을 선정한다.</p><p>이외에도 <strong>변수조작법(IV)</strong> , <strong>차의 차 분석(DID)</strong> , <strong>경향스코어 매칭(PS)</strong> , <strong>회귀불연속 디자인(RDD)</strong> 등이 있다.</p></li></ul><h3><span id="level-3-관찰observation-레벨">Level 3. 관찰(Observation) 레벨</span></h3><ul><li><p><em>독립변수를 조작할 수 없고, 연구대상을 무작위할 수 없는 경우</em> 이다. 어느 한 시점에서 독립변수와 종속변수 모두를 측정해서 상관관계를 파악하는데에 그친다.</p></li><li><p>선후관계가 파악되지 않았고, 무작위화를 통해 동일한 집단에서 비교하지 못했으므로 부적절한 해석을 하게 될 위험을 가지고 있다.</p></li><li><p><strong>확증편향</strong> <span class="math inline">\(^{[*1]}\)</span>(confirmation bias) 이나 <strong>사후해석편향</strong> <span class="math inline">\(^{[*2]}\)</span>(hindsight bias)에 영향을 받기 쉽다. 예를 들어, 시책 담당자가 좋은 결과만을 보고 싶다고 하면 집계의 방법을 유리하게 설정해서 유리한 결과가 나오도록 하는 것이 얼마든지 가능하므로 주의가 필요하다.</p><ul><li><p><code>Level 3</code>은 <code>Level 1</code>&amp; <code>Level 2</code>를 한 후에 추가적으로 검토하는 용도.</p></li><li><p>또한, 집계의 방법을 미리 정해놓는 것을 통해, 자의적으로 변경해서 입맛에 맞는 해석을 하지 않는 것이 중요하다.</p></li></ul></li></ul><p><br></p><p>####【여기서 기억해야 할 것】 Lv1 <span class="math inline">\(\rightarrow\)</span> Lv2 <span class="math inline">\(\rightarrow\)</span> Lv3 의 순서로 시책의 효과를 검토해가는 것이 중요하다!!</p><p><br></p><p>&lt;span style="font-size: 85%;&gt; <span class="math inline">\(^{[*1]}:\)</span> 원하는 정보를 선택적으로 모으는 등의 가지고 있는 신념을 확인하려는 경향성. </p><p>&lt;span style="font-size: 85%;&gt; <span class="math inline">\(^{[*2]}:\)</span> 어떤 사건이 발생한 후, 사전에 그런 일이 일어날 것으로 예상했었다는 식으로 문제를 처리하는 것. 실제로는 벌어진 사건에 대해 전혀 대비를 하지 못하고, 그 원인을 냉정하게 규명해야 함에도 불구하고 "충분히 예측했던 일"이라며 자기 확신에 빠지는 것.</p><hr><h1><span id="potential-outcome-framework">* Potential Outcome Framework</span></h1><hr><ul><li><p><strong>처치(Treatment) 혹은 개입(Intervention)이 이뤄졌는지 여부</strong></p><p><span class="math inline">\(\begin{equation}Z_i= \left \{\begin{array}{l}1　(Treated) \\0　(Untreated)\end{array}\right.\end{equation}\)</span><br><br></p></li><li><p><strong>종속변수(DV; Dependent Variable) 혹은 목적변수(Criterion Variable)</strong> ; 개입을 받은 경우와 받지 않은 경우 두가지로 나타낼 수 있다.<br><em>(실제로는 어느 한쪽만 관찰가능하지만)</em></p><p><span class="math inline">\(\begin{equation}Y_i= \left \{\begin{array}{l}Y_i^{(1)}　(Z_i = 1) \\Y_i^{(0)}　(Z_i = 0)\end{array}\right.\end{equation}\)</span></p><p><span class="math inline">\(\Rightarrow Y_i = Y_i^{(0)}(1- Z_i) + Y_i^{(1)}Z_i\)</span></p></li></ul><p><br></p><ul><li><p>이와 같이, 샘플 <span class="math inline">\(i\)</span> 에 대하여 개입을 받은 경우의 결과 <span class="math inline">\(Y^{(1)}\)</span> 와 받지 않은 경우의 결과 <span class="math inline">\(Y^{(0)}\)</span> 간의 차이가 개입의 진정한 <strong>처치효과(TE; Treatment Effect)</strong> 라고 가정하는 것을 <strong>Potential Outcome Framework</strong> 라고 한다.</p><p><span class="math inline">\(\bf \tau_{TE} = Y^{(1)}-Y^{(0)}\)</span></p></li></ul><p><br></p><ul><li><p>모든 샘플 <span class="math inline">\(i\)</span> 에 대해 각각의 처치효과를 구하는 것은 까다롭기 떄문에, 그룹간의 비교로써 <strong>평균처치효과(ATE; Average Treatment Effect)</strong> 를 다루는 경우도 많다.</p><p><span class="math inline">\(\bf \tau_{ATE}= E[Y^{(1)}]-E[Y^{(0)}]\)</span></p></li></ul><p><br></p><hr><h1><span id="level-1-실험레벨-인과추론의-기초-rct">* Level 1. 실험레벨 ; 인과추론의 기초, RCT</span></h1><hr><h3><span id="-rct의-특징">- RCT의 특징</span></h3><ul><li><p>비즈니스의 관점에서는 <strong>AB테스트</strong> 라고 할 수 있다.</p></li><li><p>RCT (Randomized Controlled Trial; 무작위화 비교 실험)를 통해 <code>Control Group</code>과 <code>Treatment Group</code>을 무작위하게 나눔으로써 <strong>두 그룹간의 동질성</strong> 을 기대할 수 있다.</p></li><li><p>측정된 교란인자(confounding factors)<span class="math inline">\(^{[*1]}\)</span>는 물론, <strong>측정되지 않은 교란인자</strong> 에 대해서도 비교군과 대조군의 균형을 이룬다.<br>(측정되지 않은 교란인자 까지 처리할 수 있는 실험디자인은 <strong>RCT</strong>와 완벽하게 설계된 조작변수법(IV), 분할시계열디자인(ITS) 밖에 존재하지 않는다.)</p></li><li><p>그로 인해 모든 연구 디자인 중 가장 높은 내적타당성<span class="math inline">\(^{[*2]}\)</span>을 기대할 수 있다.</p></li><li><p>즉 RCT에서는 이론상, <span class="math inline">\(ATU = ATT = ATE\)</span>을 기대할 수 있다.</p><p>( <span class="math inline">\(ATU\)</span> <em>(Average Treatment Effect on the Untreated)</em> <span class="math inline">\(= E[Y^{(1)}|Z=0] - E[Y^{(0)}|Z=0]\)</span> )</p><p>( <span class="math inline">\(ATT\)</span> <em>(Average Treatment Effect on the Treated)</em> <span class="math inline">\(= E[Y^{(1)}|Z=1] - E[Y^{(0)}|Z=1]\)</span> )</p><p>( <span class="math inline">\(\bf ATE\)</span> <strong>(Average Treatment Effect)</strong> <span class="math inline">\(\bf = E[Y^{(1)}] - E[Y^{(0)}]\)</span> )</p></li></ul><p><br></p><p><img src="https://i.imgur.com/waDPtS0.png" width="600px"></p><p>[*] 위의 표에서 <code>Control Group</code>의 <span class="math inline">\(Y_i^{(1)}\)</span>과 <code>Treatment Group</code>의 <span class="math inline">\(Y_i^{(0)}\)</span>은 실제로 관찰 불가능한 반사실적 <strong>Potential Outcome</strong> 이다.</p><p><br></p><h3><span id="-rct의-의의">- RCT의 의의</span></h3><ul><li><p><strong>선택바이어스(Selection Bias)</strong> 의 제거</p></li><li><p>조작변수 이외의 다른 변수들을 통제하지 못한 채 <code>Control Group</code>과 <code>Treatment Group</code> 선택하게 되면, 그룹간의 동질성을 확보하지 못하여 <strong>교란변수(confounding factor)</strong> 에 의해 효과가 왜곡 될 수있다. 이러한 것을 <strong>선택 바이어스</strong> 라고 한다.</p></li><li><p>RCT는 완전 무작위로 처치그룹을 선택하기 때문에 <strong>선택 바이어스</strong> 에서 자유로워질 수 있다.</p></li></ul><p><br></p><h3><span id="-rct의-약점">- RCT의 약점</span></h3><p>(1). 비용(예산, 시간 등)이 많이 든다.</p><p>(2). 외적타당성(일반화 가능성)<span class="math inline">\(^{[*3]}\)</span></p><ul><li>RCT에서는 비용의 문제로 인해 외부조건을 통제하게 되고 그로인해 외적타당성은 낮아질 수 있다.</li></ul><p>(3). noncompliance 문제</p><ul><li>RCT에서 무작위로 그룹을 배분해도 거기에 따르지 않는 사람이 생겨서 나타나는 문제</li></ul><p>(4). <em>(특히 기업의 AB테스트에서)</em> 다른 RCT를 같은 대상자에 겹쳐서 실행하게 될 경우, 그에 따른 바이어스가 생길 수 있다.</p><ul><li>통계적으로 처리하기가 상당히 복잡해진다.</li></ul><p><br><br>&lt;span style="font-size: 85%;&gt; <span class="math inline">\(^{[*1]}:\)</span> '원인'과 '결과' 양쪽 모두에게 공통의 원인이 되는 요인. Graphical Model에서 공통부모, 분기로 표현되는 부분. 내생성(Endogeneity)으로도 표현한다. </p><p>&lt;span style="font-size: 85%;&gt; <span class="math inline">\(^{[*2]}:\)</span> 다른 외생변수들이 종속변수에 영향을 주지 않고 진정한 독립변수 의 효과인가의 타당성. </p><p>&lt;span style="font-size: 85%;&gt; <span class="math inline">\(^{[*3]}:\)</span> 내적타당성을 높이기 위해 실험조건을 엄격히 통제한다면 일반화 가능성이 낮아질 수 있다. 얼마나 일반적 현실에 확장 가능한지의 타당성. </p><hr><h2><span id="reference">* Reference</span></h2><p>해당 포스트는 <a href="https://www.youtube.com/watch?v=u8hsTkLg2xc&amp;t=159s">유튜브 채널「データの科学のメソドロジー」의 山田典一님의 강의</a>를 틀로 내용을 정리 &amp; 추가 했음을 밝힙니다.</p><p>그 외 참조</p><p><a href="https://www.amazon.co.jp/dp/4297111179/ref=cm_sw_r_tw_dp_U_x_-LQxEbJ8JDZ1N">効果検証入門〜正しい比較のための因果推論/計量経済学の基礎 （安井翔太）</a></p><p><a href="https://www.rieti.go.jp/jp/publications/dp/19j003.pdf">RCTをめぐる3つの問題とその解法（山口一男）</a></p><p><a href="https://healthpolicyhealthecon.com/2015/02/23/experiment-and-quasi-experiment-1/">実験（Experiment）と疑似実験（Quasi-experiment）に関する記事(津川友介)</a></p><p><a href="http://blog.daum.net/sangrimza/15612241">http://blog.daum.net/sangrimza/15612241</a></p><p><a href="https://m.blog.naver.com/PostView.nhn?blogId=lucifer246&amp;logNo=201407281&amp;proxyReferer=https:%2F%2Fwww.google.com%2F">https://m.blog.naver.com/PostView.nhn?blogId=lucifer246&amp;logNo=201407281&amp;proxyReferer=https:%2F%2Fwww.google.com%2F</a></p>]]></content:encoded>
      
      
      <category domain="https://jaysung00.github.io/categories/Prerequisite/">Prerequisite</category>
      
      <category domain="https://jaysung00.github.io/categories/Prerequisite/Causal-Inference/">Causal Inference</category>
      
      <category domain="https://jaysung00.github.io/categories/Prerequisite/Causal-Inference/a-Overall/">a.Overall</category>
      
      
      <category domain="https://jaysung00.github.io/tags/Causal-Inference/">Causal Inference</category>
      
      <category domain="https://jaysung00.github.io/tags/Bayesian-Network/">Bayesian Network</category>
      
      
      <comments>https://jaysung00.github.io/2020/11/30/CI1/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>【 도대체 베이지안 네트워크가 뭐야? ①】</title>
      <link>https://jaysung00.github.io/2020/11/14/BN1/</link>
      <guid>https://jaysung00.github.io/2020/11/14/BN1/</guid>
      <pubDate>Sat, 14 Nov 2020 14:15:12 GMT</pubDate>
      
      <description>&lt;hr /&gt;</description>
      
      
      
      <content:encoded><![CDATA[<hr><a id="more"></a><h1><span id="베이지안-네트워크bn-bayesian-network-란">* 베이지안 네트워크(BN; Bayesian Network) 란?</span></h1><hr><ul><li>확률 변수(RV; Random variables)들 사이의 조건부 독립 등의 관계를 보임으로써, RV의 full joint distribution등을 간결하게 표현할 수 있는 <strong>그래프 표기법 (Graphical Notation)</strong> 이다.</li></ul><p><br></p><ul><li><p>여기서 <strong>그래프(Graph)</strong> 란, 수학에서 차트(Chart)와 대조되어 정의된 <code>node</code>와 <code>edge</code>의 집합</p><ul><li><p><code>edge</code>가 방향이 지정되어 있으면 <code>directed</code>, 그렇지 않으면 <code>undirected</code></p></li><li><p>그래프의 모든 <code>edge</code>가 <code>directed</code>일 때 <code>directed graph</code></p></li><li><p><code>directed edge</code>에서, 시작되는 쪽의 노드를 <code>parent node</code> 라고 하고 반대쪽은 <code>child node</code>라고 한다</p></li><li><p>복수의 연결된 <code>directed edge</code>의 방향이 같은 경우 이를 <code>directed path</code>라고 하고, <code>directed path</code>의 첫 번째 노드는 경로상의 모든 노드들의 <code>ancestor node</code>이고, 반대로 나머지 노드들은 첫번째 노드의 <code>descendant node</code>이다.</p></li><li><p><code>directed path</code>의 시작점과 끝점이 일치할 경우 이를 <code>cyclic</code>이라 하고, 그렇지 않은 경우 <code>acyclic</code>라고 한다.</p></li></ul></li></ul><p><br></p><ul><li><p><strong>베이지안 네트워크(BN)</strong> 의 <strong>Syntax</strong></p><ul><li><p><code>Network</code> 는 <code>Node</code>와 이들을 연결시키는 <code>Edge</code>로 구성된다</p></li><li><p><code>방향성 비순환 그래프(DAG; Directed Acyclic Graph)</code> 가 되어야 한다</p></li><li><p>개별 <code>Node</code>들은 RV인 <span class="math inline">\(X\)</span>에 대해 <span class="math inline">\(\bf P(X | Paranets(X))\)</span>를 의미한다.</p></li><li><p>개별 <code>Edge</code>들은 부모가 자식에게 주는 <strong>직접적인 영향(Direct Influence)</strong> 을 의미한다.</p></li></ul></li></ul><p><br></p><hr><h1><span id="먼저-확률에-대한-간단한-복습부터">* 먼저 확률에 대한 간단한 복습부터</span></h1><hr><ul><li><strong>베이지안 네트워크</strong> 라는 것은 결국 <em>확률변수(RV) 간의 관계</em> 를 표현한 것이다.<br></li><li><strong>확률</strong> 이라는 것은 <em>상대적인 빈도</em> 이다.<br><br></li></ul><blockquote><p>독립성 (Independence)</p></blockquote><ul><li><p><span class="math inline">\(P(A|B) = P(A)\)</span></p><p><span class="math inline">\(\Leftrightarrow P(A,B) = P(A)P(B)\)</span></p><p><span class="math inline">\(\Leftrightarrow P(B|A) = P(B)\)</span>; A와 B가 독립이면, B는 A와 독립이다.</p><ul><li><p>사건B가 발생했다는 정보는 사건A가 발생할 확률에 추가적인 정보를 제공하지 못한다.</p></li><li><p>이는, 밑에 서술하는 Conditional Independence 와 대립되는 의미로 Marginal Independence 라고 할 수 있다.</p></li></ul></li></ul><p><br></p><blockquote><p>조건부 독립 (Conditional Independence)</p></blockquote><ul><li><p><span class="math inline">\(P(A|B,C) = P(A|C)\)</span></p><ul><li>사건C가 주어졌을 때 두 사건 A와 B가 독립인 경우, 이것은 C라는 조건하에서 <em>조건부 독립</em> 이다.</li></ul></li></ul><p><br></p><blockquote><p>조건부 확률 (Conditional Probability)</p></blockquote><ul><li><p><span class="math inline">\(P(A= true|B=true)\)</span></p><ul><li><p>"Probablity of A given B"</p></li><li><p>B가 주어졌을 때, A의 확률<br><br></p></li></ul></li></ul><blockquote><p>결합 확률 (joint Probability)</p></blockquote><ul><li><p><span class="math inline">\(P(A= true, B=true)\)</span></p><ul><li><p>"the probability of A=true <strong>and</strong> B=true"</p></li><li><p>A=true와 B=true가 동시에 만족할 확률</p></li><li><p><strong>조건부 확률과 결합 확률의 관계</strong> 는 일반적으로, <span class="math inline">\(P(X|Y) =\cfrac{P(X,Y)}{P(Y)}\)</span><br><br></p></li></ul></li></ul><blockquote><p>총 확률 법칙 (Law of Total Probability)</p></blockquote><ul><li><p>"Summing out" or "Marginalization"</p></li><li><p><span class="math inline">\(P(A) = \sum_kP(A,B_k) = \sum_kP(A|B_k)P(B_k)\)</span></p><ul><li><p><span class="math inline">\(P(A) = \sum_kP(A,B_k)\)</span> 는 <span class="math inline">\(B_1,B_2,...,B_n\)</span>이 각각 상호배반적인 집합이고 이들의 합집합이 전체집합이 되므로 성립 (marginalize)</p></li><li><p><span class="math inline">\(\sum_kP(A,B_k) = \sum_kP(A|B_k)P(B_k)\)</span>는 조건부확률과 결합확률의 관계를 이용하면 유도가능<br><br></p></li></ul></li><li><p>이로 인한 이점은, <span class="math inline">\(P(A)\)</span>를 직접 구하는 것보다, <span class="math inline">\(P(A|B_k)\)</span>와 같은 조건부확률을 구해서 합치는 것이 일반적으로 더 수월하다는 것이다.</p></li><li><p>혹은 결합확률을 알고 있을 때, 여러가지 확률을 계산 할 수 있다.</p><ul><li><p>예를들어, 결합확률인 <span class="math inline">\(P(a,b,c,d)\)</span>를 알고 있을 때, <span class="math inline">\(P(c|b)\)</span>는 이렇게 표현할 수 있다</p></li><li><p><span class="math inline">\(P(c|b) = \sum_a \sum_d P(a,c,d|b) = \cfrac{1}{P(b)}\sum_a \sum_d {\bf P(a,b,c,d)}\)</span></p></li><li><p>그러나 joint의 경우에는 parameter의 수가 exponential하게 늘어나게 된다! (Chain Rule의 필요성)</p></li></ul></li></ul><p><br></p><blockquote><p>확률의 연쇄법칙 (Chain Rule for probability)</p></blockquote><ul><li><p>모든 joint distribution에 대해, 결합확률과 조건부확률의 관계에 의해 언제나 이하와 같이 표현할 수 있다.</p></li><li><p><span class="math inline">\(P(a,b,c,...,z) = P(a|b,c,...,z)P(b,c,....,z)\)</span></p></li><li><p>이것을 반복적으로 하면, <span class="math inline">\(P(a,b,c,...,z) = P(a|b,c,...,z)P(b|c,...,z)P(c|d,...,z)...P(z)\)</span>로 표현 가능하다. (Factorization)</p></li></ul><p><br></p><blockquote><p>곱 분해 법칙 (Rule of product decomposition)</p></blockquote><ul><li><p>Bayesian Network에서는 그래프에 속한 RV의 결합분포(joint distribution)는 <code>family</code>의 모든 조건부 분포 <span class="math inline">\(P(Child|Parent)\)</span>의 곱<span class="math inline">\(^{[*1]}\)</span>으로 표현 할 수 있다. <em>(시리즈의 다음 포스트의 Factorization of Bayes Network 내용 참조)</em></p></li><li><p><span class="math inline">\(P(x_1,x_2,...,x_n) = \prod _iP(x_i|Parents(x_i))\)</span></p><ul><li><p>Parents는 직접적으로 연결되어 영향을 받는 변수만을 의미!</p></li><li><p>예를 들어, <span class="math inline">\(X\rightarrow Y \rightarrow Z\)</span> 인 그래프에서 <span class="math inline">\(P(X=x, Y=y, Z=z)\)</span>를 구하는 것을 생각해보자</p></li><li><p>원래는 가능한 모든 조합의 <span class="math inline">\((x, y, z)\)</span>에 해당하는 확률 테이블을 만들어야 한다</p></li><li><p>그러나, 이 법칙을 이용하면 <span class="math inline">\(P(X=x, Y=y, Z=z) = P(X=x)P(Y=y|X=x)P(Z=z|Y=y)\)</span>로 간결하게 표현 가능</p></li><li><p>이처럼 고차원을 저차원으로 만들어 <em>차원의 저주(curse of dimensionality)</em> 에서도 비교적 자유로워 질 수 있다.</p></li></ul></li></ul><p><br></p><p>&lt;span style="font-size: 85%;&gt; <span class="math inline">\(^{[*1]}:\)</span> 이렇게 정의되는 원래는 뒤에서 기술하는 베이지안 네트워크의 Typical Local Structures Rules와 관련 되어있다. </p><hr><h1><span id="베이지안-네트워크의-rules-of-typical-local-structures">* 베이지안 네트워크의 Rules of Typical Local Structures</span></h1><hr><p><br></p><blockquote><p>Rule 1. 사슬 혹은 폭포형 (Chain or Cascading)</p></blockquote><p><img src="https://i.imgur.com/IF5m1WL.png"></p><ul><li><p>변수<span class="math inline">\(X\)</span>와 변수<span class="math inline">\(Y\)</span>의 사이에 하나의 방향성 경로 만 있고 변수<span class="math inline">\(Z\)</span>가 해당 경로를 가로막고 있는 경우, <strong><span class="math inline">\(Z\)</span>가 조건부로 주어졌을때 두 변수 <span class="math inline">\(X\)</span>와 <span class="math inline">\(Y\)</span>는 조건부 독립</strong> 이다.</p></li><li><p><span class="math inline">\(X \perp Y|Z\)</span><br><span class="math inline">\(\Leftrightarrow P(Y|X,Z) = P(Y|Z)\)</span></p></li></ul><p><br></p><blockquote><p>Rule 2. 분기 혹은 공통부모형 (Fork or Common parent)</p></blockquote><p><img src="https://i.imgur.com/mIdGQWD.png"></p><ul><li><p>변수 <span class="math inline">\(Z\)</span>가 <span class="math inline">\(X\)</span>와 <span class="math inline">\(Y\)</span>의 공통 원인이고 <span class="math inline">\(X\)</span>와 <span class="math inline">\(Y\)</span>사이에 단 하나의 경로가 있는 경우, <strong><span class="math inline">\(Z\)</span>의 조건이 주어졌을 때 <span class="math inline">\(X\)</span>와 <span class="math inline">\(Y\)</span>는 조건부 독립</strong> 이다.</p></li><li><p><span class="math inline">\(X \perp Y | Z\)</span><br><span class="math inline">\(\Leftrightarrow P(X,Y|Z) = P(X|Z)P(Y|Z)\)</span></p></li></ul><p><br></p><blockquote><p>Rule 3. 충돌부 혹은 V-구조 (Collider or V-structure)</p></blockquote><p><img src="https://i.imgur.com/9HLO4Ad.png"></p><ul><li><p>변수 <span class="math inline">\(Z\)</span>가 두 변수 <span class="math inline">\(X\)</span>와 <span class="math inline">\(Y\)</span> 사이의 충돌 노드이고 <span class="math inline">\(X\)</span>와 <span class="math inline">\(Y\)</span> 사이에 단 <em>하나의 경로</em> 만 있을 경우, <strong><span class="math inline">\(X\)</span>와 <span class="math inline">\(Y\)</span>는 비조건부 독립(underconditionally independent)</strong> 이다. 그러나 <strong><span class="math inline">\(Z\)</span> 또는 <span class="math inline">\(Z\)</span>의 <code>descendant</code>을 조건부로 하였을 때 <span class="math inline">\(X\)</span>와 <span class="math inline">\(Y\)</span>는 종속적일 가능성</strong> 이 있다.</p></li><li><p><span class="math inline">\(\sim (X \perp Y|Z)\)</span><br><span class="math inline">\(\Leftrightarrow P(X,Y,Z)=P(X)P(Y)P(Z|X,Y)\)</span></p></li><li><p>즉 <span class="math inline">\(Z\)</span>가 not given 일 때는 독립이지만, 반대로 <span class="math inline">\(Z\)</span>가 given으로 주어지면 <span class="math inline">\(X\)</span>, <span class="math inline">\(Y\)</span>가 종속적이 될 가능성이 생겨버린다.</p></li></ul><p><br></p><hr><h1><span id="bayes-ball-algorithm">* Bayes Ball Algorithm</span></h1><hr><ul><li><p>목적 ; <span class="math inline">\(X \perp Y | Z\)</span> (<span class="math inline">\(Z\)</span>가 given일 때 <span class="math inline">\(X\)</span>와 <span class="math inline">\(Y\)</span>가 독립) 이 성립하는지 여부를 판정하기 위한 알고리즘</p></li><li><p><span class="math inline">\(X\)</span>에서 공이 출발한다고 가정했을 때 <span class="math inline">\(Y\)</span>까지 공이 도달하는지 확인하는 방법</p></li><li><p>여기서 공은 <code>Information</code>을 의미하고 화살표는 공의 움직임을 의미한다. 노드 간이 직접적인 edge로 연결되어 있지 않더라도 공이 굴러가서 도달할 수 있다면 <code>Indirect influence</code>가 존재하기때문에 두 변수는 <code>depedent</code>하다는 것을 의미한다.</p></li></ul><p><br></p><blockquote><p>Rule 1의 경우</p></blockquote><p>(1). <span class="math inline">\(Z\)</span>가 given이 아닐 때, 공은 지나갈 수 있다. (<span class="math inline">\(X, Y\)</span>는 종속)<br><img src="https://i.imgur.com/A5X39bt.png" width="298px"></p><p>(2). <span class="math inline">\(Z\)</span>가 <strong>given</strong> 일 때, 공은 지나갈 수 없다. (<span class="math inline">\(X \perp Y|Z\)</span>)<br><img src="https://i.imgur.com/k6dl20u.png" width="300px"></p><p><br></p><blockquote><p>Rule 2의 경우</p></blockquote><p>(1). <span class="math inline">\(Z\)</span>가 given이 아닐 때, 공은 지나갈 수 있다. (<span class="math inline">\(X, Y\)</span>는 종속)<br><img src="https://i.imgur.com/8mPvc3A.png" width="300px"></p><p>(2). <span class="math inline">\(Z\)</span>가 <strong>given</strong> 일 때, 공은 지나갈 수 없다. (<span class="math inline">\(X \perp Y|Z\)</span>)</p><p><img src="https://i.imgur.com/hssut55.png" width="300px"></p><p><br></p><blockquote><p>Rule 3의 경우</p></blockquote><p>(1). <span class="math inline">\(Z\)</span>가 <strong>given이 아닐 때, 공은 지나갈 수 없다.</strong> (<span class="math inline">\(\bf X \perp Y\)</span>)<br><img src="https://i.imgur.com/yhO2p9I.png" width="300px"></p><p>(2). <span class="math inline">\(X_C\)</span>가 <strong>given</strong> 일 때, 반대로 path가 생겨서 공이 지나갈 수 있게 된다. (<span class="math inline">\(X, Y\)</span>는 <strong>종속</strong> <span class="math inline">\(|Z\)</span>)</p><p><img src="https://i.imgur.com/Y6SAkrl.png" width="300px"></p><p><br></p><blockquote><p>Bayes Ball Algorithm 연습</p></blockquote><p><img src="https://i.imgur.com/7He2cq7.png" width="350px"></p><p><br></p><ul><li><p><strong>문제 1.</strong> <span class="math inline">\(X_1\perp X_4|X_2\)</span></p><p>두가지 경로로 공을 굴릴 수 있다.</p><p>(1). <span class="math inline">\(X_1 \rightarrow {\bf X_2}(given) \rightarrow X_4\)</span> 의 경로는 <span class="math inline">\(X_2\)</span>가 사슬의 given으로 막혀있으므로 지나갈 수 없다.</p><p>(2). <span class="math inline">\(X_1 \rightarrow X_3 \rightarrow X_5 \rightarrow X_6 \leftarrow {\bf X_2}(given) \rightarrow X_4\)</span> 의 경로는 <span class="math inline">\(X_6\)</span>가 충돌부의 not given으로 막혀있으므로 지나갈 수 없다.</p><p>따라서 어떠한 경로로도 볼은 지나갈수 없으므로 <strong><span class="math inline">\(X_2\)</span>가 given일 때 <span class="math inline">\(X_1\)</span>와 <span class="math inline">\(X_4\)</span>는 독립</strong> 이다.</p></li></ul><p><br></p><ul><li><p><strong>문제 2.</strong> <span class="math inline">\(X_2\perp X_5|X_1\)</span></p><p>두가지 경로로 공을 굴릴 수 있다.</p><p>(1). <span class="math inline">\(X_2 \rightarrow X_6 \leftarrow X_5\)</span> 의 경로는 <span class="math inline">\(X_6\)</span>가 충돌부의 not given으로 막혀있으므로 지나갈 수 없다.</p><p>(2). <span class="math inline">\(X_2 \leftarrow {\bf X_1}(given) \rightarrow X_3 \rightarrow X_5\)</span> 의 경로는 <span class="math inline">\(X_1\)</span>가 분기의 given으로 막혀있으므로 지나갈 수 없다.</p><p>따라서 어떠한 경로로도 볼은 지나갈수 없으므로 <strong><span class="math inline">\(X_1\)</span>가 given일 때 <span class="math inline">\(X_2\)</span>와 <span class="math inline">\(X_5\)</span>는 독립</strong> 이다.</p></li></ul><p><br></p><ul><li><p><strong>문제 3.</strong> <span class="math inline">\(X_1\perp X_6|\{X_2, X_3\}\)</span></p><p>두가지 경로로 공을 굴릴 수 있다.</p><p>(1). <span class="math inline">\(X_1 \rightarrow {\bf X_2}(given) \rightarrow X_6\)</span> 의 경로는 <span class="math inline">\(X_2\)</span>가 사슬의 given으로 막혀있으므로 지나갈 수 없다.</p><p>(2). <span class="math inline">\(X_1 \rightarrow {\bf X_3}(given) \rightarrow X_5 \rightarrow X_6\)</span> 의 경로는 <span class="math inline">\(X_3\)</span>가 사슬의 given으로 막혀있으므로 지나갈 수 없다.</p><p>따라서 어떠한 경로로도 볼은 지나갈수 없으므로 <strong><span class="math inline">\(\{X_2, X_3\}\)</span>가 given일 때 <span class="math inline">\(X_1\)</span>와 <span class="math inline">\(X_6\)</span>는 독립</strong> 이다.</p></li></ul><p><br></p><ul><li><p><strong>문제 4.</strong> <span class="math inline">\(X_2\perp X_3|\{X_1, X_6\}\)</span></p><p>두가지 경로로 공을 굴릴 수 있다.</p><p>(1). <span class="math inline">\(X_2 \leftarrow {\bf X_1}(given) \rightarrow X_3\)</span> 의 경로는 <span class="math inline">\(X_1\)</span>가 분기의 given으로 막혀있으므로 지나갈 수 없다.</p><p>(2). <span class="math inline">\(X_2 \rightarrow {\bf X_6}(given) \leftarrow X_5 \leftarrow X_3\)</span> 의 경로는 <span class="math inline">\(X_6\)</span>가 충돌부의 given으로 뚫려있으므로 지나갈 수 있다.</p><p>따라서 두번째 경로로 볼은 지나갈 수 있으므로 <strong><span class="math inline">\(\{X_1, X_6\}\)</span>가 given일 때 <span class="math inline">\(X_2\)</span>와 <span class="math inline">\(X_3\)</span>는 독립이 성립하지 않는다.</strong></p></li></ul><p><br></p><hr><h1><span id="d-seperation의-정의">* <span class="math inline">\(d\)</span>-Seperation의 정의</span></h1><hr><ul><li><p><span class="math inline">\(d\)</span>는 방향성(directly)을 의미한다.</p></li><li><p>Bayesian Ball Algorithm으로 <span class="math inline">\(d\)</span>-Seperation을 확인할 수 있다.</p></li><li><p>정리하자면, 경로p가 조건부집합 <span class="math inline">\(\{W\}\)</span>에 의해 <span class="math inline">\(d\)</span>-Seperate된다는 명제는 이하와 필요충분조건이다.</p><ol type="1"><li><p>경로p는 조건부집합 <span class="math inline">\(\{W\}\)</span>에 속하는 중간노드 <span class="math inline">\(Z\)</span> 의 사슬 <span class="math inline">\(X \rightarrow Z \rightarrow Y\)</span> 또는 분기 <span class="math inline">\(X \leftarrow Z \rightarrow Y\)</span> 를 포함한다.</p></li><li><p>경로p는 조건부집합 <span class="math inline">\(\{W\}\)</span>에 속하지 않는 중간노드 <span class="math inline">\(Z&#39;\)</span> 의 충돌부 <span class="math inline">\(X \rightarrow Z&#39; \leftarrow Y\)</span> 를 포함한다.</p></li></ol></li></ul><p><br></p><hr><h2><span id="reference">* Reference</span></h2><p>해당 포스트는 <a href="https://www.edwith.org/machinelearning2__17/joinLectures/9782">Edwith에 개설된 문일철 교수님의 인공지능 및 기계학습 개론 II 강의</a>를 정리 &amp; 추가한 내용임을 밝힙니다.</p><p>추가 내용 참조</p><p><a href="http://www.kyobobook.co.kr/product/detailViewKor.laf?ejkGb=KOR&amp;mallGb=KOR&amp;barcode=9791125102236">의학 및 사회과학 연구를 위한 통계적 인과추론 （Judea Pearl, Madelyn Glymour, Nicholas P. Jewell）</a></p>]]></content:encoded>
      
      
      <category domain="https://jaysung00.github.io/categories/Prerequisite/">Prerequisite</category>
      
      <category domain="https://jaysung00.github.io/categories/Prerequisite/Causal-Inference/">Causal Inference</category>
      
      <category domain="https://jaysung00.github.io/categories/Prerequisite/Causal-Inference/b-Bayesian-Network/">b.Bayesian Network</category>
      
      
      <category domain="https://jaysung00.github.io/tags/Causal-Inference/">Causal Inference</category>
      
      <category domain="https://jaysung00.github.io/tags/Bayesian-Network/">Bayesian Network</category>
      
      
      <comments>https://jaysung00.github.io/2020/11/14/BN1/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>【 도대체 베이지안 네트워크가 뭐야? ②】</title>
      <link>https://jaysung00.github.io/2020/11/14/BN2/</link>
      <guid>https://jaysung00.github.io/2020/11/14/BN2/</guid>
      <pubDate>Sat, 14 Nov 2020 14:15:12 GMT</pubDate>
      
      <description>&lt;hr /&gt;</description>
      
      
      
      <content:encoded><![CDATA[<hr><a id="more"></a><h1><span id="factorization-of-bayes-network">* Factorization of Bayes Network</span></h1><hr><ul><li><p>그래프에 속한 RV의 결합분포(joint distribution)는 <code>family</code>의 모든 조건부 분포 <span class="math inline">\(P(Child|Parent)\)</span>의 곱으로 표현 할 수 있다.</p></li><li><p><span class="math inline">\(P(X_1,X_2,...,X_n) = \prod _iP(X_i|Parents(X_i))\)</span></p></li><li><p><code>곱 분해 법칙 (Rule of product decomposition)</code></p></li><li><p>확률의 연쇄법칙 <span class="math inline">\(P(a,b,c,...,z) = P(a|b,c,...,z)P(b,c,....,z)\)</span>에서 사슬과 분기의 Rule에 따르면 부모노드가 given이면 이상은 조상노드는 전부 독립이게 되므로 성립. (충돌부는 부모노드가 아니다.)</p></li><li><p>즉, Bayes Network의 정보를 통해 joint distribution를 계산할 때 parameter의 갯수를 줄일 수 있다.</p></li></ul><p><br></p><p><span class="math inline">\([ 예시 ]\)</span><br><img src="https://i.imgur.com/tl4t2Iz.png" width="350px"></p><p><br></p><ul><li><span class="math inline">\(P(X_1,X_2,X_3,X_4,X_5,X_6,X_7,X_8)\)</span>를 구한다고 하자.</li></ul><ol type="1"><li><p><strong>확률의 연쇄법칙 (Chain Rule for probability)</strong> 에 의해 아무런 Bayesian Network의 정보가 없다고 하더라도 <span class="math inline">\(P(X_1,X_2,X_3,...,X_8) = P(X_1|X_2,X_3,...,X_8)P(X_2|X_3,...,X_8)P(X_3|X_4,...,X_8)...P(X_8)\)</span> 로 Factorize 할 수 있다.</p></li><li><p><strong>곱 분해 법칙 (Rule of product decomposition)</strong> 에 의해 Bayesian Network의 정보를 활용하면 <span class="math inline">\(P(X_1,X_2,X_3,...,X_8) = P(X_1)P(X_2)P(X_3|X_1)P(X_4|X_2)P(X_5|X_2)P(X_6|X_3,X_4)P(X_7|X_6)P(X_8|X_5,X_6)\)</span> 로 훨씬 작은 parameter만으로 Factorize 가능하다.</p></li></ol><p><br></p><hr><h1><span id="plate-notation">* Plate Notation</span></h1><hr><blockquote><p><span class="math inline">\(\begin{align} P(D|\theta) &amp;= P(X_1,...,X_N|\mu,\sigma) \\ &amp;= \prod_i^N P(X_i|\mu,\sigma) \end{align}\)</span></p></blockquote><p><img src="https://i.imgur.com/QqfT9En.png" width="700px"></p><ul><li>이처럼 여러 개의 독립적인 RV들에 대해 위와 같이 <strong>Plate Notation</strong> 로 표현하는 것이 가능하다.</li></ul><p><br></p><hr><h1><span id="베이지안-네트워크에서의-확률추론">* 베이지안 네트워크에서의 확률추론</span></h1><hr><ul><li><p>BN에 있는 모든 random variables ;<br><span class="math inline">\(X = \{X1 ... X_N\}\)</span></p></li><li><p>주어진 증거 변수 (given evidence variables) ;<br><span class="math inline">\(X_V =\{X_{k+1}...X_N\}\)</span><br><span class="math inline">\(x_V\)</span>는 evidence values</p></li><li><p>명시적으로 다루지는 않지만 관계가 있어서 감안할 필요가 있는 변수 (hidden variables) ;<br><span class="math inline">\(X_H = X-X_V = \{X_1...X_k\}\)</span></p></li><li><p>hidden variables ; <span class="math inline">\(X_H = \{Y,Z\}\)</span></p><ul><li><span class="math inline">\(Y\)</span> : query variable (interested hidden variables)<br></li><li><span class="math inline">\(Z\)</span> : uninterested hidden variables</li></ul></li></ul><p><br></p><h3><span id="1-1-주변확률-marginal-probability">1-1 주변확률 (Marginal Probability)</span></h3><blockquote><p>증거 변수 <span class="math inline">\(X_V\)</span> 의 <strong>주변확률 (Marginal Probability)</strong> <span class="math inline">\(P(x_V)\)</span> 는?</p></blockquote><p>      <span class="math inline">\(\begin{align} P(x_V) &amp;=\sum_{X_H}P(X)=\sum_{X_H}P(X_H,X_V) \space\space\space\space\space\space\dots(1)\\ &amp;= \sum_{x_1}...\sum_{x_k}P(x_1...x_k,x_V)\space\space\space\space\space\space\space\space\space\dots(2) \end{align}\)</span></p><ul><li><p>(1). 모든 변수에 대해 <strong>full joint</strong> 된 것을 <span class="math inline">\(X_H\)</span>로 marginalize out한 것이라고 생각한다.</p></li><li><p>(2). 각각의 Hidden variable에 대해 marginalize out한 것이라고 생각한다.</p></li></ul><p><br></p><h3><span id="1-2-조건부-확률-conditional-probability">1-2. 조건부 확률 (Conditional Probability)</span></h3><blockquote><p>주어진 증거(evidence)의 집합<span class="math inline">\(x_V\)</span>이 있을때, <strong>query variable(주어지지 않았지만 관심있는 변수)</strong> 의 <strong>조건부 확률</strong> <span class="math inline">\(P(Y|x_V)\)</span>은?</p></blockquote><p>      <span class="math inline">\(\begin{align} P(Y|X_V) &amp;= \sum_ZP(Y,Z = z|x_V) \space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\dots(1)\\ &amp;= \sum_Z\cfrac{P(Y,Z,x_V)}{P(x_V)} = \sum_Z\alpha P(X) \space\space\space\space\space\space\space\space\space\space\dots(2)\\ &amp;= \sum_Z \cfrac{P(Y,Z,x_V)}{\sum_{y,z}P(Y=y, Z=z, x_V)}\space\space\space\space\space\space\space\space\space\dots(3) \end{align}\)</span><br><br></p><ul><li><p>(1). <span class="math inline">\(Z\)</span>를 joint로 넣어주면서 <span class="math inline">\(Z\)</span>에 대해 marginalize out 한다.</p></li><li><p>(2). 조건부 확률의 정의를 이용해, <span class="math inline">\(x_V\)</span>를 포함한 <strong>full joint</strong> 를 <span class="math inline">\(P(x_V)\)</span> (Marginal Probability)로 나눈다.<br>(<span class="math inline">\(\cfrac{1}{P(x_V)} = \alpha\)</span>라는 정규화 상수(normalization constant)의 곱으로 생각할수도 있다.)</p></li><li><p>(3). 분모의 주변확률은 Inference Question1처럼 <strong>full joint</strong> 를 모든 Hidden variable에 대해 marginalize 해서 구할 수 있다.</p></li></ul><p><br></p><hr><h1><span id="변수제거-알고리즘-variable-eliminatation-algorithm">* 변수제거 알고리즘 (Variable Eliminatation Algorithm)</span></h1><hr><p><img src="https://i.imgur.com/suXGsdJ.png" width="750px"></p><blockquote><p>위와 같이 주어진 상황에서 변수제거 알고리즘으로 <span class="math inline">\(P(J=j)\)</span>를 구해보자</p></blockquote><h3><span id="step1">* Step1</span></h3><ul><li>위의 준비를 통해 베이지안 네트워크 상에서 관심있는 확률의 추론을 위해서, <strong>full joint</strong> 를 구하고 uninterested hidden variable에 대해 <strong>Marginalize</strong> 한다.</li></ul><p><br></p><ul><li><span class="math inline">\(\sum_{A,E,B,M} P(J= j,A,E,B,M)\)</span></li></ul><p><br></p><h3><span id="step2">* Step2</span></h3><ul><li><p><strong>full joint</strong> 를 Bayesina Network의 정보를 이용해 <em>곱분해 법칙</em>으로 바꿔 쓴다.</p></li><li><p>분해한 곱의 나열순서는 <strong>topological order</strong> <span class="math inline">\(^{[*1]}\)</span> 를 따른다.</p></li><li><p><strong>topological order</strong> ; B, E, A, J, M</p></li></ul><p><br></p><ul><li><span class="math inline">\(\sum_{B,E,A,M} P(B)P(E)P(A|B,E)P(J=j|A)P(M|A)\)</span></li></ul><p><br></p><p>&lt;span style="font-size: 85%;&gt; <span class="math inline">\(^{[*1]}:\)</span> 들어오는 화살표가 없는 노드 부터 하나씩 선택하며 지우는 것을 반복할때 결정되는 순서 </p><h3><span id="step3">* Step3</span></h3><ul><li><p>순서를 유지한 채 각 <span class="math inline">\(\sum\)</span>가 관련없는 것을 밖으로 빼낸다.</p></li><li><p>제거할 변수의 순서는 뒤에서부터 정해진다.</p></li></ul><p><br></p><ul><li><span class="math inline">\(\space\space\space\sum_B P(B)\sum_EP(E)\sum_AP(A|B,E)P(J=j|A)\sum_MP(M|A)\)</span></li></ul><p><br></p><h3><span id="step4">* Step4</span></h3><ul><li>뒤에서 부터 <strong>function notation</strong>으로 바꿔주면서 변수를 지워나간다.</li></ul><p><br></p><ol type="1"><li><span class="math inline">\(\space\space\space\sum_B P(B)\sum_EP(E)\sum_AP(A|B,E)P(J=j|A) \underline {\sum_MP(M|A)}\)</span></li></ol><ul><li><p><span class="math inline">\(=\sum_B P(B)\sum_EP(E)\sum_AP(A|B,E)P(J=j|A) \underline {\bf f_1(A)}\)</span></p><ul><li>밑줄친 부분은 J와 <span class="math inline">\(d\)</span>-seperate이기 때문에 고려할 필요가 없다. 즉, A의 값과 상관없이 <span class="math inline">\(f_1(A)\)</span>는 1을 갖는다.</li></ul></li></ul><p><img src="https://i.imgur.com/EnN5hP3.png" width="220px"></p><p><br></p><ol start="2" type="1"><li><span class="math inline">\(=\sum_B P(B)\sum_EP(E)\underline{\sum_AP(A|B,E)P(J=j|A)}\)</span></li></ol><ul><li><p><span class="math inline">\(=\sum_B P(B)\sum_EP(E)\underline {\bf f_2(E,B)}\)</span></p><ul><li><span class="math inline">\(f_2(E,B)\)</span>는 이하와 같다.</li></ul></li></ul><p><img src="https://i.imgur.com/BOhvHDZ.png" width="750px"></p><p><br></p><ol start="3" type="1"><li><span class="math inline">\(=\sum_B P(B)\underline {\sum_EP(E)f_2(B,E)}\)</span></li></ol><ul><li><p><span class="math inline">\(=\sum_B P(B) \underline {\bf f_3(B)}\)</span></p><ul><li><span class="math inline">\(f_3(B)\)</span>는 이하와 같다.</li></ul></li></ul><p><img src="https://i.imgur.com/A3u5hM9.png" width="750px"></p><p><br></p><ol start="4" type="1"><li><span class="math inline">\(= \sum_BP(B)f_3(B)\)</span></li></ol><ul><li><p><span class="math inline">\(= P(B=b)f_3(B=b) + P(B= \sim b)f_3(B=\sim b)\)</span></p></li><li><p><span class="math inline">\(=0.001 * 0.849017 + 0.999 * 0.0513413 \fallingdotseq 0.052139\)</span></p></li><li><p>따라서, <span class="math inline">\(P(J=j) = 0.052139\)</span> 가 된다.</p></li></ul><p><br></p><hr><h2><span id="reference">* Reference</span></h2><p>해당 포스트는 <a href="https://www.edwith.org/machinelearning2__17/joinLectures/9782">Edwith에 개설된 문일철 교수님의 인공지능 및 기계학습 개론 II 강의</a>를 정리 &amp; 추가한 내용임을 밝힙니다.</p><p>추가 내용 참조</p><p><a href="https://www.youtube.com/watch?v=TZnEJ4wvLPY">https://www.youtube.com/watch?v=TZnEJ4wvLPY</a></p><p><a href="http://www.kyobobook.co.kr/product/detailViewKor.laf?ejkGb=KOR&amp;mallGb=KOR&amp;barcode=9791125102236">의학 및 사회과학 연구를 위한 통계적 인과추론 （Judea Pearl, Madelyn Glymour, Nicholas P. Jewell）</a></p>]]></content:encoded>
      
      
      <category domain="https://jaysung00.github.io/categories/Prerequisite/">Prerequisite</category>
      
      <category domain="https://jaysung00.github.io/categories/Prerequisite/Causal-Inference/">Causal Inference</category>
      
      <category domain="https://jaysung00.github.io/categories/Prerequisite/Causal-Inference/b-Bayesian-Network/">b.Bayesian Network</category>
      
      
      <category domain="https://jaysung00.github.io/tags/Causal-Inference/">Causal Inference</category>
      
      <category domain="https://jaysung00.github.io/tags/Bayesian-Network/">Bayesian Network</category>
      
      
      <comments>https://jaysung00.github.io/2020/11/14/BN2/#disqus_thread</comments>
      
    </item>
    
  </channel>
</rss>
