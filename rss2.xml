<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"
  xmlns:atom="http://www.w3.org/2005/Atom"
  xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Jay Sung&#39;s DS blog</title>
    <link>https://jaysung00.github.io/</link>
    
    <atom:link href="https://jaysung00.github.io/rss2.xml" rel="self" type="application/rss+xml"/>
    
    <description></description>
    <pubDate>Fri, 04 Dec 2020 08:37:44 GMT</pubDate>
    <generator>http://hexo.io/</generator>
    
    <item>
      <title></title>
      <link>https://jaysung00.github.io/2020/12/04/CI1/</link>
      <guid>https://jaysung00.github.io/2020/12/04/CI1/</guid>
      <pubDate>Fri, 04 Dec 2020 08:37:44 GMT</pubDate>
      
        
        
      <description>
</description>
        
      
      
      
      <content:encoded><![CDATA[]]></content:encoded>
      
      
      
      
      <comments>https://jaysung00.github.io/2020/12/04/CI1/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>【Causal Inference②】조작변수법(IV)에 관하여</title>
      <link>https://jaysung00.github.io/2020/12/04/CN2/</link>
      <guid>https://jaysung00.github.io/2020/12/04/CN2/</guid>
      <pubDate>Fri, 04 Dec 2020 08:34:44 GMT</pubDate>
      
      <description>&lt;hr /&gt;</description>
      
      
      
      <content:encoded><![CDATA[<hr><a id="more"></a><h1><span id="rct를-사용할-수-없을-때는-어떻게-할까">* RCT를 사용할 수 없을 때는 어떻게 할까?</span></h1><hr><p>Level 1. 실험(Experimental) 레벨 (개입연구)</p><ul><li>관찰자(해석자)가 개입의 계획을 세워서 데이터를 수집 <span class="math inline">\(\rightarrow\)</span> RCT (무작위화비교실험)</li></ul><p><br></p><h3><span id="blacktriangleright-level-2-준실험quasi-experimental-레벨"><span class="math inline">\(\blacktriangleright\)</span> Level 2. 준실험(Quasi Experimental) 레벨</span></h3><ul><li><p>비교적 질 좋은 관찰연구 정도의 느낌</p></li><li><p>실험데이터가 아니라 <strong>관찰데이터</strong> 를 사용해서, 개입의 여부 등으로 결과에의 영향을 추정</p></li><li><p><strong>측정되지 않은 교란인자</strong>를 처리할 수 있는 것은 사실상 RCT만이 쉽게 가능하지만, <strong>모든 교란인자를 충분히 측정할 수 있다고 하면</strong> 준실험설계로도 충분히 인과관계를 설명할 수 있다.</p></li><li><p><strong>변수조작법(IV)</strong> , <strong>차의 차 분석(DID)</strong> , <strong>경향스코어 매칭(PS)</strong> , <strong>회귀불연속 디자인(RDD)</strong> 등이 있다.</p></li></ul><p><br></p><p>Level 3. 관찰(Observation) 레벨</p><ul><li>더욱 인과추론 하기에 취약한 관찰연구 디자인</li></ul><p><br></p><hr><h1><span id="i-조작변수법-iv-instrumental-variable-methods"><span class="math inline">\(I\)</span>. 조작변수법 (IV; Instrumental variable methods)</span></h1><hr><h3><span id="-조작변수법이란">- 조작변수법이란?</span></h3><ul><li>매우 어렵지만 이론상 완벽하게 설계된다면 <strong>측정되지 않은 교란인자</strong> 도 처리할 수 있는 방법.</li></ul><p><br></p><ul><li><p><strong>외생변수</strong> ; 모델의 밖에서 결정되어 주어진 변수 (설명변수로써 바람직하다).</p><ul><li><strong>모델의 잔차항</strong> 과 독립하게 된다.</li></ul></li></ul><p><br></p><ul><li><p><strong>내생변수</strong> ; 모델 내에서 결정되는 변수 (설명변수로써 바람직하지 않다).</p><ul><li>예를 들어 <em>측정되지 않은 교란인자</em> 가 있는 경우 영향을 받는 <strong>설명변수와 모델의 잔차항 사이에 상관</strong> 관계가 생겨버리고 이 설명변수는 <strong>내생변수</strong> 가 되어 <em>내생성 바이어스</em> 를 만든다.</li></ul></li></ul><p><br></p><ul><li><p>이렇게 발생된 <strong>내생변수</strong> 를 <strong>외생화</strong> 하기 위해 도입된 변수 <span class="math inline">\(Z\)</span>를 <strong>조작변수(IV)</strong> 라고 한다.</p></li><li><p>이러한 조작변수를 이용해, 설명변수가 결과에 미치는 영향을 평가하는 방법을 <strong>조작변수법</strong> 이라고 한다.</p></li></ul><p><br></p><blockquote><p><span class="math inline">\([ 예시 ]\)</span><br><img src="https://i.imgur.com/Q8xihRF.png" width="550px"><br>- 참의 관계 : <span class="math inline">\(ln(wage) = a + b \cdot educ + c \cdot ability + u\)</span></p></blockquote><p>임금(Wage)와 교육년수(Education)와 능력(Ability)은 위와 같은 관계가 있다고 가정한다.</p><p>그러나 능력은 실제로 측정불가하기 때문에 교육수준만으로 임금과의 관계를 설명하는 모델을 작성했다고 하자.</p><ul><li><span class="math inline">\(ln(wage) = a&#39; + b&#39; \cdot educ + v\)</span></li></ul><p>이 때, 능력(Ability)은 <strong>관측되지 않은 교란인자</strong> 가 되고 계수 <span class="math inline">\(b&#39;\)</span>에는 내생성 바이어스가 존재하게 된다.</p><p><br></p><h3><span id="-조작변수법의-과정">- 조작변수법의 과정</span></h3><p><strong>내생변수</strong> 를 피설명변수로 별도의 조작변수 <span class="math inline">\(IV\)</span>를 통해 설명하는 모델을 작성한다.</p><ul><li><span class="math inline">\(\begin{align} ln(wage) &amp;= a&#39; + b&#39; \cdot educ + \underline v \\ &amp;= a&#39; + b&#39; \cdot educ + \underline {c&#39; \cdot X+ v&#39;} \end{align}\)</span></li></ul><p><span class="math inline">\(\space\space\space\space\space\space\space\space\space\space\space\space\space\)</span> (C를 잔차항에 포함된 <em>교란인자</em> 라고 가정)</p><ul><li><span class="math inline">\(\bf educ = \alpha + \beta \cdot \underline {IV} + \gamma \cdot X + \epsilon\)</span><br><br><br><img src="https://i.imgur.com/SJ5bifx.png" width="600px"></li></ul><p><br></p><ul><li><p><strong>조작변수 <span class="math inline">\(\bf IV\)</span>의 조건</strong></p><ol type="1"><li><p>Exclusion restriction : IV는 원래의 결과부분에 해당하는 변수(Wage)에게 개입변수(설명변수, Education)를 통해서만 영향을 줄 수있다.</p></li><li><p>No instrument-outcome confounder：IV와 원래의 결과부분에 해당하는 변수(Wage)에게 동시에 영향을 주는 <strong>공통의 원인(L 또는 X)</strong> 이 존재하지 않아야 한다</p></li><li><p>Instrument relevance : 개입변수(설명변수, Education)에게는 확실히 영향을 주는 변수여야 한다.</p></li><li><p>Monotonicity : 조작변수가 역효과를 내는 사람(Defiers)이 존재하지 않아야 한다. (완전히 반대로 움직이는 케이스)</p></li></ol></li></ul><p>이상의 조건을 만족하는 조작변수를 발견해, 이를 통해 교란인자에 의한 효과를 제거한다.<br><br></p><h4><span id="그러나-이러한-조건을-만족하는-조작변수를-찾아내는-것은-매우-어렵고-특히-비즈니스-현장에서는-거의-불가능에-가깝다">【그러나, 이러한 조건을 만족하는 조작변수를 찾아내는 것은 매우 어렵고 특히 비즈니스 현장에서는 거의 불가능에 가깝다.】</span></h4><p><br></p><h3><span id="-그럼에도-불구하고-생각해보는-조작변수법iv의-활용-가능성">- 그럼에도 불구하고 생각해보는 조작변수법(IV)의 활용 가능성</span></h3><ul><li><p>하지만 실제 개입에서는 개입의 대상이지만 따르지 않는 경우나 대상이 아니지만 따르는 경우와 같이 참가자가 개입의도와 반대로 움직이는 경우가 존재한다.</p></li><li><p><em>정책이나 치료와 같은 개입의 효과를 추정하기 위해서 개입의도대로 움직이는 부분집단만을 비교하는 것이 좋지 않을까 라는 이론</em></p></li><li><p>개입을 행하는 참가자의 의도를 1과 0을 갖는 dummy <strong>조작변수 <span class="math inline">\(z\)</span></strong> 로 생각한다.</p></li></ul><p><img src="https://i.imgur.com/qCI2qOc.png" width="600px"></p><p><br></p><ul><li><span class="math inline">\(\begin{equation}z= \left \{\begin{array}{l}1　(개입의도 있음) \\0　(개입의도없음)\end{array}\right.\end{equation}\)</span></li></ul><p><br></p><ul><li><span class="math inline">\(d = zd_1 + (1-z)d_0\)</span><br>(<span class="math inline">\(d\)</span>는 <span class="math inline">\(z\)</span>가 1일 때 <span class="math inline">\(d_1\)</span>이 되고, <span class="math inline">\(z\)</span>가 0일 때 <span class="math inline">\(d_0\)</span>이 된다.)</li></ul><p><br></p><ul><li><span class="math inline">\(\begin{equation}d= \left \{\begin{array}{l}1　(실행) \\0　(실행하지않음)\end{array}\right.\end{equation}\)</span></li></ul><p><br></p><ul><li><span class="math inline">\(y=dy_1 + (1-d)y_0\)</span><br>(마찬가지로 <span class="math inline">\(y\)</span>는 <span class="math inline">\(d\)</span>가 1일 때 <span class="math inline">\(y_1\)</span>이 되고, <span class="math inline">\(d\)</span>가 0일 때 <span class="math inline">\(y_0\)</span>이 된다.)</li></ul><p><br></p><ul><li>조작변수의 가정으로, <span class="math inline">\(\bf (y_0,y_1) \perp z|d,\space\space\space d_z \perp z\)</span>를 만족한다</li></ul><p><br></p><table><thead><tr class="header"><th style="text-align: center;">개입의도 <span class="math inline">\(z\)</span></th><th style="text-align: center;">참가자의 의사 <span class="math inline">\(d\)</span></th><th style="text-align: center;">Notation</th><th style="text-align: left;">상황의 해석</th></tr></thead><tbody><tr class="odd"><td style="text-align: center;">1</td><td style="text-align: center;">1</td><td style="text-align: center;"><span class="math inline">\(d_1\)</span> = 1</td><td style="text-align: left;">개입의 대상이 되어서 참가자가 개입의도에 맞게 따르는 경우</td></tr><tr class="even"><td style="text-align: center;">1</td><td style="text-align: center;">0</td><td style="text-align: center;"><span class="math inline">\(d_1\)</span> = 0</td><td style="text-align: left;">개입의 대상이 되었지만 참가자가 개입의도에 따르지 않는 경우 (noncompliance)</td></tr><tr class="odd"><td style="text-align: center;">0</td><td style="text-align: center;">1</td><td style="text-align: center;"><span class="math inline">\(d_0\)</span> = 1</td><td style="text-align: left;">개입의 대상이 아님에도 불구하고 개입의도의 방향으로 움직이는 경우</td></tr><tr class="even"><td style="text-align: center;">0</td><td style="text-align: center;">0</td><td style="text-align: center;"><span class="math inline">\(d_0\)</span> = 0</td><td style="text-align: left;">개입의 대상이 아니였기 때문에 개입의도에 따르지 않는 경우</td></tr></tbody></table><p><br></p><h3><span id="-국소적-평균효과late-local-average-treatment-effect">- <strong>국소적 평균효과(LATE; local average treatment effect)</strong></span></h3><p><br></p><ul><li><p>정의 ; <span class="math inline">\(\Large LATE = E(y_1-y_0|d_1=1,d_0=0)\)</span></p></li><li><p>의미 ; 개입의도의 방향대로 움직여주는 부분집합에서만 측정한 효과</p></li></ul><p><br></p><blockquote><p>[예시]<br><strong>콜롬비아에서 이루어진 '바우쳐제도'는 학업성적 향상의 효과가 있었을까?</strong></p></blockquote><blockquote><p>[상황설명]<br>- 바우쳐제도란, 제비뽑기로 장학생을 선정해서 사립 중학교의 수업료 절반을 부담해주는 제도이다.<br>- 그러나 바우쳐제도 만으로 수업료를 감당하기 힘들어 제비뽑기에서 선발되어도 사립중학교의 입학을 포기하는 학생들이 존재했다.<br>- 부모님들의 경제적능력이 좋거나 사립학교를 선호하는 학생들은 제비뽑기에서 떨어져도 사립학교에 입학했다.</p></blockquote><p><br></p><ul><li><span class="math inline">\(\begin{equation}z= \left \{\begin{array}{l}1　(제비뽑기당첨) \\0　(제비뽑기탈락)\end{array}\right.\end{equation}\)</span></li></ul><p><br></p><ul><li><span class="math inline">\(d = zd_1 + (1-z)d_0\)</span></li></ul><p><br></p><ul><li><span class="math inline">\(\begin{equation}d= \left \{\begin{array}{l}1　(사립학교진학) \\0　(공립학교진학)\end{array}\right.\end{equation}\)</span></li></ul><p><br></p><ul><li><span class="math inline">\(y=dy_1 + (1-d)y_0\)</span> (성적)</li></ul><p><br></p><ul><li><p>여기서 우리가 궁금한 것은 <strong>[바우쳐제도] <span class="math inline">\(\bf \rightarrow\)</span> [사립학교진학] <span class="math inline">\(\bf \rightarrow\)</span> [성적향상]</strong> 의 인과스토리(causal story)를 가진 효과이다.</p></li><li><p>그러므로 우리가 관심있는 케이스는 <strong>제비뽑기에 붙으면 사립학교에 가고 떨어지면 공립학교에 진학할 학생</strong> 이다.</p></li><li><p>즉, 제비뽑기에 붙던 안붙던 사립학교에 갈 학생 (<span class="math inline">\(d_1=1,d_0=1\)</span>)이나 붙던 안붙던 공립학교에 갈 학생 (<span class="math inline">\(d_1=0,d_0=0\)</span>)은 고려의 대상이 아니다.</p></li></ul><p><br></p><ul><li><p>따라서, <span class="math inline">\(ATE = E(y_1-y_0)\)</span> 를 구하면 단순히 사립학교와 공립학교의 성적 차이를 구하게 된다.</p></li><li><p>이 경우 <span class="math inline">\(LATE = E(y_1-y_0|d_1=1,d_0=0)\)</span> 를 구하는 것이 바람직할 것이다.</p></li></ul><p><br></p><h4><span id="이와-같이-준실험으로써의-조작변수법은-상당이-어렵지만-late-의-아이디어로써의-조작변수법은-생각해볼만-하다">이와 같이 준실험으로써의 조작변수법은 상당이 어렵지만 <strong>LATE</strong> 의 아이디어로써의 조작변수법은 생각해볼만 하다.</span></h4><p><br><br><br></p><hr><h2><span id="reference">* Reference</span></h2><p>해당 포스트는 <a href="https://www.youtube.com/watch?v=u8hsTkLg2xc&amp;t=159s">유튜브 채널「データの科学のメソドロジー」의 山田典一님의 강의</a>를 틀로 내용을 정리 &amp; 추가 했음을 밝힙니다.</p><p>그 외 참조</p><p><a href="https://www.amazon.co.jp/dp/4000069721/ref=cm_sw_r_tw_dp_U_x_5LQxEbXZJDK4H">調査観察データの統計科学―因果推論・選択バイアス・データ融（星野崇宏）</a></p><p><a href="http://www.ier.hit-u.ac.jp/~kitamura/lecture/Hit/08Statsys5.pdf">捜査変数法（一橋大学経済研究所, 北村 行伸）</a></p><p><a href="https://healthpolicyhealthecon.com/2015/02/23/experiment-and-quasi-experiment-1/">操作変数法Instrumental variable methodsに関するブログ (津川友介)</a></p>]]></content:encoded>
      
      
      <category domain="https://jaysung00.github.io/categories/KOR/">KOR</category>
      
      <category domain="https://jaysung00.github.io/categories/KOR/%ED%86%B5%EA%B3%84%EC%A0%81%EC%9D%B8%EA%B3%BC%EC%B6%94%EB%A1%A0/">통계적인과추론</category>
      
      <category domain="https://jaysung00.github.io/categories/KOR/%ED%86%B5%EA%B3%84%EC%A0%81%EC%9D%B8%EA%B3%BC%EC%B6%94%EB%A1%A0/ML/">ML</category>
      
      
      <category domain="https://jaysung00.github.io/tags/causal/">causal</category>
      
      <category domain="https://jaysung00.github.io/tags/%ED%86%B5%EA%B3%84%EC%A0%81-%EC%9D%B8%EA%B3%BC%EC%B6%94%EB%A1%A0/">통계적 인과추론</category>
      
      
      <comments>https://jaysung00.github.io/2020/12/04/CN2/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>【 도대체 베이지안 네트워크가 뭐야? ①】</title>
      <link>https://jaysung00.github.io/2020/11/14/BN1/</link>
      <guid>https://jaysung00.github.io/2020/11/14/BN1/</guid>
      <pubDate>Sat, 14 Nov 2020 14:15:12 GMT</pubDate>
      
      <description>&lt;hr /&gt;</description>
      
      
      
      <content:encoded><![CDATA[<hr><a id="more"></a><h1><span id="베이지안-네트워크bn-bayesian-network-란">* 베이지안 네트워크(BN; Bayesian Network) 란?</span></h1><hr><ul><li>확률 변수(RV; Random variables)들 사이의 조건부 독립 등의 관계를 보임으로써, RV의 full joint distribution등을 간결하게 표현할 수 있는 <strong>그래프 표기법 (Graphical Notation)</strong> 이다.</li></ul><p><br></p><ul><li><p>여기서 <strong>그래프(Graph)</strong> 란, 수학에서 차트(Chart)와 대조되어 정의된 <code>node</code>와 <code>edge</code>의 집합</p><ul><li><p><code>edge</code>가 방향이 지정되어 있으면 <code>directed</code>, 그렇지 않으면 <code>undirected</code></p></li><li><p>그래프의 모든 <code>edge</code>가 <code>directed</code>일 때 <code>directed graph</code></p></li><li><p><code>directed edge</code>에서, 시작되는 쪽의 노드를 <code>parent node</code> 라고 하고 반대쪽은 <code>child node</code>라고 한다</p></li><li><p>복수의 연결된 <code>directed edge</code>의 방향이 같은 경우 이를 <code>directed path</code>라고 하고, <code>directed path</code>의 첫 번째 노드는 경로상의 모든 노드들의 <code>ancestor node</code>이고, 반대로 나머지 노드들은 첫번째 노드의 <code>descendant node</code>이다.</p></li><li><p><code>directed path</code>의 시작점과 끝점이 일치할 경우 이를 <code>cyclic</code>이라 하고, 그렇지 않은 경우 <code>acyclic</code>라고 한다.</p></li></ul></li></ul><p><br></p><ul><li><p><strong>베이지안 네트워크(BN)</strong> 의 <strong>Syntax</strong></p><ul><li><p><code>Network</code> 는 <code>Node</code>와 이들을 연결시키는 <code>Edge</code>로 구성된다</p></li><li><p><code>방향성 비순환 그래프(DAG; Directed Acyclic Graph)</code> 가 되어야 한다</p></li><li><p>개별 <code>Node</code>들은 RV인 <span class="math inline">\(X\)</span>에 대해 <span class="math inline">\(\bf P(X | Paranets(X))\)</span>를 의미한다.</p></li><li><p>개별 <code>Edge</code>들은 부모가 자식에게 주는 <strong>직접적인 영향(Direct Influence)</strong> 을 의미한다.</p></li></ul></li></ul><p><br></p><hr><h1><span id="먼저-확률에-대한-간단한-복습부터">* 먼저 확률에 대한 간단한 복습부터</span></h1><hr><ul><li><strong>베이지안 네트워크</strong> 라는 것은 결국 <em>확률변수(RV) 간의 관계</em> 를 표현한 것이다.<br></li><li><strong>확률</strong> 이라는 것은 <em>상대적인 빈도</em> 이다.<br><br></li></ul><blockquote><p>독립성 (Independence)</p></blockquote><ul><li><p><span class="math inline">\(P(A|B) = P(A)\)</span></p><p><span class="math inline">\(\Leftrightarrow P(A,B) = P(A)P(B)\)</span></p><p><span class="math inline">\(\Leftrightarrow P(B|A) = P(B)\)</span>; A와 B가 독립이면, B는 A와 독립이다.</p><ul><li><p>사건B가 발생했다는 정보는 사건A가 발생할 확률에 추가적인 정보를 제공하지 못한다.</p></li><li><p>이는, 밑에 서술하는 Conditional Independence 와 대립되는 의미로 Marginal Independence 라고 할 수 있다.</p></li></ul></li></ul><p><br></p><blockquote><p>조건부 독립 (Conditional Independence)</p></blockquote><ul><li><p><span class="math inline">\(P(A|B,C) = P(A|C)\)</span></p><ul><li>사건C가 주어졌을 때 두 사건 A와 B가 독립인 경우, 이것은 C라는 조건하에서 <em>조건부 독립</em> 이다.</li></ul></li></ul><p><br></p><blockquote><p>조건부 확률 (Conditional Probability)</p></blockquote><ul><li><p><span class="math inline">\(P(A= true|B=true)\)</span></p><ul><li><p>"Probablity of A given B"</p></li><li><p>B가 주어졌을 때, A의 확률<br><br></p></li></ul></li></ul><blockquote><p>결합 확률 (joint Probability)</p></blockquote><ul><li><p><span class="math inline">\(P(A= true, B=true)\)</span></p><ul><li><p>"the probability of A=true <strong>and</strong> B=true"</p></li><li><p>A=true와 B=true가 동시에 만족할 확률</p></li><li><p><strong>조건부 확률과 결합 확률의 관계</strong> 는 일반적으로, <span class="math inline">\(P(X|Y) =\cfrac{P(X,Y)}{P(Y)}\)</span><br><br></p></li></ul></li></ul><blockquote><p>총 확률 법칙 (Law of Total Probability)</p></blockquote><ul><li><p>"Summing out" or "Marginalization"</p></li><li><p><span class="math inline">\(P(A) = \sum_kP(A,B_k) = \sum_kP(A|B_k)P(B_k)\)</span></p><ul><li><p><span class="math inline">\(P(A) = \sum_kP(A,B_k)\)</span> 는 <span class="math inline">\(B_1,B_2,...,B_n\)</span>이 각각 상호배반적인 집합이고 이들의 합집합이 전체집합이 되므로 성립 (marginalize)</p></li><li><p><span class="math inline">\(\sum_kP(A,B_k) = \sum_kP(A|B_k)P(B_k)\)</span>는 조건부확률과 결합확률의 관계를 이용하면 유도가능<br><br></p></li></ul></li><li><p>이로 인한 이점은, <span class="math inline">\(P(A)\)</span>를 직접 구하는 것보다, <span class="math inline">\(P(A|B_k)\)</span>와 같은 조건부확률을 구해서 합치는 것이 일반적으로 더 수월하다는 것이다.</p></li><li><p>혹은 결합확률을 알고 있을 때, 여러가지 확률을 계산 할 수 있다.</p><ul><li><p>예를들어, 결합확률인 <span class="math inline">\(P(a,b,c,d)\)</span>를 알고 있을 때, <span class="math inline">\(P(c|b)\)</span>는 이렇게 표현할 수 있다</p></li><li><p><span class="math inline">\(P(c|b) = \sum_a \sum_d P(a,c,d|b) = \cfrac{1}{P(b)}\sum_a \sum_d {\bf P(a,b,c,d)}\)</span></p></li><li><p>그러나 joint의 경우에는 parameter의 수가 exponential하게 늘어나게 된다! (Chain Rule의 필요성)</p></li></ul></li></ul><p><br></p><blockquote><p>확률의 연쇄법칙 (Chain Rule for probability)</p></blockquote><ul><li><p>모든 joint distribution에 대해, 결합확률과 조건부확률의 관계에 의해 언제나 이하와 같이 표현할 수 있다.</p></li><li><p><span class="math inline">\(P(a,b,c,...,z) = P(a|b,c,...,z)P(b,c,....,z)\)</span></p></li><li><p>이것을 반복적으로 하면, <span class="math inline">\(P(a,b,c,...,z) = P(a|b,c,...,z)P(b|c,...,z)P(c|d,...,z)...P(z)\)</span>로 표현 가능하다. (Factorization)</p></li></ul><p><br></p><blockquote><p>곱 분해 법칙 (Rule of product decomposition)</p></blockquote><ul><li><p>Bayesian Network에서는 그래프에 속한 RV의 결합분포(joint distribution)는 <code>family</code>의 모든 조건부 분포 <span class="math inline">\(P(Child|Parent)\)</span>의 곱<span class="math inline">\(^{[*1]}\)</span>으로 표현 할 수 있다. <em>(시리즈의 다음 포스트의 Factorization of Bayes Network 내용 참조)</em></p></li><li><p><span class="math inline">\(P(x_1,x_2,...,x_n) = \prod _iP(x_i|Parents(x_i))\)</span></p><ul><li><p>Parents는 직접적으로 연결되어 영향을 받는 변수만을 의미!</p></li><li><p>예를 들어, <span class="math inline">\(X\rightarrow Y \rightarrow Z\)</span> 인 그래프에서 <span class="math inline">\(P(X=x, Y=y, Z=z)\)</span>를 구하는 것을 생각해보자</p></li><li><p>원래는 가능한 모든 조합의 <span class="math inline">\((x, y, z)\)</span>에 해당하는 확률 테이블을 만들어야 한다</p></li><li><p>그러나, 이 법칙을 이용하면 <span class="math inline">\(P(X=x, Y=y, Z=z) = P(X=x)P(Y=y|X=x)P(Z=z|Y=y)\)</span>로 간결하게 표현 가능</p></li><li><p>이처럼 고차원을 저차원으로 만들어 <em>차원의 저주(curse of dimensionality)</em> 에서도 비교적 자유로워 질 수 있다.</p></li></ul></li></ul><p><br></p><p>&lt;span style="font-size: 85%;&gt; <span class="math inline">\(^{[*1]}:\)</span> 이렇게 정의되는 원래는 뒤에서 기술하는 베이지안 네트워크의 Typical Local Structures Rules와 관련 되어있다. </p><hr><h1><span id="베이지안-네트워크의-rules-of-typical-local-structures">* 베이지안 네트워크의 Rules of Typical Local Structures</span></h1><hr><p><br></p><blockquote><p>Rule 1. 사슬 혹은 폭포형 (Chain or Cascading)</p></blockquote><p><img src="https://i.imgur.com/IF5m1WL.png"></p><ul><li><p>변수<span class="math inline">\(X\)</span>와 변수<span class="math inline">\(Y\)</span>의 사이에 하나의 방향성 경로 만 있고 변수<span class="math inline">\(Z\)</span>가 해당 경로를 가로막고 있는 경우, <strong><span class="math inline">\(Z\)</span>가 조건부로 주어졌을때 두 변수 <span class="math inline">\(X\)</span>와 <span class="math inline">\(Y\)</span>는 조건부 독립</strong> 이다.</p></li><li><p><span class="math inline">\(X \perp Y|Z\)</span><br><span class="math inline">\(\Leftrightarrow P(Y|X,Z) = P(Y|Z)\)</span></p></li></ul><p><br></p><blockquote><p>Rule 2. 분기 혹은 공통부모형 (Fork or Common parent)</p></blockquote><p><img src="https://i.imgur.com/mIdGQWD.png"></p><ul><li><p>변수 <span class="math inline">\(Z\)</span>가 <span class="math inline">\(X\)</span>와 <span class="math inline">\(Y\)</span>의 공통 원인이고 <span class="math inline">\(X\)</span>와 <span class="math inline">\(Y\)</span>사이에 단 하나의 경로가 있는 경우, <strong><span class="math inline">\(Z\)</span>의 조건이 주어졌을 때 <span class="math inline">\(X\)</span>와 <span class="math inline">\(Y\)</span>는 조건부 독립</strong> 이다.</p></li><li><p><span class="math inline">\(X \perp Y | Z\)</span><br><span class="math inline">\(\Leftrightarrow P(X,Y|Z) = P(X|Z)P(Y|Z)\)</span></p></li></ul><p><br></p><blockquote><p>Rule 3. 충돌부 혹은 V-구조 (Collider or V-structure)</p></blockquote><p><img src="https://i.imgur.com/9HLO4Ad.png"></p><ul><li><p>변수 <span class="math inline">\(Z\)</span>가 두 변수 <span class="math inline">\(X\)</span>와 <span class="math inline">\(Y\)</span> 사이의 충돌 노드이고 <span class="math inline">\(X\)</span>와 <span class="math inline">\(Y\)</span> 사이에 단 <em>하나의 경로</em> 만 있을 경우, <strong><span class="math inline">\(X\)</span>와 <span class="math inline">\(Y\)</span>는 비조건부 독립(underconditionally independent)</strong> 이다. 그러나 <strong><span class="math inline">\(Z\)</span> 또는 <span class="math inline">\(Z\)</span>의 <code>descendant</code>을 조건부로 하였을 때 <span class="math inline">\(X\)</span>와 <span class="math inline">\(Y\)</span>는 종속적일 가능성</strong> 이 있다.</p></li><li><p><span class="math inline">\(\sim (X \perp Y|Z)\)</span><br><span class="math inline">\(\Leftrightarrow P(X,Y,Z)=P(X)P(Y)P(Z|X,Y)\)</span></p></li><li><p>즉 <span class="math inline">\(Z\)</span>가 not given 일 때는 독립이지만, 반대로 <span class="math inline">\(Z\)</span>가 given으로 주어지면 <span class="math inline">\(X\)</span>, <span class="math inline">\(Y\)</span>가 종속적이 될 가능성이 생겨버린다.</p></li></ul><p><br></p><hr><h1><span id="bayes-ball-algorithm">* Bayes Ball Algorithm</span></h1><hr><ul><li><p>목적 ; <span class="math inline">\(X \perp Y | Z\)</span> (<span class="math inline">\(Z\)</span>가 given일 때 <span class="math inline">\(X\)</span>와 <span class="math inline">\(Y\)</span>가 독립) 이 성립하는지 여부를 판정하기 위한 알고리즘</p></li><li><p><span class="math inline">\(X\)</span>에서 공이 출발한다고 가정했을 때 <span class="math inline">\(Y\)</span>까지 공이 도달하는지 확인하는 방법</p></li><li><p>여기서 공은 <code>Information</code>을 의미하고 화살표는 공의 움직임을 의미한다. 노드 간이 직접적인 edge로 연결되어 있지 않더라도 공이 굴러가서 도달할 수 있다면 <code>Indirect influence</code>가 존재하기때문에 두 변수는 <code>depedent</code>하다는 것을 의미한다.</p></li></ul><p><br></p><blockquote><p>Rule 1의 경우</p></blockquote><p>(1). <span class="math inline">\(Z\)</span>가 given이 아닐 때, 공은 지나갈 수 있다. (<span class="math inline">\(X, Y\)</span>는 종속)<br><img src="https://i.imgur.com/A5X39bt.png" width="298px"></p><p>(2). <span class="math inline">\(Z\)</span>가 <strong>given</strong> 일 때, 공은 지나갈 수 없다. (<span class="math inline">\(X \perp Y|Z\)</span>)<br><img src="https://i.imgur.com/k6dl20u.png" width="300px"></p><p><br></p><blockquote><p>Rule 2의 경우</p></blockquote><p>(1). <span class="math inline">\(Z\)</span>가 given이 아닐 때, 공은 지나갈 수 있다. (<span class="math inline">\(X, Y\)</span>는 종속)<br><img src="https://i.imgur.com/8mPvc3A.png" width="300px"></p><p>(2). <span class="math inline">\(Z\)</span>가 <strong>given</strong> 일 때, 공은 지나갈 수 없다. (<span class="math inline">\(X \perp Y|Z\)</span>)</p><p><img src="https://i.imgur.com/hssut55.png" width="300px"></p><p><br></p><blockquote><p>Rule 3의 경우</p></blockquote><p>(1). <span class="math inline">\(Z\)</span>가 <strong>given이 아닐 때, 공은 지나갈 수 없다.</strong> (<span class="math inline">\(\bf X \perp Y\)</span>)<br><img src="https://i.imgur.com/yhO2p9I.png" width="300px"></p><p>(2). <span class="math inline">\(X_C\)</span>가 <strong>given</strong> 일 때, 반대로 path가 생겨서 공이 지나갈 수 있게 된다. (<span class="math inline">\(X, Y\)</span>는 <strong>종속</strong> <span class="math inline">\(|Z\)</span>)</p><p><img src="https://i.imgur.com/Y6SAkrl.png" width="300px"></p><p><br></p><blockquote><p>Bayes Ball Algorithm 연습</p></blockquote><p><img src="https://i.imgur.com/7He2cq7.png" width="350px"></p><p><br></p><ul><li><p><strong>문제 1.</strong> <span class="math inline">\(X_1\perp X_4|X_2\)</span></p><p>두가지 경로로 공을 굴릴 수 있다.</p><p>(1). <span class="math inline">\(X_1 \rightarrow {\bf X_2}(given) \rightarrow X_4\)</span> 의 경로는 <span class="math inline">\(X_2\)</span>가 사슬의 given으로 막혀있으므로 지나갈 수 없다.</p><p>(2). <span class="math inline">\(X_1 \rightarrow X_3 \rightarrow X_5 \rightarrow X_6 \leftarrow {\bf X_2}(given) \rightarrow X_4\)</span> 의 경로는 <span class="math inline">\(X_6\)</span>가 충돌부의 not given으로 막혀있으므로 지나갈 수 없다.</p><p>따라서 어떠한 경로로도 볼은 지나갈수 없으므로 <strong><span class="math inline">\(X_2\)</span>가 given일 때 <span class="math inline">\(X_1\)</span>와 <span class="math inline">\(X_4\)</span>는 독립</strong> 이다.</p></li></ul><p><br></p><ul><li><p><strong>문제 2.</strong> <span class="math inline">\(X_2\perp X_5|X_1\)</span></p><p>두가지 경로로 공을 굴릴 수 있다.</p><p>(1). <span class="math inline">\(X_2 \rightarrow X_6 \leftarrow X_5\)</span> 의 경로는 <span class="math inline">\(X_6\)</span>가 충돌부의 not given으로 막혀있으므로 지나갈 수 없다.</p><p>(2). <span class="math inline">\(X_2 \leftarrow {\bf X_1}(given) \rightarrow X_3 \rightarrow X_5\)</span> 의 경로는 <span class="math inline">\(X_1\)</span>가 분기의 given으로 막혀있으므로 지나갈 수 없다.</p><p>따라서 어떠한 경로로도 볼은 지나갈수 없으므로 <strong><span class="math inline">\(X_1\)</span>가 given일 때 <span class="math inline">\(X_2\)</span>와 <span class="math inline">\(X_5\)</span>는 독립</strong> 이다.</p></li></ul><p><br></p><ul><li><p><strong>문제 3.</strong> <span class="math inline">\(X_1\perp X_6|\{X_2, X_3\}\)</span></p><p>두가지 경로로 공을 굴릴 수 있다.</p><p>(1). <span class="math inline">\(X_1 \rightarrow {\bf X_2}(given) \rightarrow X_6\)</span> 의 경로는 <span class="math inline">\(X_2\)</span>가 사슬의 given으로 막혀있으므로 지나갈 수 없다.</p><p>(2). <span class="math inline">\(X_1 \rightarrow {\bf X_3}(given) \rightarrow X_5 \rightarrow X_6\)</span> 의 경로는 <span class="math inline">\(X_3\)</span>가 사슬의 given으로 막혀있으므로 지나갈 수 없다.</p><p>따라서 어떠한 경로로도 볼은 지나갈수 없으므로 <strong><span class="math inline">\(\{X_2, X_3\}\)</span>가 given일 때 <span class="math inline">\(X_1\)</span>와 <span class="math inline">\(X_6\)</span>는 독립</strong> 이다.</p></li></ul><p><br></p><ul><li><p><strong>문제 4.</strong> <span class="math inline">\(X_2\perp X_3|\{X_1, X_6\}\)</span></p><p>두가지 경로로 공을 굴릴 수 있다.</p><p>(1). <span class="math inline">\(X_2 \leftarrow {\bf X_1}(given) \rightarrow X_3\)</span> 의 경로는 <span class="math inline">\(X_1\)</span>가 분기의 given으로 막혀있으므로 지나갈 수 없다.</p><p>(2). <span class="math inline">\(X_2 \rightarrow {\bf X_6}(given) \leftarrow X_5 \leftarrow X_3\)</span> 의 경로는 <span class="math inline">\(X_6\)</span>가 충돌부의 given으로 뚫려있으므로 지나갈 수 있다.</p><p>따라서 두번째 경로로 볼은 지나갈 수 있으므로 <strong><span class="math inline">\(\{X_1, X_6\}\)</span>가 given일 때 <span class="math inline">\(X_2\)</span>와 <span class="math inline">\(X_3\)</span>는 독립이 성립하지 않는다.</strong></p></li></ul><p><br></p><hr><h1><span id="d-seperation의-정의">* <span class="math inline">\(d\)</span>-Seperation의 정의</span></h1><hr><ul><li><p><span class="math inline">\(d\)</span>는 방향성(directly)을 의미한다.</p></li><li><p>Bayesian Ball Algorithm으로 <span class="math inline">\(d\)</span>-Seperation을 확인할 수 있다.</p></li><li><p>정리하자면, 경로p가 조건부집합 <span class="math inline">\(\{W\}\)</span>에 의해 <span class="math inline">\(d\)</span>-Seperate된다는 명제는 이하와 필요충분조건이다.</p><ol type="1"><li><p>경로p는 조건부집합 <span class="math inline">\(\{W\}\)</span>에 속하는 중간노드 <span class="math inline">\(Z\)</span> 의 사슬 <span class="math inline">\(X \rightarrow Z \rightarrow Y\)</span> 또는 분기 <span class="math inline">\(X \leftarrow Z \rightarrow Y\)</span> 를 포함한다.</p></li><li><p>경로p는 조건부집합 <span class="math inline">\(\{W\}\)</span>에 속하지 않는 중간노드 <span class="math inline">\(Z&#39;\)</span> 의 충돌부 <span class="math inline">\(X \rightarrow Z&#39; \leftarrow Y\)</span> 를 포함한다.</p></li></ol></li></ul><p><br></p><hr><h2><span id="reference">* Reference</span></h2><p>해당 포스트는 <a href="https://www.edwith.org/machinelearning2__17/joinLectures/9782">Edwith에 개설된 문일철 교수님의 인공지능 및 기계학습 개론 II 강의</a>를 정리 &amp; 추가한 내용임을 밝힙니다.</p><p>추가 내용 참조</p><p><a href="http://www.kyobobook.co.kr/product/detailViewKor.laf?ejkGb=KOR&amp;mallGb=KOR&amp;barcode=9791125102236">의학 및 사회과학 연구를 위한 통계적 인과추론 （Judea Pearl, Madelyn Glymour, Nicholas P. Jewell）</a></p>]]></content:encoded>
      
      
      <category domain="https://jaysung00.github.io/categories/KOR/">KOR</category>
      
      <category domain="https://jaysung00.github.io/categories/KOR/%ED%86%B5%EA%B3%84%EC%A0%81%EC%9D%B8%EA%B3%BC%EC%B6%94%EB%A1%A0/">통계적인과추론</category>
      
      <category domain="https://jaysung00.github.io/categories/KOR/%ED%86%B5%EA%B3%84%EC%A0%81%EC%9D%B8%EA%B3%BC%EC%B6%94%EB%A1%A0/ML/">ML</category>
      
      
      <category domain="https://jaysung00.github.io/tags/causal/">causal</category>
      
      <category domain="https://jaysung00.github.io/tags/KMOOC/">KMOOC</category>
      
      
      <comments>https://jaysung00.github.io/2020/11/14/BN1/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>【 도대체 베이지안 네트워크가 뭐야? ②】</title>
      <link>https://jaysung00.github.io/2020/11/14/BN2/</link>
      <guid>https://jaysung00.github.io/2020/11/14/BN2/</guid>
      <pubDate>Sat, 14 Nov 2020 14:15:12 GMT</pubDate>
      
      <description>&lt;hr /&gt;</description>
      
      
      
      <content:encoded><![CDATA[<hr><a id="more"></a><h1><span id="factorization-of-bayes-network">* Factorization of Bayes Network</span></h1><hr><ul><li><p>그래프에 속한 RV의 결합분포(joint distribution)는 <code>family</code>의 모든 조건부 분포 <span class="math inline">\(P(Child|Parent)\)</span>의 곱으로 표현 할 수 있다.</p></li><li><p><span class="math inline">\(P(X_1,X_2,...,X_n) = \prod _iP(X_i|Parents(X_i))\)</span></p></li><li><p><code>곱 분해 법칙 (Rule of product decomposition)</code></p></li><li><p>확률의 연쇄법칙 <span class="math inline">\(P(a,b,c,...,z) = P(a|b,c,...,z)P(b,c,....,z)\)</span>에서 사슬과 분기의 Rule에 따르면 부모노드가 given이면 이상은 조상노드는 전부 독립이게 되므로 성립. (충돌부는 부모노드가 아니다.)</p></li><li><p>즉, Bayes Network의 정보를 통해 joint distribution를 계산할 때 parameter의 갯수를 줄일 수 있다.</p></li></ul><p><br></p><p><span class="math inline">\([ 예시 ]\)</span><br><img src="https://i.imgur.com/tl4t2Iz.png" width="350px"></p><p><br></p><ul><li><span class="math inline">\(P(X_1,X_2,X_3,X_4,X_5,X_6,X_7,X_8)\)</span>를 구한다고 하자.</li></ul><ol type="1"><li><p><strong>확률의 연쇄법칙 (Chain Rule for probability)</strong> 에 의해 아무런 Bayesian Network의 정보가 없다고 하더라도 <span class="math inline">\(P(X_1,X_2,X_3,...,X_8) = P(X_1|X_2,X_3,...,X_8)P(X_2|X_3,...,X_8)P(X_3|X_4,...,X_8)...P(X_8)\)</span> 로 Factorize 할 수 있다.</p></li><li><p><strong>곱 분해 법칙 (Rule of product decomposition)</strong> 에 의해 Bayesian Network의 정보를 활용하면 <span class="math inline">\(P(X_1,X_2,X_3,...,X_8) = P(X_1)P(X_2)P(X_3|X_1)P(X_4|X_2)P(X_5|X_2)P(X_6|X_3,X_4)P(X_7|X_6)P(X_8|X_5,X_6)\)</span> 로 훨씬 작은 parameter만으로 Factorize 가능하다.</p></li></ol><p><br></p><hr><h1><span id="plate-notation">* Plate Notation</span></h1><hr><blockquote><p><span class="math inline">\(\begin{align} P(D|\theta) &amp;= P(X_1,...,X_N|\mu,\sigma) \\ &amp;= \prod_i^N P(X_i|\mu,\sigma) \end{align}\)</span></p></blockquote><p><img src="https://i.imgur.com/QqfT9En.png" width="700px"></p><ul><li>이처럼 여러 개의 독립적인 RV들에 대해 위와 같이 <strong>Plate Notation</strong> 로 표현하는 것이 가능하다.</li></ul><p><br></p><hr><h1><span id="베이지안-네트워크에서의-확률추론">* 베이지안 네트워크에서의 확률추론</span></h1><hr><ul><li><p>BN에 있는 모든 random variables ;<br><span class="math inline">\(X = \{X1 ... X_N\}\)</span></p></li><li><p>주어진 증거 변수 (given evidence variables) ;<br><span class="math inline">\(X_V =\{X_{k+1}...X_N\}\)</span><br><span class="math inline">\(x_V\)</span>는 evidence values</p></li><li><p>명시적으로 다루지는 않지만 관계가 있어서 감안할 필요가 있는 변수 (hidden variables) ;<br><span class="math inline">\(X_H = X-X_V = \{X_1...X_k\}\)</span></p></li><li><p>hidden variables ; <span class="math inline">\(X_H = \{Y,Z\}\)</span></p><ul><li><span class="math inline">\(Y\)</span> : query variable (interested hidden variables)<br></li><li><span class="math inline">\(Z\)</span> : uninterested hidden variables</li></ul></li></ul><p><br></p><h3><span id="1-1-주변확률-marginal-probability">1-1 주변확률 (Marginal Probability)</span></h3><blockquote><p>증거 변수 <span class="math inline">\(X_V\)</span> 의 <strong>주변확률 (Marginal Probability)</strong> <span class="math inline">\(P(x_V)\)</span> 는?</p></blockquote><p>      <span class="math inline">\(\begin{align} P(x_V) &amp;=\sum_{X_H}P(X)=\sum_{X_H}P(X_H,X_V) \space\space\space\space\space\space\dots(1)\\ &amp;= \sum_{x_1}...\sum_{x_k}P(x_1...x_k,x_V)\space\space\space\space\space\space\space\space\space\dots(2) \end{align}\)</span></p><ul><li><p>(1). 모든 변수에 대해 <strong>full joint</strong> 된 것을 <span class="math inline">\(X_H\)</span>로 marginalize out한 것이라고 생각한다.</p></li><li><p>(2). 각각의 Hidden variable에 대해 marginalize out한 것이라고 생각한다.</p></li></ul><p><br></p><h3><span id="1-2-조건부-확률-conditional-probability">1-2. 조건부 확률 (Conditional Probability)</span></h3><blockquote><p>주어진 증거(evidence)의 집합<span class="math inline">\(x_V\)</span>이 있을때, <strong>query variable(주어지지 않았지만 관심있는 변수)</strong> 의 <strong>조건부 확률</strong> <span class="math inline">\(P(Y|x_V)\)</span>은?</p></blockquote><p>      <span class="math inline">\(\begin{align} P(Y|X_V) &amp;= \sum_ZP(Y,Z = z|x_V) \space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\dots(1)\\ &amp;= \sum_Z\cfrac{P(Y,Z,x_V)}{P(x_V)} = \sum_Z\alpha P(X) \space\space\space\space\space\space\space\space\space\space\dots(2)\\ &amp;= \sum_Z \cfrac{P(Y,Z,x_V)}{\sum_{y,z}P(Y=y, Z=z, x_V)}\space\space\space\space\space\space\space\space\space\dots(3) \end{align}\)</span><br><br></p><ul><li><p>(1). <span class="math inline">\(Z\)</span>를 joint로 넣어주면서 <span class="math inline">\(Z\)</span>에 대해 marginalize out 한다.</p></li><li><p>(2). 조건부 확률의 정의를 이용해, <span class="math inline">\(x_V\)</span>를 포함한 <strong>full joint</strong> 를 <span class="math inline">\(P(x_V)\)</span> (Marginal Probability)로 나눈다.<br>(<span class="math inline">\(\cfrac{1}{P(x_V)} = \alpha\)</span>라는 정규화 상수(normalization constant)의 곱으로 생각할수도 있다.)</p></li><li><p>(3). 분모의 주변확률은 Inference Question1처럼 <strong>full joint</strong> 를 모든 Hidden variable에 대해 marginalize 해서 구할 수 있다.</p></li></ul><p><br></p><hr><h1><span id="변수제거-알고리즘-variable-eliminatation-algorithm">* 변수제거 알고리즘 (Variable Eliminatation Algorithm)</span></h1><hr><p><img src="https://i.imgur.com/suXGsdJ.png" width="750px"></p><blockquote><p>위와 같이 주어진 상황에서 변수제거 알고리즘으로 <span class="math inline">\(P(J=j)\)</span>를 구해보자</p></blockquote><h3><span id="step1">* Step1</span></h3><ul><li>위의 준비를 통해 베이지안 네트워크 상에서 관심있는 확률의 추론을 위해서, <strong>full joint</strong> 를 구하고 uninterested hidden variable에 대해 <strong>Marginalize</strong> 한다.</li></ul><p><br></p><ul><li><span class="math inline">\(\sum_{A,E,B,M} P(J= j,A,E,B,M)\)</span></li></ul><p><br></p><h3><span id="step2">* Step2</span></h3><ul><li><p><strong>full joint</strong> 를 Bayesina Network의 정보를 이용해 <em>곱분해 법칙</em>으로 바꿔 쓴다.</p></li><li><p>분해한 곱의 나열순서는 <strong>topological order</strong> <span class="math inline">\(^{[*1]}\)</span> 를 따른다.</p></li><li><p><strong>topological order</strong> ; B, E, A, J, M</p></li></ul><p><br></p><ul><li><span class="math inline">\(\sum_{B,E,A,M} P(B)P(E)P(A|B,E)P(J=j|A)P(M|A)\)</span></li></ul><p><br></p><p>&lt;span style="font-size: 85%;&gt; <span class="math inline">\(^{[*1]}:\)</span> 들어오는 화살표가 없는 노드 부터 하나씩 선택하며 지우는 것을 반복할때 결정되는 순서 </p><h3><span id="step3">* Step3</span></h3><ul><li><p>순서를 유지한 채 각 <span class="math inline">\(\sum\)</span>가 관련없는 것을 밖으로 빼낸다.</p></li><li><p>제거할 변수의 순서는 뒤에서부터 정해진다.</p></li></ul><p><br></p><ul><li><span class="math inline">\(\space\space\space\sum_B P(B)\sum_EP(E)\sum_AP(A|B,E)P(J=j|A)\sum_MP(M|A)\)</span></li></ul><p><br></p><h3><span id="step4">* Step4</span></h3><ul><li>뒤에서 부터 <strong>function notation</strong>으로 바꿔주면서 변수를 지워나간다.</li></ul><p><br></p><ol type="1"><li><span class="math inline">\(\space\space\space\sum_B P(B)\sum_EP(E)\sum_AP(A|B,E)P(J=j|A) \underline {\sum_MP(M|A)}\)</span></li></ol><ul><li><p><span class="math inline">\(=\sum_B P(B)\sum_EP(E)\sum_AP(A|B,E)P(J=j|A) \underline {\bf f_1(A)}\)</span></p><ul><li>밑줄친 부분은 J와 <span class="math inline">\(d\)</span>-seperate이기 때문에 고려할 필요가 없다. 즉, A의 값과 상관없이 <span class="math inline">\(f_1(A)\)</span>는 1을 갖는다.</li></ul></li></ul><p><img src="https://i.imgur.com/EnN5hP3.png" width="220px"></p><p><br></p><ol start="2" type="1"><li><span class="math inline">\(=\sum_B P(B)\sum_EP(E)\underline{\sum_AP(A|B,E)P(J=j|A)}\)</span></li></ol><ul><li><p><span class="math inline">\(=\sum_B P(B)\sum_EP(E)\underline {\bf f_2(E,B)}\)</span></p><ul><li><span class="math inline">\(f_2(E,B)\)</span>는 이하와 같다.</li></ul></li></ul><p><img src="https://i.imgur.com/BOhvHDZ.png" width="750px"></p><p><br></p><ol start="3" type="1"><li><span class="math inline">\(=\sum_B P(B)\underline {\sum_EP(E)f_2(B,E)}\)</span></li></ol><ul><li><p><span class="math inline">\(=\sum_B P(B) \underline {\bf f_3(B)}\)</span></p><ul><li><span class="math inline">\(f_3(B)\)</span>는 이하와 같다.</li></ul></li></ul><p><img src="https://i.imgur.com/A3u5hM9.png" width="750px"></p><p><br></p><ol start="4" type="1"><li><span class="math inline">\(= \sum_BP(B)f_3(B)\)</span></li></ol><ul><li><p><span class="math inline">\(= P(B=b)f_3(B=b) + P(B= \sim b)f_3(B=\sim b)\)</span></p></li><li><p><span class="math inline">\(=0.001 * 0.849017 + 0.999 * 0.0513413 \fallingdotseq 0.052139\)</span></p></li><li><p>따라서, <span class="math inline">\(P(J=j) = 0.052139\)</span> 가 된다.</p></li></ul><p><br></p><hr><h2><span id="reference">* Reference</span></h2><p>해당 포스트는 <a href="https://www.edwith.org/machinelearning2__17/joinLectures/9782">Edwith에 개설된 문일철 교수님의 인공지능 및 기계학습 개론 II 강의</a>를 정리 &amp; 추가한 내용임을 밝힙니다.</p><p>추가 내용 참조</p><p><a href="https://www.youtube.com/watch?v=TZnEJ4wvLPY">https://www.youtube.com/watch?v=TZnEJ4wvLPY</a></p><p><a href="http://www.kyobobook.co.kr/product/detailViewKor.laf?ejkGb=KOR&amp;mallGb=KOR&amp;barcode=9791125102236">의학 및 사회과학 연구를 위한 통계적 인과추론 （Judea Pearl, Madelyn Glymour, Nicholas P. Jewell）</a></p>]]></content:encoded>
      
      
      <category domain="https://jaysung00.github.io/categories/KOR/">KOR</category>
      
      <category domain="https://jaysung00.github.io/categories/KOR/%ED%86%B5%EA%B3%84%EC%A0%81%EC%9D%B8%EA%B3%BC%EC%B6%94%EB%A1%A0/">통계적인과추론</category>
      
      <category domain="https://jaysung00.github.io/categories/KOR/%ED%86%B5%EA%B3%84%EC%A0%81%EC%9D%B8%EA%B3%BC%EC%B6%94%EB%A1%A0/ML/">ML</category>
      
      
      <category domain="https://jaysung00.github.io/tags/causal/">causal</category>
      
      <category domain="https://jaysung00.github.io/tags/KMOOC/">KMOOC</category>
      
      
      <comments>https://jaysung00.github.io/2020/11/14/BN2/#disqus_thread</comments>
      
    </item>
    
  </channel>
</rss>
